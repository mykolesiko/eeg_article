{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mykolesiko/egg_article/blob/main/MADE_%D0%A1NN2_leak_beta1_article.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgn5imtHV3u1"
      },
      "source": [
        "#Статья Multimodal Physiological Signal Emotion Recognition Based on Convolutional Recurrent Neural Network\n",
        "https://drive.google.com/file/d/1HrkFFrHnpqEs01KkcVgMvkpx7IaHq-C5/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2dwCgjkV1wi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset,  WeightedRandomSampler\n",
        "import numpy as np\n",
        "from  scipy import stats\n",
        "import scipy\n",
        "np.random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8i6x4kaxXah"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/MADE/Project/deap\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quQeqXQ4b7K-"
      },
      "outputs": [],
      "source": [
        "def get_padding(in_size, kernel_size, stride):\n",
        "    if (in_size % stride == 0):\n",
        "        padding = max(kernel_size - stride, 0)\n",
        "    else:\n",
        "        padding = max(kernel_size - (in_size % stride), 0)\n",
        "    return (padding)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQPEk2ahuXrf"
      },
      "outputs": [],
      "source": [
        "def get_feature_extractor():\n",
        "  conv1 = nn.Conv2d(1, 64, kernel_size = (3, 3), stride=(1, 1), padding='same')\n",
        "  relu1 = nn.ReLU()\n",
        "  bn1 = nn.BatchNorm2d(64)\n",
        "  conv2 = nn.Conv2d(64, 128, kernel_size = (3, 3), stride=(1, 1), padding='same')\n",
        "  relu2 = nn.ReLU()\n",
        "  bn2 = nn.BatchNorm2d(128)\n",
        "  conv3 = nn.Conv2d(128, 256, kernel_size = (3, 3), stride=(1, 1), padding='same')\n",
        "  relu3 = nn.ReLU()\n",
        "  bn3 = nn.BatchNorm2d(256)\n",
        "  #result = torch.nn.Sequential(conv1, bn1, relu1, conv2, bn2, relu2, conv3, bn3, relu3)\n",
        "  result = torch.nn.Sequential(conv1, bn1, conv2, bn2, conv3, bn3)\n",
        "  return(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMhUn9alIx5S"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pickle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "data_dir = './data_preprocessed_python'\n",
        "files = glob.glob(os.path.join(data_dir, \"*.dat\"))\n",
        "data_raw = []\n",
        "for file_data in files:\n",
        "    raw_data = pickle.load(open(file_data, 'rb'), encoding='latin1')\n",
        "    data.append(raw_data['data'])\n",
        "    #data_raw.append(raw_data['data'][:, :, :])\n",
        "    # data_raw[-1][0, :32, 0]\n",
        "    # print(data_raw[-1][:, :31, :].min())\n",
        "    # print(data_raw[-1][:, :31, :].max())\n",
        "    # scaler = MinMaxScaler()\n",
        "    # for i in range(40):\n",
        "    #     #scaler.fit(data[-1][i])\n",
        "    #     scaler = MinMaxScaler()\n",
        "    #     data[-1][i] = scaler.fit_transform(data[-1][i])\n",
        "    #     print(data_raw[-1][i])\n",
        "    #     print(data[-1][i])\n",
        "    #     break\n",
        "    labels.append(raw_data['labels'])\n",
        "    #break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSIzEGztwHYj"
      },
      "outputs": [],
      "source": [
        "NSUBJECTS = 32\n",
        "NVIDEOS = 40\n",
        "NCANALS = 32\n",
        "def remove_baseline():\n",
        "  for sub in range(NSUBJECTS):\n",
        "    for nvideo in range(NVIDEOS):\n",
        "        for ncanal in range(NCANALS):\n",
        "            baseline_mean = (data[sub][nvideo, ncanal, 0: 128] + data[sub][nvideo, ncanal, 128: 128  *2] + data[sub][nvideo, ncanal, 128 * 2: 128 * 3])/3\n",
        "            #print(baseline_mean.shape)\n",
        "            for nsec in range(60):\n",
        "                     data[sub][nvideo, ncanal, nsec * 128 : nsec * 128 + 128] = data[sub][nvideo, ncanal, nsec * 128 : nsec * 128 + 128] - baseline_mean\n",
        "\n",
        "remove_baseline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQf74KX5trjb"
      },
      "outputs": [],
      "source": [
        "class EmotionNet(torch.nn.Module): \n",
        "   def __init__(self, hcanals, wcanals, nfeatures, ntimes_in_sample):\n",
        "      super().__init__()\n",
        "      #print(\"1\")\n",
        "      self.convs = nn.ModuleList([get_feature_extractor() for _ in range(ntimes_in_sample)])\n",
        "      self.conv2 = nn.Conv2d(256 * ntimes_in_sample, 15, kernel_size = 1, stride=1)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.flat = nn.Flatten(1, 3)\n",
        "      self.fc = nn.Linear(1215, 2)\n",
        "      \n",
        "   def forward(self, input):\n",
        "      #print(f\"input_shape = {input.shape}\")\n",
        "      input = input.permute(0, 3, 1, 2)\n",
        "      #input (bs, time = 128,  h=9, w=9)\n",
        "\n",
        "      outputs = []\n",
        "      for i, conv in enumerate(self.convs):\n",
        "            outputs.append(conv(input[:, i, :, :].unsqueeze(1)))\n",
        "            #print(outputs[i])\n",
        "\n",
        "      output = torch.cat(outputs, dim = 1)\n",
        "      #output (bs, s * 256,  h=9, w=9)\n",
        "      output1 = self.conv2(output)\n",
        "      #output1 = self.relu(output1)\n",
        "\n",
        "\n",
        "      output2 = output1.permute(0, 2, 3, 1)\n",
        "      output3 = self.flat(output2)\n",
        "      output3 = self.fc(output3)\n",
        "      #output1 (bs, 15,  h=9, w=9)\n",
        "      return output3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TM4dD2hIeK4U"
      },
      "outputs": [],
      "source": [
        "LEN_RECORD_IN_SECONDS = 60\n",
        "NVIDEOS = 40\n",
        "HCANALS = 9\n",
        "WCANALS = 9\n",
        "NTIMES_IN_SAMPLE = 128\n",
        "NTIMES_IN_SEC = 128\n",
        "NCANALS = 32\n",
        "NFEATURES = 32\n",
        "electrode_matrix = {}\n",
        "electrode_matrix['FP1'] = [0, 3]\n",
        "electrode_matrix['FP2'] = [0, 5]\n",
        "electrode_matrix['AF3'] = [1, 3]\n",
        "electrode_matrix['AF4'] = [1, 5]\n",
        "electrode_matrix['F7']  = [2, 0]\n",
        "electrode_matrix['F3']  = [2, 2]\n",
        "electrode_matrix['FZ']  = [2, 4]\n",
        "electrode_matrix['F4']  = [2, 6]\n",
        "electrode_matrix['F8']  = [2, 8]\n",
        "electrode_matrix['FC5']  = [3, 1]\n",
        "electrode_matrix['FC1']  = [3, 3]\n",
        "electrode_matrix['FC2']  = [3, 5]\n",
        "electrode_matrix['FC6']  = [3, 7]\n",
        "electrode_matrix['T7']  = [4, 0]\n",
        "electrode_matrix['C3']  = [4, 2]\n",
        "electrode_matrix['CZ']  = [4, 4]\n",
        "electrode_matrix['C4']  = [4, 6]\n",
        "electrode_matrix['T8']  = [4, 8]\n",
        "electrode_matrix['CP5']  = [5, 1]\n",
        "electrode_matrix['CP1']  = [5, 3]\n",
        "electrode_matrix['CP2']  = [5, 5]\n",
        "electrode_matrix['CP6']  = [5, 7]\n",
        "electrode_matrix['P7']  = [6, 0]\n",
        "electrode_matrix['P3']  = [6, 2]\n",
        "electrode_matrix['PZ']  = [6, 4]\n",
        "electrode_matrix['P4']  = [6, 6]\n",
        "electrode_matrix['P8']  = [6, 8]\n",
        "electrode_matrix['PO3'] = [7, 3]\n",
        "electrode_matrix['PO4'] = [7, 5]\n",
        "electrode_matrix['O1'] = [8, 3]\n",
        "electrode_matrix['OZ'] = [8, 4]\n",
        "electrode_matrix['O2'] = [8, 5]\n",
        "\n",
        "list_electrodes = ['FP1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3',\t'T7',\t'CP5',\t'CP1',\t'P3',\t'P7',\t'PO3',\t'O1',\t'OZ',\t'PZ',\t'FP2',\t'AF4', 'FZ', 'F4', 'F8', 'FC6',\t'FC2',\t'CZ', 'C4', 'T8', 'CP6',\t'CP2',\t'P4', \t'P8',\t'PO4',\t'O2']\n",
        "data_dir = './data_preprocessed_python'\n",
        "TRAIN_SIZE = 0.9\n",
        "THRESHOLD = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL3auCvsI6E7"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pickle\n",
        "from collections import Counter\n",
        "\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__ (self, data_dir, type, ind, data, labels):\n",
        "       self.data = []\n",
        "       self.labels = []\n",
        "       self.cnt = [Counter(), Counter(), Counter(),Counter()]\n",
        "       #data_dir = './data_preprocessed_python'\n",
        "       #files = glob.glob(os.path.join(data_dir, \"*.dat\"))[0:1]\n",
        "       self.type = type\n",
        "       #split = int(LEN_RECORD_IN_SECONDS)# *  TRAIN_SIZE)\n",
        "       self.ind = ind\n",
        "       self.len_files = []\n",
        "       for s in range(len(data)):\n",
        "            #print(file_data)\n",
        "            #raw_data = pickle.load(open(file_data, 'rb'), encoding='latin1')\n",
        "            #print(raw_data['data'].shape)\n",
        "            #labels = raw_data['labels']\n",
        "            self.data.append(data[s][ind, :, 3 * NTIMES_IN_SEC :LEN_RECORD_IN_SECONDS * NTIMES_IN_SEC + 3 * NTIMES_IN_SEC])\n",
        "            self.len_files.append(len(ind) *  LEN_RECORD_IN_SECONDS - 1)\n",
        "            self.len_record = LEN_RECORD_IN_SECONDS\n",
        "            labels_bin_sub = (labels[s] >= THRESHOLD)\n",
        "            self.labels.append(labels_bin_sub[ind])          \n",
        "            for i in range(4):\n",
        "              self.cnt[i].update(list(self.labels[-1][:, i]))    \n",
        "\n",
        "            \n",
        "       self.len_cumsum = np.cumsum(self.len_files)     \n",
        "       print(self.data[0].shape)\n",
        "       print(self.labels[0].shape)\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        result =  sum(self.len_files) - 10\n",
        "        return result\n",
        "\n",
        "    def get_index_record(self, item):\n",
        "      for i_file in range(len(self.len_cumsum)):\n",
        "         #print(item, self.len_cumsum[i_file])\n",
        "         if (item > self.len_cumsum[i_file]):\n",
        "            continue\n",
        "         else:\n",
        "            break\n",
        "      if i_file == 0:\n",
        "         index_in_file = item\n",
        "      else:\n",
        "         index_in_file = item  - self.len_cumsum[i_file - 1]\n",
        "      nvideo = index_in_file//(self.len_record)# * LEN_RECORD_IN_SECONDS *  NTIMES_IN_SEC)\n",
        "      nsec = (index_in_file - nvideo * self.len_record) # *   NTIMES_IN_SEC)\n",
        "\n",
        "      return i_file, index_in_file, nvideo, nsec\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "      sample = {}\n",
        "      #print(item)\n",
        "      i_file, index_in_file, nvideo, nsec = self.get_index_record(item)\n",
        "      #print(i_file, nvideo, nsec )\n",
        "      sample['data'] = np.zeros((HCANALS, WCANALS, NTIMES_IN_SAMPLE))\n",
        "      sample_from_one_canals = []\n",
        "      for i_canal in range(NCANALS):\n",
        "        sample_from_one_canal = self.data[i_file][nvideo, i_canal, nsec * 128 : nsec * 128 + 128]\n",
        "        sample_from_one_canals.append(sample_from_one_canal)\n",
        "        #print(sample_from_one_canal.shape)\n",
        "      sample_from_one_canals = np.asarray(sample_from_one_canals).copy()\n",
        "      sample_from_one_canals = scipy.stats.zscore(sample_from_one_canals, axis = 0)\n",
        "      for i_canal in range(NCANALS):\n",
        "          sample['data'][electrode_matrix[list_electrodes[i_canal]][0],  electrode_matrix[list_electrodes[i_canal]][1]] = sample_from_one_canals[i_canal]\n",
        "      #for i in range(NTIMES_IN_SAMPLE): \n",
        "      #    sample['data'][:, :, i] = scipy.stats.zscore(sample['data'][:, :, i])\n",
        "      sample['data'] = torch.FloatTensor(sample['data'])\n",
        "      sample['labels']  = torch.LongTensor(self.labels[i_file][nvideo])\n",
        "      \n",
        "      return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53e0zIUWljhm",
        "outputId": "34056c02-c501-47d9-a1fe-294a0f579494"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmotionNet(\n",
              "  (convs): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (8): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (9): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (10): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (11): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (12): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (13): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (14): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (15): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (16): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (17): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (18): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (19): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (20): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (21): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (22): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (23): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (24): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (25): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (26): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (27): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (28): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (29): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (30): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (31): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (32): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (33): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (34): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (35): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (36): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (37): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (38): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (39): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (40): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (41): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (42): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (43): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (44): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (45): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (46): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (47): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (48): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (49): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (50): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (51): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (52): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (53): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (54): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (55): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (56): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (57): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (58): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (59): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (60): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (61): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (62): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (63): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (64): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (65): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (66): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (67): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (68): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (69): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (70): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (71): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (72): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (73): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (74): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (75): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (76): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (77): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (78): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (79): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (80): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (81): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (82): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (83): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (84): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (85): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (86): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (87): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (88): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (89): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (90): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (91): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (92): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (93): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (94): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (95): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (96): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (97): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (98): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (99): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (100): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (101): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (102): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (103): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (104): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (105): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (106): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (107): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (108): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (109): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (110): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (111): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (112): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (113): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (114): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (115): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (116): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (117): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (118): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (119): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (120): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (121): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (122): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (123): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (124): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (125): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (126): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (127): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (conv2): Conv2d(32768, 15, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (relu): ReLU()\n",
              "  (flat): Flatten(start_dim=1, end_dim=3)\n",
              "  (fc): Linear(in_features=1215, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "def get_model():\n",
        "  model = EmotionNet(HCANALS, WCANALS, NFEATURES, NTIMES_IN_SAMPLE).to(device)\n",
        "  return model\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = get_model()\n",
        "# def init_weights(m):\n",
        "#     for name, param in m.named_parameters():\n",
        "#         if 'weight' in name:\n",
        "#             nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "#         else:\n",
        "#             nn.init.constant_(param.data, 0)\n",
        "            \n",
        "# model.apply(init_weights)\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl95YfoKskTC"
      },
      "outputs": [],
      "source": [
        "files = glob.glob(os.path.join(data_dir, \"*.dat\"))\n",
        "files.sort()\n",
        "files = np.asarray(files)\n",
        "nfiles = len(files)\n",
        "koeff1 = 0.99\n",
        "# koeff2 = 0.05\n",
        "ind_train = random.sample(range(nfiles), int(nfiles * koeff1))\n",
        "ind_val = list(set(range(nfiles)) - set(ind_train))\n",
        "#ind_val = random.sample(ind, int(len(ind) * koeff2))\n",
        "# ind_test = list(set(ind) - set(ind_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvxVQ1aw1y3b"
      },
      "outputs": [],
      "source": [
        "# def normalize_data():\n",
        "#   for sub in range(32):\n",
        "#     for nvideo in range(40):\n",
        "#         for ncanal in range(NCANALS):\n",
        "#              #std = np.std(data[sub][nvideo, ncanal, :])\n",
        "#              #data[sub][nvideo, ncanal, :] = np.clip(data[sub][nvideo, ncanal, :], -3 * std, 3 * std)\n",
        "#              scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "#              data[sub][nvideo, ncanal, :] = scaler.fit_transform(data[sub][nvideo, ncanal, :].reshape(-1, 1)).reshape(1, -1)\n",
        "\n",
        "# normalize_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60uHw5tpczfW",
        "outputId": "45bae007-b2ab-4adb-f782-3532ffdc3614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[26]\n"
          ]
        }
      ],
      "source": [
        "print(ind_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ty8V6MvCzJdT"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "  def __init__(self): #(data_path, epoch, batch_siz, image_size, learning_rate, weight_deca, learning_rate, learning_rate_gamma, weight_bce, load, output_dir)\n",
        "    self.data_path = \"/content/drive/MyDrive/MADE/semester2/CV/contest02/data/\"\n",
        "    self.epochs = 2\n",
        "    self.batch_size = 100\n",
        "    self.lr= 3e-4\n",
        "    self.weight_decay= 1e-6\n",
        "    self.learning_rate=None\n",
        "    self.learning_rate_gamma=None\n",
        "    self.weight_bce=1\n",
        "    self.load=None\n",
        "    self.output_dir=\"runs/segmentation_baseline\"\n",
        "    self.data_dir =\"./data_preprocessed_python/\"# \"/content/drive/MyDrive/MADE/Project/train/physionet.org/\"\n",
        "args = Args()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhCbhL-aWheC"
      },
      "outputs": [],
      "source": [
        "type_emotion = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUuWjER6K33u",
        "outputId": "9ea2ef75-f2e5-4970-d03c-96fa5c0a96ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  2  3  5  6  7  8  9 10 12 13 14 15 16 18 20 21 22 23 24 25 26 28 30\n",
            " 31 32 33 35 36 37 38 39] [ 0  4 11 17 19 27 29 34]\n",
            "16\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "k  = 5\n",
        "labels_bin = []\n",
        "for i in range(32):\n",
        "  temp = labels[i] > 4.5\n",
        "  #print(labels[i])\n",
        "  #print(temp)\n",
        "  labels_bin.append(temp)\n",
        "X = np.arange(40)\n",
        "y = np.array(labels_bin[0][:, type_emotion])\n",
        "skf = StratifiedKFold(n_splits=k, random_state=None, shuffle=True)\n",
        "balanced_split = skf.split(X, y)\n",
        "for ind_train, ind_test in  balanced_split:\n",
        "    print(ind_train, ind_test)\n",
        "    print(sum(labels_bin[0][ind_train, type_emotion]))\n",
        "    print(sum(labels_bin[0][ind_test, type_emotion]))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2lPXmuCYbUI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# train_dataset = EmotionDataset(args.data_dir, 'train', ind_train, data, labels)\n",
        "\n",
        "# class_weights_all = [1/train_dataset.cnt[0][i] for i in range(2)]\n",
        "# weights_samples =  [0] * train_dataset.__len__()\n",
        "# for i in range(train_dataset.__len__()):\n",
        "#     i_file, index_in_file, nvideo, nsec = train_dataset.get_index_record(i)\n",
        "#     #print(train_dataset.labels[i_file][nvideo])\n",
        "#     weights_samples[i] = class_weights_all[int(train_dataset.labels[i_file][nvideo, 0])]\n",
        "\n",
        "# weighted_sampler = WeightedRandomSampler(\n",
        "#     weights=weights_samples,\n",
        "#     num_samples=len(weights_samples),\n",
        "#     replacement=True\n",
        "# )\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "#                               pin_memory=True, shuffle=False, drop_last=True, sampler=weighted_sampler)\n",
        "\n",
        "\n",
        "# val_dataset = EmotionDataset(args.data_dir, 'val', ind_test, data, labels)\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "#                               pin_memory=True, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOT0qjQSLPUy"
      },
      "outputs": [],
      "source": [
        "# train_dataset = EmotionDataset(files[ind_train])\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "#                               pin_memory=True, shuffle=True, drop_last=True)\n",
        "\n",
        "\n",
        "# val_dataset = EmotionDataset(files[ind_val])\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "#                               pin_memory=True, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lrXjgrpcgiM",
        "outputId": "30130d44-97f2-4d8e-83e4-4c453c77e994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss(reduce = 'mean')#torch.nn.MSELoss()\n",
        "#optimizer = optim.SGD(model.parameters(), lr=3e-5, momentum = 0.9)#, weight_decay=args.weight_decay)\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-5)#, momentum = 0.9)#, weight_decay=args.weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5In2kzycPvri"
      },
      "outputs": [],
      "source": [
        "# print(train_dataset.cnt)\n",
        "# print(val_dataset.cnt)\n",
        "# print(files[ind_train])\n",
        "# print(files[ind_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6WowEgaa_AU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R40YQ6CEa_SJ"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, criterion, optimizer, device, type_emotion, batch = None):\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    inputs = []\n",
        "   \n",
        "    #lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)#, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n",
        "    #for batch in tqdm(loader, total=len(loader), desc=\"training...\", position=0 , leave = True):\n",
        "    for i, batch in enumerate(loader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            src  = batch['data'].to(device)\n",
        "            #print(src.shape)\n",
        "            trg = batch['labels'][:, type_emotion]\n",
        "\n",
        "            #print(batch)\n",
        "            #print(trg.shape)\n",
        "            levels_pred = model(src)  # B x (2 * NUM_PTS)\n",
        "            #print(levels_pred.shape)\n",
        "            levels_pred = levels_pred.cpu()\n",
        "\n",
        "            #usual cross entropy\n",
        "            #output = levels_pred[:, 1:].reshape(-1, levels_pred.shape[-1])\n",
        "            #trg1 = trg[:, 1:].reshape(-1)\n",
        "            loss = criterion(levels_pred, trg) \n",
        "\n",
        "            #print(\"after\")\n",
        "            train_loss.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #break\n",
        "    return np.mean(train_loss)#, mid_outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dspQneiWa_SJ"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, criterion, device, type_emotion):\n",
        "    \n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    history = []\n",
        "  \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        #for s, batch in enumerate(tqdm(loader, total=len(loader), desc=\"validating...\", position=0 , leave = True)):\n",
        "        for s, batch in enumerate(loader):\n",
        "            src  = batch['data'].to(device)\n",
        "            #print(src.shape)\n",
        "            trg = batch['labels'][:, type_emotion]\n",
        "\n",
        "\n",
        "\n",
        "            levels_pred = model(src)  # B x (2 * NUM_PTS)\n",
        "            #print(levels_pred.shape)\n",
        "            levels_pred = levels_pred.cpu()\n",
        "\n",
        "            \n",
        "            loss = criterion(levels_pred, trg) \n",
        "\n",
        "            epoch_loss += loss.item() \n",
        "        \n",
        "    return epoch_loss / s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvSptnLBa_SK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
        "\n",
        "def calculate_predictions(model, loader, type_emotion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    history = []\n",
        "    real = []\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch in enumerate(loader):#, total=len(loader), desc=\"predicting...\", position=0 , leave = True)):\n",
        "            src  = batch['data'].to(device)\n",
        "            #print(src.shape)\n",
        "            trg = batch['labels'][:, type_emotion]\n",
        "            #print(trg)\n",
        "         \n",
        "\n",
        "            levels_pred = model(src)  # B x (2 * NUM_PTS)\n",
        "            levels_pred = levels_pred.cpu()\n",
        "            #print(levels_pred.shape)\n",
        "            trg_pred = levels_pred.argmax(1)\n",
        "            #print(levels_pred.shape)\n",
        "            \n",
        "            real.extend(trg)\n",
        "            pred.extend(trg_pred) \n",
        "\n",
        "        #print(real)\n",
        "            \n",
        "        #print(accuracy_score(real, pred)) \n",
        "        #print(confusion_matrix(real, pred))  \n",
        "        #print(classification_report(real, pred))\n",
        "        f1 = f1_score(real, pred, average = \"macro\")\n",
        "        return (accuracy_score(real, pred)) , f1\n",
        "        #plt.hist(real)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3TxflTba_SK"
      },
      "outputs": [],
      "source": [
        "def train_loop(description, type_emotion, n_epochs = 10):\n",
        "      args.epochs = n_epochs\n",
        "      #criterion =  fnn.mse_loss\n",
        "      train_loss_min = 10000\n",
        "      val_loss_min = 10000\n",
        "      acc_max = -10000\n",
        "      #batch = next(iter(train_dataloader))\n",
        "      for epoch in range(args.epochs):\n",
        "          #logger.info(f\"Starting epoch {epoch + 1}/{args.epochs}.\")\n",
        "          \n",
        "          train_loss = train(model, train_dataloader, criterion, optimizer ,device, type_emotion)\n",
        "          #if epoch % 500 == 0:\n",
        "          print(train_loss)\n",
        "\n",
        "          if (train_loss < train_loss_min):\n",
        "              train_loss_min      = train_loss\n",
        "              torch.save({\n",
        "                              'model_state_dict': model.state_dict(),\n",
        "                              'optimizer_state_dict': optimizer.state_dict(),\n",
        "                            },\n",
        "                            os.path.join(\"/content/drive/MyDrive/MADE/Project/CNN_models/\", \"train_cnn2.tgz\")\n",
        "                  )  \n",
        "\n",
        "          val_loss = evaluate(model, val_dataloader, criterion, device, type_emotion)\n",
        "          # #break\n",
        "          print(val_loss)\n",
        "          #break\n",
        "\n",
        "          acc, f1 = calculate_predictions(model, val_dataloader, type_emotion)\n",
        "          print(acc, f1)\n",
        "          if (acc > acc_max):\n",
        "              acc_max   = acc\n",
        "              torch.save({'model_state_dict': model.state_dict(),    'optimizer_state_dict': optimizer.state_dict(),}, os.path.join(\"/content/drive/MyDrive/MADE/Project/CNN_models/\", f\"val_{description}.tgz\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oabt39QsWMpL"
      },
      "source": [
        "#Результаты на датасете без лика"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyITzQ8DZlic"
      },
      "source": [
        "##Valence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vub7D3V6RD1",
        "outputId": "ae57654b-5ec2-42d7-b2ce-6ec1602374ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******0*********\n",
            "fold = 0\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.9631445396103357\n",
            "0.9748820886015892\n",
            "0.6226012793176973 0.6175309267663387\n",
            "0.3804452285954827\n",
            "3.8775350004434586\n",
            "0.47974413646055436 0.47962821492233254\n",
            "0.21482605398877672\n",
            "4.44195719063282\n",
            "0.509594882729211 0.5095748163235616\n",
            "0.08347702281255472\n",
            "4.534787341952324\n",
            "0.5223880597014925 0.5223685167672947\n",
            "0.042446476260298176\n",
            "4.560009136795998\n",
            "0.5287846481876333 0.5287846481876332\n",
            "0.021419136686936804\n",
            "4.476233780384064\n",
            "0.5245202558635395 0.5243818696935383\n",
            "0.010501139209066567\n",
            "4.36704383790493\n",
            "0.5266524520255863 0.5265469824293354\n",
            "0.006200517441979365\n",
            "4.267477065324783\n",
            "0.5309168443496801 0.5308123249299721\n",
            "0.004771270593138118\n",
            "4.193490669131279\n",
            "0.5287846481876333 0.5287075139252018\n",
            "0.0039825493126715485\n",
            "4.1364023089408875\n",
            "0.5394456289978679 0.5393430099312453\n",
            "fold = 1\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.0964468607777045\n",
            "1.385007306933403\n",
            "0.4669509594882729 0.4624321449530516\n",
            "0.4791931311943029\n",
            "2.343850299715996\n",
            "0.5735607675906184 0.5714390145838664\n",
            "0.21824482413572505\n",
            "3.038291499018669\n",
            "0.5756929637526652 0.5731781492236984\n",
            "0.0995562863536179\n",
            "3.334535777568817\n",
            "0.5607675906183369 0.5577092107672588\n",
            "0.047087995850137974\n",
            "3.2523023188114166\n",
            "0.5607675906183369 0.5563117675153385\n",
            "0.02326988079585135\n",
            "3.139558047056198\n",
            "0.5543710021321961 0.5492479111196951\n",
            "0.01413212484974218\n",
            "3.0260619670152664\n",
            "0.5607675906183369 0.5555115936694883\n",
            "0.009239692970080987\n",
            "2.9511728733778\n",
            "0.5543710021321961 0.5483839756732475\n",
            "0.005861372049701841\n",
            "2.915536195039749\n",
            "0.5607675906183369 0.5541825095057034\n",
            "0.004417318158390883\n",
            "2.885719671845436\n",
            "0.5628997867803838 0.5561111188058929\n",
            "fold = 2\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.69150773631899\n",
            "1.5479377508163452\n",
            "0.4925373134328358 0.4925165490652506\n",
            "0.6561673574982897\n",
            "2.030375100672245\n",
            "0.5970149253731343 0.5970149253731344\n",
            "0.1672246335993374\n",
            "3.6324450373649597\n",
            "0.5628997867803838 0.561336271597841\n",
            "0.07148239707672283\n",
            "3.836966887116432\n",
            "0.5479744136460555 0.5470663265306123\n",
            "0.03618467898157082\n",
            "3.695552319288254\n",
            "0.5415778251599147 0.5411689759515846\n",
            "0.018387049687781223\n",
            "3.5732636004686356\n",
            "0.5415778251599147 0.5411689759515846\n",
            "0.009971436419475236\n",
            "3.482518807053566\n",
            "0.5479744136460555 0.5475115593257363\n",
            "0.006081988410043873\n",
            "3.4163792729377747\n",
            "0.5501066098081023 0.5497053670966714\n",
            "0.004515976326442079\n",
            "3.366214394569397\n",
            "0.5479744136460555 0.5475115593257363\n",
            "0.0037913564715142314\n",
            "3.3270055651664734\n",
            "0.5479744136460555 0.54762684720099\n",
            "fold = 3\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.1623192335429944\n",
            "2.3414742052555084\n",
            "0.2878464818763326 0.28547839731426067\n",
            "0.524945099887095\n",
            "3.9950279891490936\n",
            "0.4562899786780384 0.4540561761335884\n",
            "0.20504656980598443\n",
            "5.970847189426422\n",
            "0.4115138592750533 0.40925520262869663\n",
            "0.11128533024978089\n",
            "6.058726608753204\n",
            "0.39658848614072495 0.3947283215906241\n",
            "0.061640320382522124\n",
            "5.4995375871658325\n",
            "0.4093816631130064 0.406261282877448\n",
            "0.03461640998476038\n",
            "5.011050760746002\n",
            "0.417910447761194 0.41364529380246473\n",
            "0.019540967689336913\n",
            "4.653491169214249\n",
            "0.4136460554371002 0.4079506070830177\n",
            "0.010759284928146946\n",
            "4.443647503852844\n",
            "0.42217484008528783 0.4170439169819975\n",
            "0.006223570984347086\n",
            "4.348227262496948\n",
            "0.42430703624733473 0.4189578591880185\n",
            "0.004520551019691323\n",
            "4.303351163864136\n",
            "0.42643923240938164 0.42134617589725953\n",
            "fold = 4\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.6519804847867867\n",
            "1.2871297597885132\n",
            "0.5181236673773987 0.5179461524467892\n",
            "0.37927783251200853\n",
            "2.633579730987549\n",
            "0.5287846481876333 0.528089529541926\n",
            "0.16698560233865128\n",
            "3.4054020047187805\n",
            "0.5735607675906184 0.5735122944856685\n",
            "0.07820816827006638\n",
            "3.5318933725357056\n",
            "0.579957356076759 0.5796821901854724\n",
            "0.03491065741859769\n",
            "3.498821511864662\n",
            "0.5842217484008528 0.5839493760719143\n",
            "0.01583649693547111\n",
            "3.4711896926164627\n",
            "0.5756929637526652 0.5754150042990305\n",
            "0.0075590694568267\n",
            "3.4563055336475372\n",
            "0.5714285714285714 0.5711478184125887\n",
            "0.004624082712995771\n",
            "3.4397606402635574\n",
            "0.5692963752665245 0.5689652034650943\n",
            "0.003682938428889764\n",
            "3.4314766824245453\n",
            "0.5671641791044776 0.5667781493868449\n",
            "0.003125398254365121\n",
            "3.4244122952222824\n",
            "0.5692963752665245 0.5688553536971639\n",
            "*******1*********\n",
            "fold = 0\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "5.601237943297939\n",
            "1.2411586493253708\n",
            "0.55863539445629 0.5181148090239\n",
            "2.2220932441322425\n",
            "2.153695911169052\n",
            "0.603411513859275 0.5816355893186003\n",
            "1.3038774595448845\n",
            "3.636193409562111\n",
            "0.5884861407249466 0.5429750021458469\n",
            "0.9791312978455895\n",
            "3.11637744307518\n",
            "0.652452025586354 0.6162780775505082\n",
            "0.6013877458478275\n",
            "2.704303488135338\n",
            "0.6162046908315565 0.5815322996391323\n",
            "0.3417756549621883\n",
            "3.1216868609189987\n",
            "0.6226012793176973 0.5756523961661342\n",
            "0.2704370464933546\n",
            "2.518908202648163\n",
            "0.6140724946695096 0.5808716432059328\n",
            "0.1893320703192761\n",
            "2.4763429313898087\n",
            "0.6204690831556503 0.5752676136594896\n",
            "0.14915185225637337\n",
            "2.3559327572584152\n",
            "0.6140724946695096 0.5713910641885922\n",
            "0.11126714552703657\n",
            "2.2945846170186996\n",
            "0.6183368869936035 0.5748476914428671\n",
            "fold = 1\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "4.597741828153008\n",
            "1.4746759086847305\n",
            "0.5010660980810234 0.5010638297872341\n",
            "1.8490967225087316\n",
            "1.9934234768152237\n",
            "0.5628997867803838 0.5517402149334453\n",
            "1.2842795715520257\n",
            "5.384082078933716\n",
            "0.48187633262260127 0.480932406028393\n",
            "0.6133061200380325\n",
            "4.014359191060066\n",
            "0.5671641791044776 0.5645988155397526\n",
            "0.43269297676651103\n",
            "3.793519765138626\n",
            "0.42857142857142855 0.4217335296282665\n",
            "0.23894290096665682\n",
            "4.295110195875168\n",
            "0.47334754797441364 0.4731080091512365\n",
            "0.19199306027669655\n",
            "3.4684098064899445\n",
            "0.48187633262260127 0.47591982010567413\n",
            "0.13672579942565216\n",
            "3.4569102823734283\n",
            "0.4562899786780384 0.451894389015431\n",
            "0.11159004035748933\n",
            "3.430386930704117\n",
            "0.4520255863539446 0.4480104047884008\n",
            "0.0882944168620988\n",
            "3.3184371292591095\n",
            "0.47334754797441364 0.4702261450163492\n",
            "fold = 2\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "4.248066174356561\n",
            "2.2330875247716904\n",
            "0.32409381663113007 0.31359621786081987\n",
            "2.3698159268027856\n",
            "3.137300878763199\n",
            "0.44136460554371004 0.41069099140577037\n",
            "1.4849761065683866\n",
            "4.276541590690613\n",
            "0.47547974413646055 0.4752865199199564\n",
            "0.7091609968950874\n",
            "5.386355996131897\n",
            "0.44562899786780386 0.4074829931972789\n",
            "0.5557701430822674\n",
            "3.4924465715885162\n",
            "0.5010660980810234 0.49827188940092165\n",
            "0.42194686712403046\n",
            "3.4529527127742767\n",
            "0.4946695095948827 0.4824725180070491\n",
            "0.21478200547005\n",
            "3.676923543214798\n",
            "0.44349680170575695 0.4180892482779275\n",
            "0.15225073067765488\n",
            "3.06400728225708\n",
            "0.4946695095948827 0.4831559418025584\n",
            "0.11205035899030535\n",
            "2.9063409864902496\n",
            "0.488272921108742 0.4755674829475568\n",
            "0.10342222452163696\n",
            "3.0130923092365265\n",
            "0.44776119402985076 0.4236114735818169\n",
            "fold = 3\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "4.027439227229671\n",
            "1.6846050471067429\n",
            "0.3816631130063966 0.3804209183673469\n",
            "2.2182939978022325\n",
            "2.5366190373897552\n",
            "0.535181236673774 0.5248977695167286\n",
            "1.4493096243394048\n",
            "4.855230629444122\n",
            "0.464818763326226 0.46466300131425164\n",
            "1.1449325986598666\n",
            "3.8753464818000793\n",
            "0.464818763326226 0.45591395861546213\n",
            "0.559126050456574\n",
            "2.873195320367813\n",
            "0.5266524520255863 0.5242973061880916\n",
            "0.3547744158851473\n",
            "3.143904149532318\n",
            "0.47547974413646055 0.4714403518416712\n",
            "0.24685691473515411\n",
            "2.6419045627117157\n",
            "0.4925373134328358 0.4849293070988224\n",
            "0.1715768435479779\n",
            "2.4608846455812454\n",
            "0.5202558635394456 0.5138105001267018\n",
            "0.11846003857882399\n",
            "2.297508269548416\n",
            "0.5330490405117271 0.5267755534566564\n",
            "0.1023623977150572\n",
            "2.1746338307857513\n",
            "0.5330490405117271 0.5289026487788098\n",
            "fold = 4\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.873940496068252\n",
            "1.763317197561264\n",
            "0.2515991471215352 0.25093167701863356\n",
            "1.4937698378374702\n",
            "3.769292801618576\n",
            "0.43070362473347545 0.4300402812862702\n",
            "1.1672277717213881\n",
            "6.686974883079529\n",
            "0.3795309168443497 0.37451477334702127\n",
            "0.9109906491480375\n",
            "5.3874741196632385\n",
            "0.44989339019189767 0.44478195433521767\n",
            "0.7118265087667265\n",
            "5.509164214134216\n",
            "0.39445628997867804 0.39273078746762957\n",
            "0.42840921094543055\n",
            "5.08841860294342\n",
            "0.4520255863539446 0.45033632031374693\n",
            "0.2708212829342014\n",
            "4.913193047046661\n",
            "0.42857142857142855 0.42836092414044025\n",
            "0.1646528661643204\n",
            "4.348954439163208\n",
            "0.4349680170575693 0.4329468876752579\n",
            "0.13424962651180594\n",
            "3.9130387902259827\n",
            "0.44349680170575695 0.44313224181933153\n",
            "0.1009827765979265\n",
            "3.8174357414245605\n",
            "0.43923240938166314 0.43799578087908986\n",
            "*******2*********\n",
            "fold = 0\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.6170607146463896\n",
            "1.3765807151794434\n",
            "0.44136460554371004 0.4310992999740731\n",
            "0.7716743308854731\n",
            "2.443906217813492\n",
            "0.4968017057569296 0.4040789076969462\n",
            "0.3283287333814721\n",
            "2.4556518644094467\n",
            "0.5607675906183369 0.498723642702972\n",
            "0.1391117029676312\n",
            "2.5466346740722656\n",
            "0.5650319829424307 0.5282248520710059\n",
            "0.07603701645214307\n",
            "2.566467761993408\n",
            "0.5437100213219617 0.512312925170068\n",
            "0.044308077666516364\n",
            "2.4413178116083145\n",
            "0.5522388059701493 0.5214285714285715\n",
            "0.029635012970845167\n",
            "2.3699484765529633\n",
            "0.5501066098081023 0.5197027718322437\n",
            "0.02130765809775575\n",
            "2.3447355180978775\n",
            "0.5501066098081023 0.5197027718322437\n",
            "0.017091280952292055\n",
            "2.278777092695236\n",
            "0.5501066098081023 0.5197027718322437\n",
            "0.014215042545019011\n",
            "2.2348091155290604\n",
            "0.5565031982942431 0.5270710518150792\n",
            "fold = 1\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.2544623393761483\n",
            "1.1115515381097794\n",
            "0.5970149253731343 0.4182172603225235\n",
            "0.8932084143161774\n",
            "2.8530311584472656\n",
            "0.535181236673774 0.3684086978008401\n",
            "0.31776271446755056\n",
            "3.796596646308899\n",
            "0.5394456289978679 0.37789240972733973\n",
            "0.16119695101913653\n",
            "3.760255753993988\n",
            "0.5501066098081023 0.37153326855538826\n",
            "0.08382850836374257\n",
            "3.433374673128128\n",
            "0.5543710021321961 0.38523628837530177\n",
            "0.04570688321990402\n",
            "3.208854526281357\n",
            "0.5565031982942431 0.38628013488348684\n",
            "0.025973811990728502\n",
            "3.0587131679058075\n",
            "0.5628997867803838 0.3854861080041161\n",
            "0.01773995131646332\n",
            "2.976917326450348\n",
            "0.5628997867803838 0.3854861080041161\n",
            "0.013469550660566279\n",
            "2.918830305337906\n",
            "0.5692963752665245 0.3844664483601019\n",
            "0.011245486939227894\n",
            "2.8558861017227173\n",
            "0.5714285714285714 0.38545734271204785\n",
            "fold = 2\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.454991644934604\n",
            "1.0518442541360855\n",
            "0.6076759061833689 0.564935064935065\n",
            "0.6850665748903626\n",
            "2.1810240745544434\n",
            "0.5628997867803838 0.5130937248368033\n",
            "0.38679875747153636\n",
            "2.7969878911972046\n",
            "0.5714285714285714 0.5240309607840167\n",
            "0.1595403580485206\n",
            "2.412774085998535\n",
            "0.5863539445628998 0.5412902315076228\n",
            "0.07543109450489283\n",
            "2.1318353414535522\n",
            "0.6012793176972282 0.5409685911829207\n",
            "0.04372884362543884\n",
            "2.0263527631759644\n",
            "0.6076759061833689 0.5507101503602816\n",
            "0.02719502499032962\n",
            "1.9768432080745697\n",
            "0.6098081023454158 0.5491734820907987\n",
            "0.01918902821642788\n",
            "1.9397872686386108\n",
            "0.605543710021322 0.5442464163212993\n",
            "0.01479762101447896\n",
            "1.9139287173748016\n",
            "0.6012793176972282 0.5393193505517999\n",
            "0.012110913294906678\n",
            "1.9010226726531982\n",
            "0.5991471215351812 0.5360149869495664\n",
            "fold = 3\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.4659735780013237\n",
            "1.3000359386205673\n",
            "0.5479744136460555 0.4688675213675213\n",
            "0.7953110360785535\n",
            "2.674150586128235\n",
            "0.511727078891258 0.4437054877890866\n",
            "0.32548442522161886\n",
            "3.466311812400818\n",
            "0.511727078891258 0.439852506297689\n",
            "0.15483292035366358\n",
            "3.7156978845596313\n",
            "0.5181236673773987 0.4422307821840532\n",
            "0.07851240725109451\n",
            "3.5229505002498627\n",
            "0.5138592750533049 0.43932466442953017\n",
            "0.0454602874815464\n",
            "3.3211870789527893\n",
            "0.5138592750533049 0.43932466442953017\n",
            "0.02759996605546851\n",
            "3.181901127099991\n",
            "0.5138592750533049 0.4372947714069209\n",
            "0.019234033865167907\n",
            "3.135879546403885\n",
            "0.5053304904051172 0.4315151515151515\n",
            "0.01538976661762909\n",
            "3.070772409439087\n",
            "0.4946695095948827 0.4222967178607625\n",
            "0.013009325196770461\n",
            "3.0383664667606354\n",
            "0.4946695095948827 0.4182329203762149\n",
            "fold = 4\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.0582511174051383\n",
            "1.259383201599121\n",
            "0.5053304904051172 0.5043367346938775\n",
            "0.8188576915938603\n",
            "2.520901322364807\n",
            "0.4690831556503198 0.468928634769915\n",
            "0.37320996820926666\n",
            "3.383747488260269\n",
            "0.5330490405117271 0.532913136604865\n",
            "0.19276966801599452\n",
            "3.486653968691826\n",
            "0.5138592750533049 0.5138393831381393\n",
            "0.10374348468490337\n",
            "3.0119626373052597\n",
            "0.5181236673773987 0.5179461524467891\n",
            "0.061456871856200065\n",
            "2.7633794248104095\n",
            "0.5266524520255863 0.5264780789521557\n",
            "0.03944015831343437\n",
            "2.5602177381515503\n",
            "0.535181236673774 0.5348238334425275\n",
            "0.027219483726903013\n",
            "2.4790785014629364\n",
            "0.5479744136460555 0.5470663265306122\n",
            "0.019303905336480392\n",
            "2.399041533470154\n",
            "0.5458422174840085 0.5451722615042093\n",
            "0.015030135106491415\n",
            "2.346573159098625\n",
            "0.5437100213219617 0.542959927140255\n",
            "*******3*********\n",
            "fold = 0\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.113272124215176\n",
            "1.5366996228694916\n",
            "0.40298507462686567 0.3661917448550137\n",
            "0.3675379667823252\n",
            "2.634778931736946\n",
            "0.4989339019189765 0.4514401469263427\n",
            "0.17306063706545452\n",
            "3.724767506122589\n",
            "0.4840085287846482 0.43112193752756733\n",
            "0.060697398133159275\n",
            "3.892656408250332\n",
            "0.47974413646055436 0.4296451355661882\n",
            "0.028003077519028204\n",
            "3.7242680862545967\n",
            "0.488272921108742 0.4463899272083415\n",
            "0.011186080678415141\n",
            "3.5860598757863045\n",
            "0.488272921108742 0.4463899272083415\n",
            "0.005492946047237829\n",
            "3.534482389688492\n",
            "0.4861407249466951 0.44478501991875313\n",
            "0.004125533444733408\n",
            "3.5146748274564743\n",
            "0.48187633262260127 0.44157091407991766\n",
            "0.0034487345072097683\n",
            "3.4982462897896767\n",
            "0.4840085287846482 0.4417765099350777\n",
            "0.0030582572186463757\n",
            "3.4818457514047623\n",
            "0.4840085287846482 0.4431786961811688\n",
            "fold = 1\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.2227821350097656\n",
            "1.6006534099578857\n",
            "0.39658848614072495 0.3941094033168844\n",
            "0.3549089874876173\n",
            "3.809374362230301\n",
            "0.4349680170575693 0.4316191434385933\n",
            "0.18304043890614258\n",
            "5.294524431228638\n",
            "0.44989339019189767 0.44565695437053326\n",
            "0.08001355518047747\n",
            "5.700900077819824\n",
            "0.43070362473347545 0.4256484348125215\n",
            "0.03379843511471623\n",
            "5.76861435174942\n",
            "0.4093816631130064 0.4046068461069584\n",
            "0.016367631394563143\n",
            "5.7116774916648865\n",
            "0.4072494669509595 0.4026846252519699\n",
            "0.010555265887983535\n",
            "5.591358125209808\n",
            "0.4136460554371002 0.40934965492922276\n",
            "0.007246566231754657\n",
            "5.494606912136078\n",
            "0.4093816631130064 0.40547874993707583\n",
            "0.004737408310910196\n",
            "5.429895639419556\n",
            "0.4115138592750533 0.40741622413477385\n",
            "0.0038443843000813536\n",
            "5.381757378578186\n",
            "0.40298507462686567 0.39882805347006045\n",
            "fold = 2\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.304192757920215\n",
            "1.4442470967769623\n",
            "0.40085287846481876 0.39503316578301084\n",
            "0.3407802938630706\n",
            "4.367343246936798\n",
            "0.34328358208955223 0.34304165908677464\n",
            "0.1887062480183024\n",
            "6.260445833206177\n",
            "0.3411513859275053 0.3394215648289536\n",
            "0.09072150465248055\n",
            "6.369987487792969\n",
            "0.34754797441364604 0.34537841191067\n",
            "0.04422912568981318\n",
            "6.107135117053986\n",
            "0.35607675906183367 0.3532511415525114\n",
            "0.01881903655042774\n",
            "5.896531701087952\n",
            "0.3603411513859275 0.3585184374658059\n",
            "0.007657864596694708\n",
            "5.767526030540466\n",
            "0.3624733475479744 0.3610674467028436\n",
            "0.004919759095891526\n",
            "5.689661800861359\n",
            "0.3582089552238806 0.3567936503597188\n",
            "0.003928468011221604\n",
            "5.62760329246521\n",
            "0.3624733475479744 0.36131189054522433\n",
            "0.0033606163005491622\n",
            "5.571948289871216\n",
            "0.36673773987206826 0.3655840518124803\n",
            "fold = 3\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.4457641777239347\n",
            "1.117598995566368\n",
            "0.5159914712153518 0.48993651934363397\n",
            "0.4169791113389166\n",
            "1.9447020888328552\n",
            "0.5501066098081023 0.5185905886817052\n",
            "0.1821666165304027\n",
            "2.4896034002304077\n",
            "0.5522388059701493 0.5246438086412604\n",
            "0.09344141040683578\n",
            "2.53997266292572\n",
            "0.5628997867803838 0.5374553186985533\n",
            "0.04635052314322246\n",
            "2.488927960395813\n",
            "0.5671641791044776 0.540987479329081\n",
            "0.02245528477636215\n",
            "2.4557173252105713\n",
            "0.55863539445629 0.5319428976409841\n",
            "0.011997143431615672\n",
            "2.4495362043380737\n",
            "0.5565031982942431 0.5281324974847148\n",
            "0.007777622226919783\n",
            "2.4598817229270935\n",
            "0.55863539445629 0.528807932555803\n",
            "0.0061374499683121315\n",
            "2.4662148356437683\n",
            "0.5543710021321961 0.5242553521940234\n",
            "0.005220503815890927\n",
            "2.4680537581443787\n",
            "0.5522388059701493 0.5203097603740502\n",
            "fold = 4\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.478253813166367\n",
            "1.1849631071090698\n",
            "0.5074626865671642 0.46914765906362543\n",
            "0.40427473254844937\n",
            "2.0898534655570984\n",
            "0.535181236673774 0.5031972789115646\n",
            "0.18644803713418936\n",
            "3.2463594675064087\n",
            "0.488272921108742 0.4633867276887872\n",
            "0.07386985788808058\n",
            "3.7695998549461365\n",
            "0.464818763326226 0.4434010884315144\n",
            "0.03160703416276527\n",
            "3.90645295381546\n",
            "0.4520255863539446 0.43009593516692907\n",
            "0.015017678777344133\n",
            "3.9326620399951935\n",
            "0.44136460554371004 0.419510582010582\n",
            "0.0083984958473593\n",
            "3.9397903084754944\n",
            "0.42857142857142855 0.40916441034897716\n",
            "0.006142377491893345\n",
            "3.9371635615825653\n",
            "0.42430703624733473 0.40379110324306\n",
            "0.005043084800586496\n",
            "3.9294823110103607\n",
            "0.42430703624733473 0.4028013582342954\n",
            "0.004350077268961621\n",
            "3.919601798057556\n",
            "0.42857142857142855 0.4072250518770043\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "#def get_mertics_per_subject():\n",
        "k  = 5\n",
        "type_emotion = 0\n",
        "acc_all = []\n",
        "f1_all = []\n",
        "\n",
        "for sub in range(0, 4):\n",
        "    print(f\"*******{sub}*********\")\n",
        "\n",
        "    args.batch_size = 100\n",
        "    X = np.arange(40)\n",
        "    y = np.array(labels_bin[sub][:, type_emotion])\n",
        "    \n",
        "\n",
        "    skf = StratifiedKFold(n_splits=k, random_state=None, shuffle=True)\n",
        "    balanced_split = skf.split(X, y)\n",
        "    acc_sub = []\n",
        "    f1_sub = []\n",
        "   \n",
        "    for fold,  (ind_train, ind_test) in  enumerate(balanced_split):\n",
        "        inds_train = []\n",
        "        inds_test = []\n",
        "        inds_train.append(ind_train)\n",
        "        inds_test.append(ind_test)\n",
        "        print(f\"fold = {fold}\")\n",
        "       \n",
        "        train_dataset = EmotionDataset(args.data_dir, 'train', ind_train, data[sub : sub + 1], labels[sub : sub + 1])\n",
        "\n",
        "#     class_weights_all = [1/train_dataset.cnt[0][i] for i in range(2)]\n",
        "# weights_samples =  [0] * train_dataset.__len__()\n",
        "# for i in range(train_dataset.__len__()):\n",
        "#     i_file, index_in_file, nvideo, nsec = train_dataset.get_index_record(i)\n",
        "#     #print(train_dataset.labels[i_file][nvideo])\n",
        "#     weights_samples[i] = class_weights_all[int(train_dataset.labels[i_file][nvideo, 0])]\n",
        "\n",
        "# weighted_sampler = WeightedRandomSampler(\n",
        "#     weights=weights_samples,\n",
        "#     num_samples=len(weights_samples),\n",
        "#     replacement=True\n",
        "# )\n",
        "    #train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "    #                          pin_memory=True, shuffle=False, drop_last=True, sampler=weighted_sampler)\n",
        "\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "                              pin_memory=True, shuffle=False, drop_last=True)\n",
        " \n",
        "        val_dataset = EmotionDataset(args.data_dir, 'val', ind_test, data[sub : sub + 1], labels[sub : sub + 1])\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "                              pin_memory=True, shuffle=False, drop_last=False)\n",
        "        device  = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = get_model()\n",
        "        model.apply(initialize_weights)\n",
        "        criterion = nn.CrossEntropyLoss(reduction = 'mean')#torch.nn.MSELoss()\n",
        "        #optimizer = optim.SGD(model.parameters(), lr=3e-5, momentum = 0.9)#, weight_decay=args.weight_decay)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
        "        description = f'val_cnn2_noleak_result_{sub}_{fold}_relu'\n",
        "        train_loop(description, 0, 10)\n",
        "        model_state  = torch.load(os.path.join(\"/content/drive/MyDrive/MADE/Project/CNN_models/\", f\"val_{description}.tgz\"))\n",
        "        #   #model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device)\n",
        "        model.load_state_dict(model_state['model_state_dict'])\n",
        "        acc, f1 = calculate_predictions(model, val_dataloader, type_emotion)\n",
        "        #print(f\"f1 = {f1} acc = {acc}\")\n",
        "        acc_sub.append(acc)\n",
        "        f1_sub.append(f1)\n",
        "        #print(acc, f1)\n",
        "    acc_all.append(acc_sub)     \n",
        "    f1_all.append(f1_sub)     \n",
        "    pd.DataFrame(f1_all).to_csv(\"f1_val_cnn2_noleak_result2.csv\")\n",
        "    pd.DataFrame(acc_all).to_csv(\"acc_val_cnn2_noleak_result2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT3fMeQRWIts"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(f1_all).to_csv(\"f1_val_cnn2_noleak_result.csv\")\n",
        "pd.DataFrame(acc_all).to_csv(\"acc_val_cnn2_noleak_result.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojV6ZfV7WSnH"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(f1_all).to_csv(\"f1_val_cnn2_noleak_result2.csv\")\n",
        "pd.DataFrame(acc_all).to_csv(\"acc_val_cnn2_noleak_result2.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhwLelSeZ3QO"
      },
      "source": [
        "##Arousal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Titf9cC5Z2a4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVNuVykgZ5U8",
        "outputId": "9710b3e4-c273-4d2c-d2a7-36ddb70ee514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*******26*********\n",
            "fold = 0\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "4.240310789723146\n",
            "2.7105812840163708\n",
            "0.39232409381663114 0.3841599668271557\n",
            "2.1409063433345996\n",
            "4.552056014537811\n",
            "0.37100213219616207 0.36317356863070005\n",
            "1.3158138025748103\n",
            "7.7657740116119385\n",
            "0.3752665245202559 0.3601875433589258\n",
            "0.6485314812315138\n",
            "7.477760910987854\n",
            "0.3603411513859275 0.3485869847031372\n",
            "0.33773029321118403\n",
            "7.198613882064819\n",
            "0.3837953091684435 0.3735423666927034\n",
            "0.1577831795929294\n",
            "5.836229205131531\n",
            "0.4072494669509595 0.40312213880241715\n",
            "0.10106765478849411\n",
            "5.693019211292267\n",
            "0.3880597014925373 0.38102464349929416\n",
            "0.07071119380232535\n",
            "5.417939484119415\n",
            "0.39232409381663114 0.3841599668271557\n",
            "0.050307512038240305\n",
            "5.143759846687317\n",
            "0.39445628997867804 0.3860124645056606\n",
            "0.03744197886829313\n",
            "5.0069350600242615\n",
            "0.3880597014925373 0.38044343795596924\n",
            "fold = 1\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "5.561457991600037\n",
            "2.5289024114608765\n",
            "0.4200426439232409 0.42001891321742924\n",
            "2.345058897608205\n",
            "3.294526904821396\n",
            "0.47334754797441364 0.46573042776432605\n",
            "0.8609969157137369\n",
            "4.413986086845398\n",
            "0.47547974413646055 0.463176996091569\n",
            "0.3405512657014984\n",
            "2.9407206177711487\n",
            "0.5309168443496801 0.5228449870514243\n",
            "0.17577682865942879\n",
            "3.709627389907837\n",
            "0.4605543710021322 0.4496556202314418\n",
            "0.10778166841421473\n",
            "3.05524480342865\n",
            "0.5010660980810234 0.4906716417910447\n",
            "0.06667916670343593\n",
            "3.264461785554886\n",
            "0.47121535181236673 0.4627124907612713\n",
            "0.04314768704046544\n",
            "3.072500079870224\n",
            "0.4946695095948827 0.4868211471073007\n",
            "0.0300054313541439\n",
            "3.061396211385727\n",
            "0.4904051172707889 0.48249052387613867\n",
            "0.02175449562798205\n",
            "2.9993873834609985\n",
            "0.488272921108742 0.4806009819483924\n",
            "fold = 2\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "4.542156646126195\n",
            "1.0924434214830399\n",
            "0.6247334754797441 0.6242397756655377\n",
            "1.5417831132286473\n",
            "2.7886133641004562\n",
            "0.535181236673774 0.5331415525114156\n",
            "0.7210088123224283\n",
            "3.2672764509916306\n",
            "0.5330490405117271 0.5257967561877589\n",
            "0.41180362194580467\n",
            "3.724393367767334\n",
            "0.5330490405117271 0.5321983412354654\n",
            "0.29982996575142207\n",
            "3.5627608448266983\n",
            "0.5671641791044776 0.5643039214340303\n",
            "0.13113764604847683\n",
            "3.7193721532821655\n",
            "0.5074626865671642 0.5059443190368699\n",
            "0.08039383495863724\n",
            "3.4291579127311707\n",
            "0.5373134328358209 0.5339231822532413\n",
            "0.04642524269997681\n",
            "3.5328246653079987\n",
            "0.5309168443496801 0.5288584474885845\n",
            "0.0370203666266446\n",
            "3.3356591165065765\n",
            "0.5394456289978679 0.5362387841054752\n",
            "0.02777070674653116\n",
            "3.393428236246109\n",
            "0.535181236673774 0.5319446987731185\n",
            "fold = 3\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "4.682681011526208\n",
            "1.334231786429882\n",
            "0.5138592750533049 0.500392464678179\n",
            "1.0535846901567358\n",
            "1.9122579395771027\n",
            "0.6162046908315565 0.611969111969112\n",
            "1.1391317734592838\n",
            "3.451575070619583\n",
            "0.5330490405117271 0.5308650433686403\n",
            "0.45466763570316526\n",
            "3.9028100669384003\n",
            "0.47761194029850745 0.476660244761137\n",
            "0.22966745936949\n",
            "2.650544062256813\n",
            "0.5778251599147122 0.577777171540812\n",
            "0.13526769506892092\n",
            "2.4587103873491287\n",
            "0.5778251599147122 0.5771311475409835\n",
            "0.08528608936620385\n",
            "2.3536880537867546\n",
            "0.5927505330490405 0.5908457684173987\n",
            "0.061931698583066463\n",
            "2.303012430667877\n",
            "0.582089552238806 0.5802557077625571\n",
            "0.04203714427881335\n",
            "2.2454610243439674\n",
            "0.5948827292110874 0.5920618934261124\n",
            "0.03230223513061279\n",
            "2.2615736797451973\n",
            "0.5842217484008528 0.5817574829076442\n",
            "fold = 4\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.697053146597586\n",
            "1.7588579952716827\n",
            "0.48187633262260127 0.47845247738162255\n",
            "1.4860973209142685\n",
            "3.3797666132450104\n",
            "0.3582089552238806 0.34958649128061003\n",
            "0.6016863200225329\n",
            "2.76408714056015\n",
            "0.48187633262260127 0.478079876901095\n",
            "0.3807853948030817\n",
            "4.725340962409973\n",
            "0.35181236673773986 0.349656984381842\n",
            "0.1445630871641793\n",
            "3.167331725358963\n",
            "0.4605543710021322 0.44354403785459373\n",
            "0.08629287058781636\n",
            "3.6003327071666718\n",
            "0.3859275053304904 0.373901435087329\n",
            "0.05051968707457969\n",
            "3.285565495491028\n",
            "0.417910447761194 0.4004663772879879\n",
            "0.0341243611060475\n",
            "3.336594879627228\n",
            "0.39658848614072495 0.3785054387271084\n",
            "0.02577383884865987\n",
            "3.1875732243061066\n",
            "0.4115138592750533 0.39342080599812557\n",
            "0.02032901248649547\n",
            "3.1767175495624542\n",
            "0.4115138592750533 0.39342080599812557\n",
            "*******27*********\n",
            "fold = 0\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.326442080108743\n",
            "1.8955285251140594\n",
            "0.4072494669509595 0.4055604187183135\n",
            "1.3239799786457105\n",
            "4.5523741990327835\n",
            "0.42857142857142855 0.4274234693877551\n",
            "0.38032056548093496\n",
            "3.408370852470398\n",
            "0.5223880597014925 0.5091575091575091\n",
            "0.13057039776130727\n",
            "3.716598004102707\n",
            "0.47334754797441364 0.46573042776432605\n",
            "0.07323746206729036\n",
            "4.037545949220657\n",
            "0.44136460554371004 0.4335748792270532\n",
            "0.03970119214959835\n",
            "3.9953476786613464\n",
            "0.43923240938166314 0.4311218724778047\n",
            "0.023161866996241242\n",
            "4.067340046167374\n",
            "0.4349680170575693 0.4267958030669895\n",
            "0.014474663405532115\n",
            "4.068735122680664\n",
            "0.43283582089552236 0.42307621161672215\n",
            "0.01017287007140878\n",
            "4.085349082946777\n",
            "0.42857142857142855 0.4187384387717351\n",
            "0.007929678834778698\n",
            "4.125927895307541\n",
            "0.42643923240938164 0.4155560188080513\n",
            "fold = 1\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.894544814762316\n",
            "1.7075422406196594\n",
            "0.39872068230277186 0.3977322404371585\n",
            "0.9456672490035233\n",
            "3.023310959339142\n",
            "0.5053304904051172 0.5015209822246656\n",
            "0.29169046623926415\n",
            "4.641359776258469\n",
            "0.4157782515991471 0.4156480774127833\n",
            "0.14782020758445324\n",
            "4.1899469792842865\n",
            "0.417910447761194 0.41786810338948377\n",
            "0.0805351604756556\n",
            "4.330411672592163\n",
            "0.39872068230277186 0.39871794871794874\n",
            "0.04536495704546963\n",
            "4.281087279319763\n",
            "0.39232409381663114 0.3922798881538566\n",
            "0.027608964102048623\n",
            "4.31469851732254\n",
            "0.39019189765458423 0.38985625909752547\n",
            "0.017981237560314566\n",
            "4.230436563491821\n",
            "0.39445628997867804 0.3941229985443959\n",
            "0.012452095992078907\n",
            "4.202839374542236\n",
            "0.39232409381663114 0.39192601118202863\n",
            "0.009767584478188502\n",
            "4.163004159927368\n",
            "0.39232409381663114 0.3917821309125657\n",
            "fold = 2\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.7787879203495227\n",
            "1.18935227394104\n",
            "0.5159914712153518 0.5140029489502924\n",
            "1.2739901911271245\n",
            "3.227736532688141\n",
            "0.417910447761194 0.4163821592178134\n",
            "0.3089029290958455\n",
            "3.895249605178833\n",
            "0.4669509594882729 0.46490507484483384\n",
            "0.165110105256501\n",
            "3.942557066679001\n",
            "0.4904051172707889 0.4903217005797431\n",
            "0.07860641073631613\n",
            "3.652281314134598\n",
            "0.5159914712153518 0.5159826693399164\n",
            "0.04189788089378884\n",
            "3.5344214141368866\n",
            "0.5159914712153518 0.5159826693399164\n",
            "0.026997069730178305\n",
            "3.448597639799118\n",
            "0.511727078891258 0.5117181994662593\n",
            "0.01803000455134009\n",
            "3.42449289560318\n",
            "0.5053304904051172 0.5053102495089838\n",
            "0.012974515557289124\n",
            "3.430969715118408\n",
            "0.4968017057569296 0.496689584924879\n",
            "0.009993916928866193\n",
            "3.4321511685848236\n",
            "0.4904051172707889 0.49025680204823163\n",
            "fold = 3\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.799583574658946\n",
            "1.1806691884994507\n",
            "0.5330490405117271 0.5160095562560963\n",
            "1.1493007615208626\n",
            "3.02467180788517\n",
            "0.43923240938166314 0.41139165000453337\n",
            "0.37692220464937\n",
            "3.3572994470596313\n",
            "0.5309168443496801 0.5142001581980489\n",
            "0.18005412503292686\n",
            "3.225638657808304\n",
            "0.5501066098081023 0.5249139449920066\n",
            "0.09919696124760728\n",
            "3.353373035788536\n",
            "0.5266524520255863 0.5072783372454002\n",
            "0.05090751704808913\n",
            "3.2848339080810547\n",
            "0.5223880597014925 0.5053674338016498\n",
            "0.027386878617107868\n",
            "3.214440196752548\n",
            "0.5181236673773987 0.5025437410828265\n",
            "0.016634080117862476\n",
            "3.2173041254281998\n",
            "0.509594882729211 0.49451733833177136\n",
            "0.011415905968629216\n",
            "3.1885661482810974\n",
            "0.5053304904051172 0.488530385078219\n",
            "0.008909308510881505\n",
            "3.1629069596529007\n",
            "0.509594882729211 0.49451733833177136\n",
            "fold = 4\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "2.9406866776315788\n",
            "1.6328200697898865\n",
            "0.34968017057569295 0.34767539959413546\n",
            "0.9236102380642766\n",
            "2.8740859031677246\n",
            "0.4520255863539446 0.45138708723060467\n",
            "0.33961641317919683\n",
            "4.6213891208171844\n",
            "0.43283582089552236 0.4320896609490513\n",
            "0.1634171474725008\n",
            "4.101272404193878\n",
            "0.44989339019189767 0.4497708174178763\n",
            "0.09366896964217487\n",
            "3.9770749509334564\n",
            "0.43070362473347545 0.43033068416000586\n",
            "0.048164716235509046\n",
            "3.884534001350403\n",
            "0.43070362473347545 0.43004028128627025\n",
            "0.026169910879903717\n",
            "3.6877414286136627\n",
            "0.43070362473347545 0.43004028128627025\n",
            "0.016809591557830572\n",
            "3.6198885440826416\n",
            "0.43923240938166314 0.43857900366400404\n",
            "0.011879379101293651\n",
            "3.557629704475403\n",
            "0.43923240938166314 0.43857900366400404\n",
            "0.009539085097218814\n",
            "3.542308986186981\n",
            "0.43923240938166314 0.43857900366400404\n",
            "*******28*********\n",
            "fold = 0\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.273700353346373\n",
            "1.0367973744869232\n",
            "0.6652452025586354 0.6648551466739492\n",
            "1.6618679408964359\n",
            "2.8114942610263824\n",
            "0.43923240938166314 0.4316984957036559\n",
            "0.6513697934385977\n",
            "3.753342866897583\n",
            "0.4690831556503198 0.44379670510237623\n",
            "0.3699382602384216\n",
            "3.6366851925849915\n",
            "0.5053304904051172 0.4770857362552864\n",
            "0.36745337279219376\n",
            "3.912460893392563\n",
            "0.48187633262260127 0.46553834465875993\n",
            "0.17858975772794924\n",
            "3.777715176343918\n",
            "0.4861407249466951 0.45014375294924625\n",
            "0.12538735198445225\n",
            "4.2049368023872375\n",
            "0.417910447761194 0.3771337948346233\n",
            "0.06116820675762076\n",
            "3.7144697308540344\n",
            "0.4669509594882729 0.4187948606099059\n",
            "0.04079627625546173\n",
            "3.624879777431488\n",
            "0.464818763326226 0.41724709784411285\n",
            "0.026667490503505656\n",
            "3.526274263858795\n",
            "0.4690831556503198 0.4187599854666355\n",
            "fold = 1\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.31825202232913\n",
            "1.225681148469448\n",
            "0.579957356076759 0.5164214570215795\n",
            "1.6688173566209643\n",
            "2.5573157519102097\n",
            "0.5458422174840085 0.4985719663696825\n",
            "1.4978466010407399\n",
            "5.175797700881958\n",
            "0.4861407249466951 0.38006855889208835\n",
            "0.4308991275335613\n",
            "3.5904781371355057\n",
            "0.5501066098081023 0.4549064970117601\n",
            "0.20466854658566022\n",
            "3.4051805436611176\n",
            "0.5266524520255863 0.44594508301404856\n",
            "0.12270594780382357\n",
            "3.2956951558589935\n",
            "0.5202558635394456 0.4329813814781978\n",
            "0.07188170633621906\n",
            "3.11112280189991\n",
            "0.5287846481876333 0.44524371510996213\n",
            "0.04840306633789288\n",
            "3.002003952860832\n",
            "0.5287846481876333 0.45154906474058787\n",
            "0.0372920145623778\n",
            "2.936935395002365\n",
            "0.5330490405117271 0.4544686817826925\n",
            "0.028933272746048476\n",
            "2.895244985818863\n",
            "0.5287846481876333 0.44948666061175824\n",
            "fold = 2\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.186445018178538\n",
            "2.1768620014190674\n",
            "0.4925373134328358 0.4769353327085286\n",
            "3.6783129165047095\n",
            "3.354126065969467\n",
            "0.5543710021321961 0.5442176870748299\n",
            "1.4036130207149606\n",
            "4.9777491092681885\n",
            "0.5266524520255863 0.519555908302263\n",
            "0.6848500555283145\n",
            "3.094942808151245\n",
            "0.5458422174840085 0.5117090695798813\n",
            "0.26147747863280146\n",
            "2.7058884352445602\n",
            "0.603411513859275 0.5885964912280702\n",
            "0.15816227327051915\n",
            "2.5844951570034027\n",
            "0.5970149253731343 0.5801492007104796\n",
            "0.08864962025300453\n",
            "2.3405542224645615\n",
            "0.5991471215351812 0.5819964349376114\n",
            "0.066041374579072\n",
            "2.309662938117981\n",
            "0.5842217484008528 0.5635793602695209\n",
            "0.04676109356315512\n",
            "2.1784918308258057\n",
            "0.5906183368869936 0.5681399631675874\n",
            "0.035416165170700925\n",
            "2.1180321127176285\n",
            "0.5970149253731343 0.5726435152374203\n",
            "fold = 3\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.5260710010403082\n",
            "1.2200101390480995\n",
            "0.5309168443496801 0.4488247863247863\n",
            "1.6165460999074734\n",
            "1.9853438138961792\n",
            "0.5074626865671642 0.4622440622440622\n",
            "0.7683268833023152\n",
            "4.7439144551754\n",
            "0.509594882729211 0.4344064597315437\n",
            "0.43670660963183955\n",
            "3.4989048838615417\n",
            "0.511727078891258 0.46244938612691877\n",
            "0.19854429913194557\n",
            "3.8310657739639282\n",
            "0.4541577825159915 0.4138415872519919\n",
            "0.12301866308246788\n",
            "3.4723276495933533\n",
            "0.47334754797441364 0.432378665752015\n",
            "0.06947547555165856\n",
            "3.412883937358856\n",
            "0.47761194029850745 0.4355698335273631\n",
            "0.04747382860238615\n",
            "3.2551613450050354\n",
            "0.5010660980810234 0.45743355481727566\n",
            "0.031903415942858705\n",
            "3.1895807683467865\n",
            "0.4925373134328358 0.44959566074950696\n",
            "0.02497526429789631\n",
            "3.1252907812595367\n",
            "0.4840085287846482 0.44034516765285997\n",
            "fold = 4\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.1390701814701685\n",
            "1.6038140803575516\n",
            "0.4669509594882729 0.46566590105362937\n",
            "1.6134127460812266\n",
            "1.5153031796216965\n",
            "0.5948827292110874 0.5883684405025869\n",
            "0.523374647686356\n",
            "2.1899226903915405\n",
            "0.5628997867803838 0.5565778853914447\n",
            "0.2640227353886554\n",
            "2.6995562613010406\n",
            "0.5202558635394456 0.5191979113984608\n",
            "0.17239429409566678\n",
            "2.02555650472641\n",
            "0.5842217484008528 0.5782082324455206\n",
            "0.10089913824279058\n",
            "1.8409824073314667\n",
            "0.582089552238806 0.5744101633393829\n",
            "0.05978587720739214\n",
            "1.8098660111427307\n",
            "0.5884861407249466 0.5796495725304986\n",
            "0.04336139716600117\n",
            "1.8251191228628159\n",
            "0.5863539445628998 0.5782530500241034\n",
            "0.03718249029234836\n",
            "1.7867127656936646\n",
            "0.5863539445628998 0.5772026022304833\n",
            "0.02990156059202395\n",
            "1.7608027458190918\n",
            "0.5906183368869936 0.5810161920714685\n",
            "*******29*********\n",
            "fold = 0\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.7319833024551996\n",
            "1.3166010305285454\n",
            "0.4989339019189765 0.4779632918886915\n",
            "2.2314168404983845\n",
            "1.6435699686408043\n",
            "0.673773987206823 0.6320097232265112\n",
            "0.6574855920319495\n",
            "3.357949882745743\n",
            "0.5863539445628998 0.5489848118332871\n",
            "0.3868105023315078\n",
            "2.966564506292343\n",
            "0.6204690831556503 0.5697691197691198\n",
            "0.1801014423253946\n",
            "2.956674873828888\n",
            "0.5842217484008528 0.5496180950551804\n",
            "0.08686690130516102\n",
            "3.005823701620102\n",
            "0.5501066098081023 0.5258881303150078\n",
            "0.05695921947297297\n",
            "2.952244371175766\n",
            "0.5159914712153518 0.49293916489252765\n",
            "0.03881159183373185\n",
            "2.7549434900283813\n",
            "0.5287846481876333 0.5023980182143766\n",
            "0.026737288277792304\n",
            "2.7563981413841248\n",
            "0.5245202558635395 0.4989244220864774\n",
            "0.020693421412847544\n",
            "2.6930164098739624\n",
            "0.5287846481876333 0.5013542704018551\n",
            "fold = 1\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "4.74589204788208\n",
            "1.3242021650075912\n",
            "0.5245202558635395 0.47653368168691224\n",
            "1.7418723969083083\n",
            "2.6098810881376266\n",
            "0.44562899786780386 0.4139753940792003\n",
            "0.5410542613581607\n",
            "3.9687888771295547\n",
            "0.48187633262260127 0.451715328993895\n",
            "0.29938670953637675\n",
            "3.1803026869893074\n",
            "0.4925373134328358 0.4717668660558794\n",
            "0.15538104388274646\n",
            "3.3564973324537277\n",
            "0.44349680170575695 0.4268195035610435\n",
            "0.0988521101443391\n",
            "2.8557559177279472\n",
            "0.4861407249466951 0.45847885974368185\n",
            "0.05684158460874306\n",
            "2.7978307753801346\n",
            "0.47547974413646055 0.4466793278084714\n",
            "0.03771318326165017\n",
            "2.622032083570957\n",
            "0.47547974413646055 0.4419259345251916\n",
            "0.024778950518291248\n",
            "2.504836820065975\n",
            "0.4861407249466951 0.44616703824386894\n",
            "0.01862475898508963\n",
            "2.49399670958519\n",
            "0.47547974413646055 0.4310946745562131\n",
            "fold = 2\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.839589043667442\n",
            "2.0596446096897125\n",
            "0.36886993603411516 0.2772293723187138\n",
            "1.3403101253666376\n",
            "5.812494680285454\n",
            "0.4520255863539446 0.3210364737360935\n",
            "0.5464711032415691\n",
            "6.9619240164756775\n",
            "0.3880597014925373 0.2954972495695092\n",
            "0.37351410326204804\n",
            "7.347374141216278\n",
            "0.43710021321961623 0.31044776119402984\n",
            "0.17355025932192802\n",
            "6.345404505729675\n",
            "0.3880597014925373 0.2903866937290772\n",
            "0.11317204272276477\n",
            "5.97870859503746\n",
            "0.39232409381663114 0.29006198314186016\n",
            "0.06797667009461868\n",
            "5.319103449583054\n",
            "0.39445628997867804 0.28848290598290594\n",
            "0.04350417773974569\n",
            "5.096592366695404\n",
            "0.4072494669509595 0.29232522796352584\n",
            "0.02782767815025229\n",
            "4.9460519552230835\n",
            "0.4051172707889126 0.2912299517379223\n",
            "0.018760504911800747\n",
            "4.829272165894508\n",
            "0.4115138592750533 0.29450621321124915\n",
            "fold = 3\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.7240125254580847\n",
            "1.9371809661388397\n",
            "0.40085287846481876 0.34930901514291207\n",
            "3.0085799247026443\n",
            "1.205363780260086\n",
            "0.7228144989339019 0.683660551220322\n",
            "0.5559530211122412\n",
            "2.959612861275673\n",
            "0.6012793176972282 0.5806593511678501\n",
            "0.34026829471909686\n",
            "2.373985029757023\n",
            "0.6673773987206824 0.6436586791350087\n",
            "0.19326886181768618\n",
            "2.840642347931862\n",
            "0.55863539445629 0.5401634103019538\n",
            "0.14627682496058314\n",
            "2.1405466869473457\n",
            "0.6439232409381663 0.6215640325658928\n",
            "0.06081509129389336\n",
            "2.036413297057152\n",
            "0.6353944562899787 0.608932254714083\n",
            "0.04010614108196214\n",
            "1.9745397120714188\n",
            "0.6439232409381663 0.618080038229543\n",
            "0.02380066791451291\n",
            "1.9605009406805038\n",
            "0.6439232409381663 0.618080038229543\n",
            "0.01692547330534772\n",
            "1.9087384641170502\n",
            "0.650319829424307 0.6226500255112053\n",
            "fold = 4\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "4.454119956807086\n",
            "1.6263844408094883\n",
            "0.5181236673773987 0.4671954799533518\n",
            "1.3859101267788854\n",
            "3.527666360139847\n",
            "0.43283582089552236 0.3978821576122631\n",
            "0.5568133136012444\n",
            "5.42892399430275\n",
            "0.44562899786780386 0.4127335773454055\n",
            "0.29638230310458885\n",
            "5.357518821954727\n",
            "0.4157782515991471 0.38736651411136536\n",
            "0.1464687726509414\n",
            "4.829444974660873\n",
            "0.3837953091684435 0.35684832380364895\n",
            "0.07336760248596731\n",
            "4.433495849370956\n",
            "0.35394456289978676 0.3118471707706835\n",
            "0.052011536973479544\n",
            "3.960961252450943\n",
            "0.3837953091684435 0.32538809558175763\n",
            "0.03084995631912821\n",
            "3.573779046535492\n",
            "0.4093816631130064 0.346004178308037\n",
            "0.022684779557350435\n",
            "3.3940325677394867\n",
            "0.417910447761194 0.34338989830612776\n",
            "0.017313347002001184\n",
            "3.207982063293457\n",
            "0.417910447761194 0.33681920596690235\n",
            "*******30*********\n",
            "fold = 0\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.425579927469555\n",
            "2.6131300926208496\n",
            "0.3880597014925373 0.3835758216897706\n",
            "1.5459406093547219\n",
            "2.6013584434986115\n",
            "0.47761194029850745 0.47600155049364984\n",
            "0.7928153143117302\n",
            "4.377470076084137\n",
            "0.44562899786780386 0.43951093951093956\n",
            "0.7102100684454566\n",
            "3.734252631664276\n",
            "0.47334754797441364 0.4730025430244248\n",
            "0.4832872960128282\n",
            "4.818980365991592\n",
            "0.4349680170575693 0.4332261668604784\n",
            "0.39194279948347494\n",
            "3.594345986843109\n",
            "0.47121535181236673 0.4648877438351122\n",
            "0.21098963132030085\n",
            "3.916925072669983\n",
            "0.4349680170575693 0.43198281574918307\n",
            "0.17787226956141622\n",
            "2.9050674438476562\n",
            "0.4690831556503198 0.465192960281369\n",
            "0.1039269307726308\n",
            "2.6835650205612183\n",
            "0.488272921108742 0.48506807202459373\n",
            "0.08914647212153987\n",
            "2.746718853712082\n",
            "0.5010660980810234 0.5002459016393442\n",
            "fold = 1\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "4.255863942598042\n",
            "2.346522346138954\n",
            "0.32409381663113007 0.31207170190221034\n",
            "1.461413047815624\n",
            "1.813440553843975\n",
            "0.603411513859275 0.6033231474407945\n",
            "0.7452339780958075\n",
            "5.607308134436607\n",
            "0.3859275053304904 0.3753607103218646\n",
            "0.5231448772706484\n",
            "2.918212801218033\n",
            "0.5458422174840085 0.5456356516162484\n",
            "0.30377650300138875\n",
            "2.306806445121765\n",
            "0.5159914712153518 0.5112901374830727\n",
            "0.1544755373738314\n",
            "2.015167608857155\n",
            "0.5522388059701493 0.5500109653130597\n",
            "0.09371852796328695\n",
            "2.0046569406986237\n",
            "0.5415778251599147 0.5367252144429079\n",
            "0.07104031516141013\n",
            "1.9840930700302124\n",
            "0.5714285714285714 0.5701073944866271\n",
            "0.06183485637762045\n",
            "2.012508898973465\n",
            "0.5458422174840085 0.5431504813298882\n",
            "0.05514601902349999\n",
            "1.9791910648345947\n",
            "0.5650319829424307 0.5641581632653061\n",
            "fold = 2\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.832505685718436\n",
            "1.4886596202850342\n",
            "0.5138592750533049 0.4973488267148014\n",
            "1.8422697786437838\n",
            "3.475722372531891\n",
            "0.417910447761194 0.417741033301955\n",
            "0.7527266834911547\n",
            "3.7490692138671875\n",
            "0.42217484008528783 0.4216594999203695\n",
            "0.4822162687778473\n",
            "4.347514808177948\n",
            "0.48187633262260127 0.47974765019789006\n",
            "0.29108040466120366\n",
            "3.4233947098255157\n",
            "0.488272921108742 0.4868147499726447\n",
            "0.19584664192638898\n",
            "3.4208454191684723\n",
            "0.488272921108742 0.48470976011719463\n",
            "0.13245715475396105\n",
            "3.165847897529602\n",
            "0.4584221748400853 0.4563435560423513\n",
            "0.10252528049443897\n",
            "3.0760782957077026\n",
            "0.4562899786780384 0.4540561761335884\n",
            "0.07487580101740987\n",
            "3.162596434354782\n",
            "0.42217484008528783 0.41875014291267465\n",
            "0.06580530597191107\n",
            "3.2940771877765656\n",
            "0.4157782515991471 0.412871449979897\n",
            "fold = 3\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.3603014067599646\n",
            "1.249202936887741\n",
            "0.5671641791044776 0.5629599026831004\n",
            "1.3137741230036084\n",
            "2.7357794791460037\n",
            "0.4690831556503198 0.42918102500183297\n",
            "0.527570224514133\n",
            "1.5917840003967285\n",
            "0.6353944562899787 0.6089322547140831\n",
            "0.3613325722123447\n",
            "1.66103246062994\n",
            "0.6588486140724946 0.6362085013962147\n",
            "0.24154097782938103\n",
            "2.881181001663208\n",
            "0.4626865671641791 0.44780219780219777\n",
            "0.13699897324764415\n",
            "2.3873277604579926\n",
            "0.5458422174840085 0.5194047945502043\n",
            "0.10534197288124185\n",
            "1.8364273831248283\n",
            "0.5863539445628998 0.556857588155075\n",
            "0.08291285043876422\n",
            "1.6703790575265884\n",
            "0.5970149253731343 0.5717101925446332\n",
            "0.07105662928600061\n",
            "1.5262963324785233\n",
            "0.5991471215351812 0.5762591311034218\n",
            "0.06343715137949116\n",
            "1.575903631746769\n",
            "0.6012793176972282 0.5752984189244812\n",
            "fold = 4\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.9941914614878202\n",
            "1.4482678323984146\n",
            "0.488272921108742 0.4477805251383492\n",
            "1.8064405024051666\n",
            "2.1610280871391296\n",
            "0.5181236673773987 0.4607330375676666\n",
            "0.6715489186738667\n",
            "2.683036521077156\n",
            "0.5245202558635395 0.46871586989540637\n",
            "0.612401254082981\n",
            "2.2969237491488457\n",
            "0.5501066098081023 0.5032802108169155\n",
            "0.30934753033675644\n",
            "2.266665145754814\n",
            "0.5309168443496801 0.4828381250250612\n",
            "0.20860239902609273\n",
            "1.9860628619790077\n",
            "0.5863539445628998 0.519446909198462\n",
            "0.16536371958883186\n",
            "2.3354989513754845\n",
            "0.5628997867803838 0.4770777924627845\n",
            "0.10815834606948652\n",
            "2.1505066454410553\n",
            "0.5181236673773987 0.465626764539808\n",
            "0.09025413660626662\n",
            "2.034228563308716\n",
            "0.5223880597014925 0.48952380952380947\n",
            "0.06478375470951984\n",
            "1.9199626743793488\n",
            "0.5287846481876333 0.4980799496380233\n",
            "*******31*********\n",
            "fold = 0\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "4.460737048011077\n",
            "1.3768974617123604\n",
            "0.5671641791044776 0.5221131886058477\n",
            "2.756420678214023\n",
            "4.06071275472641\n",
            "0.40298507462686567 0.3339419760600527\n",
            "1.0528947773732638\n",
            "5.1536462008953094\n",
            "0.4115138592750533 0.33935570798628123\n",
            "0.7268792594733992\n",
            "4.110246241092682\n",
            "0.47974413646055436 0.4296451355661882\n",
            "0.3619100627930541\n",
            "4.230075657367706\n",
            "0.4072494669509595 0.358734999016329\n",
            "0.21686949502480657\n",
            "3.9233873188495636\n",
            "0.42643923240938164 0.387677941340633\n",
            "0.1862280396254439\n",
            "3.880891650915146\n",
            "0.4136460554371002 0.364846031488075\n",
            "0.14537872452484935\n",
            "3.6380826234817505\n",
            "0.44349680170575695 0.3890577507598784\n",
            "0.13248856718602933\n",
            "3.528905510902405\n",
            "0.43283582089552236 0.37992564316672633\n",
            "0.1139358144841696\n",
            "3.477248877286911\n",
            "0.42643923240938164 0.361083960883415\n",
            "fold = 1\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "4.180556648655942\n",
            "0.9868932664394379\n",
            "0.673773987206823 0.575113242739142\n",
            "2.7974542708773362\n",
            "1.6194156259298325\n",
            "0.6396588486140725 0.5805963436251554\n",
            "2.057977546202509\n",
            "3.1633026748895645\n",
            "0.44562899786780386 0.3651339081177892\n",
            "0.695006187809141\n",
            "3.536694675683975\n",
            "0.4584221748400853 0.3480121721616533\n",
            "0.4706114267832355\n",
            "2.3989166617393494\n",
            "0.5692963752665245 0.5117604617604617\n",
            "0.3191828033641765\n",
            "2.12838414311409\n",
            "0.5607675906183369 0.5099715966727532\n",
            "0.221951514874634\n",
            "2.171763151884079\n",
            "0.5394456289978679 0.4688338926174497\n",
            "0.18544249667933113\n",
            "2.220429480075836\n",
            "0.5223880597014925 0.434379980186932\n",
            "0.1576529523651851\n",
            "2.232008710503578\n",
            "0.5074626865671642 0.40323886639676115\n",
            "0.13401541094246663\n",
            "2.2630829215049744\n",
            "0.4946695095948827 0.39545091128624343\n",
            "fold = 2\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.533440881653836\n",
            "0.7611701786518097\n",
            "0.7078891257995735 0.690884773959521\n",
            "2.632584240875746\n",
            "4.60960066318512\n",
            "0.3816631130063966 0.38017244522221005\n",
            "1.0810912643608295\n",
            "2.586692661046982\n",
            "0.55863539445629 0.541760871514814\n",
            "0.7482564378725854\n",
            "3.0371092557907104\n",
            "0.5223880597014925 0.5028394033467101\n",
            "0.3974385383097749\n",
            "2.6557303071022034\n",
            "0.5565031982942431 0.5366845244880125\n",
            "0.21746222243497246\n",
            "2.8441352397203445\n",
            "0.5010660980810234 0.47146021961086493\n",
            "0.15236611683901988\n",
            "2.8317711651325226\n",
            "0.5031982942430704 0.4708263722428028\n",
            "0.13103323272968592\n",
            "3.2402441203594208\n",
            "0.47974413646055436 0.44646312204937705\n",
            "0.12129988560551092\n",
            "3.019356518983841\n",
            "0.4904051172707889 0.45958624413620874\n",
            "0.13181398877579914\n",
            "3.2854554057121277\n",
            "0.44776119402985076 0.4214592233795801\n",
            "fold = 3\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.039933204650879\n",
            "2.1931611001491547\n",
            "0.2857142857142857 0.2857142857142857\n",
            "1.5951248493633772\n",
            "2.959082216024399\n",
            "0.3390191897654584 0.3390161847608656\n",
            "0.9847379405247537\n",
            "3.8888960778713226\n",
            "0.43710021321961623 0.43596938775510197\n",
            "0.5538569252545896\n",
            "2.259511634707451\n",
            "0.6098081023454158 0.6090972440460738\n",
            "0.39807803811211334\n",
            "2.4520870596170425\n",
            "0.5948827292110874 0.5939060848007582\n",
            "0.3276034642599131\n",
            "3.030567154288292\n",
            "0.4904051172707889 0.4903217005797431\n",
            "0.19947990931962667\n",
            "3.3688087463378906\n",
            "0.4051172707889126 0.40501989314539044\n",
            "0.1627058849522942\n",
            "3.8828100711107254\n",
            "0.36886993603411516 0.3687981958387895\n",
            "0.1372947309558329\n",
            "4.089936718344688\n",
            "0.34754797441364604 0.3473076223394579\n",
            "0.13644631206989288\n",
            "4.181594520807266\n",
            "0.3283582089552239 0.3273674289850982\n",
            "fold = 4\n",
            "(32, 40, 7680)\n",
            "(32, 4)\n",
            "(8, 40, 7680)\n",
            "(8, 4)\n",
            "3.0439339217386747\n",
            "1.0688845813274384\n",
            "0.6823027718550106 0.6512245397058309\n",
            "1.965693147558915\n",
            "2.1565589755773544\n",
            "0.5991471215351812 0.588042909471481\n",
            "1.0953216866443032\n",
            "3.479068875312805\n",
            "0.5181236673773987 0.48952995569254476\n",
            "0.7001456516353708\n",
            "3.6922554671764374\n",
            "0.55863539445629 0.524301149031041\n",
            "0.5060584788259707\n",
            "3.3448878824710846\n",
            "0.5181236673773987 0.49370438304864533\n",
            "0.3357126640253945\n",
            "2.7694020569324493\n",
            "0.4968017057569296 0.47233028222730744\n",
            "0.20448939855161466\n",
            "2.223761171102524\n",
            "0.5628997867803838 0.539369984429273\n",
            "0.14843598066976196\n",
            "2.26012122631073\n",
            "0.5607675906183369 0.544359554800981\n",
            "0.1349582864265693\n",
            "2.2728167921304703\n",
            "0.5479744136460555 0.5318656069908472\n",
            "0.13004655832130657\n",
            "2.2451404333114624\n",
            "0.55863539445629 0.5460802236799656\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "#def get_mertics_per_subject():\n",
        "k  = 5\n",
        "type_emotion = 1\n",
        "acc_all = []\n",
        "f1_all = []\n",
        "\n",
        "for sub in range(26, 32):\n",
        "    print(f\"*******{sub}*********\")\n",
        "\n",
        "    args.batch_size = 100\n",
        "    X = np.arange(40)\n",
        "    y = np.array(labels_bin[sub][:, type_emotion])\n",
        "    \n",
        "\n",
        "    skf = StratifiedKFold(n_splits=k, random_state=None, shuffle=True)\n",
        "    balanced_split = skf.split(X, y)\n",
        "    acc_sub = []\n",
        "    f1_sub = []\n",
        "   \n",
        "    for fold,  (ind_train, ind_test) in  enumerate(balanced_split):\n",
        "        inds_train = []\n",
        "        inds_test = []\n",
        "        inds_train.append(ind_train)\n",
        "        inds_test.append(ind_test)\n",
        "        print(f\"fold = {fold}\")\n",
        "       \n",
        "        train_dataset = EmotionDataset(args.data_dir, 'train', ind_train, data[sub : sub + 1], labels[sub : sub + 1])\n",
        "\n",
        "#     class_weights_all = [1/train_dataset.cnt[0][i] for i in range(2)]\n",
        "# weights_samples =  [0] * train_dataset.__len__()\n",
        "# for i in range(train_dataset.__len__()):\n",
        "#     i_file, index_in_file, nvideo, nsec = train_dataset.get_index_record(i)\n",
        "#     #print(train_dataset.labels[i_file][nvideo])\n",
        "#     weights_samples[i] = class_weights_all[int(train_dataset.labels[i_file][nvideo, 0])]\n",
        "\n",
        "# weighted_sampler = WeightedRandomSampler(\n",
        "#     weights=weights_samples,\n",
        "#     num_samples=len(weights_samples),\n",
        "#     replacement=True\n",
        "# )\n",
        "    #train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "    #                          pin_memory=True, shuffle=False, drop_last=True, sampler=weighted_sampler)\n",
        "\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "                              pin_memory=True, shuffle=False, drop_last=True)\n",
        " \n",
        "        val_dataset = EmotionDataset(args.data_dir, 'val', ind_test, data[sub : sub + 1], labels[sub : sub + 1])\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "                              pin_memory=True, shuffle=False, drop_last=False)\n",
        "        device  = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = get_model()\n",
        "        model.apply(initialize_weights)\n",
        "        criterion = nn.CrossEntropyLoss(reduction = 'mean')#torch.nn.MSELoss()\n",
        "        #optimizer = optim.SGD(model.parameters(), lr=3e-5, momentum = 0.9)#, weight_decay=args.weight_decay)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
        "        description = f'arousal_cnn2_noleak'\n",
        "        train_loop(description, 1, 10)\n",
        "        model_state  = torch.load(os.path.join(\"/content/drive/MyDrive/MADE/Project/CNN_models/\", f\"val_{description}.tgz\"))\n",
        "        #   #model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device)\n",
        "        model.load_state_dict(model_state['model_state_dict'])\n",
        "        acc, f1 = calculate_predictions(model, val_dataloader, type_emotion)\n",
        "        #print(f\"f1 = {f1} acc = {acc}\")\n",
        "        acc_sub.append(acc)\n",
        "        f1_sub.append(f1)\n",
        "        #print(acc, f1)\n",
        "    acc_all.append(acc_sub)     \n",
        "    f1_all.append(f1_sub)     \n",
        "    pd.DataFrame(f1_all).to_csv(\"f1_arousal_cnn2_noleak1.csv\")\n",
        "    pd.DataFrame(acc_all).to_csv(\"acc_arousal_cnn2_noleak1.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qvk5FI8mcJc"
      },
      "source": [
        "#LEAK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyGWfyHnmfms"
      },
      "source": [
        "##Valence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm5OBdiImY-c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "class EmotionDataset_leak(Dataset):\n",
        "    def __init__ (self, data, labels_bin, transforms, indexes, interval = 1):  #indexes - индексы видео которые вошли в датасет, data - данные labels - метки бинарные\n",
        "       self.data_samples = []\n",
        "       self.labels = []\n",
        "       self.transforms = transforms\n",
        "       self.cnt = [Counter(), Counter(), Counter(),Counter()]\n",
        "       for sub in range(len(data)): #sub   - человек\n",
        "          for nvideo in range(NVIDEOS):\n",
        "             \n",
        "             for nsec in range(LEN_RECORD_IN_SECONDS):\n",
        "                    self.data_samples.append(data[sub][nvideo, :32,  (3 + nsec) * NTIMES_IN_SEC : (3 + nsec + interval) * NTIMES_IN_SEC])\n",
        "                    self.labels.append(labels_bin[sub][nvideo, :])\n",
        "                    \n",
        "\n",
        "       self.data_samples = np.array(self.data_samples)[np.array(indexes)]\n",
        "       self.labels = np.array(self.labels)[np.array(indexes)]\n",
        "       for i in range(4):\n",
        "          self.cnt[i].update(self.labels[:, i])\n",
        "       \n",
        "\n",
        "    def __len__(self):\n",
        "       result =  len(self.data_samples)\n",
        "       return result\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "      sample = {}   \n",
        "      sample = {\"labels\": self.labels[item],\n",
        "                 \"data\": self.data_samples[item]\n",
        "      }\n",
        "\n",
        "      data_sample = sample['data']\n",
        "      #print(data_sample.shape)\n",
        "      sample['data'] = np.zeros((HCANALS, WCANALS, NTIMES_IN_SAMPLE))\n",
        "      #sample_from_one_canals = []\n",
        "      # for i_canal in range(NCANALS):\n",
        "      #   sample_from_one_canal = data_sample[nvideo, i_canal, nsec * 128 : nsec * 128 + 128]\n",
        "      #   sample_from_one_canals.append(sample_from_one_canal)\n",
        "      #   #print(sample_from_one_canal.shape)\n",
        "      # sample_from_one_canals = np.asarray(sample_from_one_canals).copy()\n",
        "      sample_from_one_canals = scipy.stats.zscore(data_sample, axis = 0)\n",
        "      for i_canal in range(NCANALS):\n",
        "          sample['data'][electrode_matrix[list_electrodes[i_canal]][0],  electrode_matrix[list_electrodes[i_canal]][1]] = sample_from_one_canals[i_canal]\n",
        "      #for i in range(NTIMES_IN_SAMPLE): \n",
        "      #    sample['data'][:, :, i] = scipy.stats.zscore(sample['data'][:, :, i])\n",
        "      sample['data'] = torch.FloatTensor(sample['data'])\n",
        "      sample['labels'] = torch.LongTensor(sample['labels'])\n",
        "      #sample['labels']  = torch.LongTensor(self.labels[i_file][nvideo])\n",
        "      \n",
        "      #  if self.transforms is not None:\n",
        "      #      for t in self.transforms:\n",
        "      #           sample = t(sample)\n",
        "      #print(sample)         \n",
        "      \n",
        "      return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAO2bRgMVo24"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "\n",
        "#def get_mertics_per_subject():\n",
        "k  = 5\n",
        "type_emotion = 0\n",
        "\n",
        "acc_all = []\n",
        "f1_all = []\n",
        "for sub in range(0,32):\n",
        "    print(f\"*******{sub}*********\")\n",
        "\n",
        "    args.batch_size = 100\n",
        "    indexes = np.arange(NVIDEOS * 1 * LEN_RECORD_IN_SECONDS)\n",
        "    n = len(indexes)\n",
        "    #X = np.arange(40)\n",
        "    y = []\n",
        "    for nvideo in range(NVIDEOS):\n",
        "        y.extend(60 * [labels_bin[sub][nvideo, type_emotion]])\n",
        "    \n",
        "\n",
        "    skf = StratifiedKFold(n_splits=k, random_state=None, shuffle=True)\n",
        "    balanced_split = skf.split(indexes, y)\n",
        "    acc_sub = []\n",
        "    f1_sub = []\n",
        "    for fold,  (inds_train, inds_test) in  enumerate(balanced_split):\n",
        "        print(f\"fold = {fold}\")\n",
        "        #print(inds_train, inds_test)\n",
        "        #print(sum(labels_bin[sub][inds_train, type_emotion]))\n",
        "        #print(sum(labels_bin[sub][inds_test, type_emotion]))\n",
        "        args.batch_size = 100\n",
        "        transforms = []\n",
        "        #transforms_random = RandomAugmentation([add_noise, reset_part_in_freq, reset_part_in_time, None], 0.2)\n",
        "        #transforms = [RandomAugmentation([add_noise(), reset_part_in_freq(0.2), reset_part_in_time(0.2), None], 0.2), to_head_matrix(),ToTensor()]   \n",
        "        #transforms = [to_head_matrix(),ToTensor()] \n",
        "        #transforms = [RandomAugmentation([add_noise(), None], 0.5), to_head_matrix(),ToTensor()]   \n",
        "        #transforms = [RandomAugmentation([reset_part_in_time(0.4), None], 0.1), to_head_matrix(),ToTensor()]   \n",
        "\n",
        "        train_dataset = EmotionDataset_leak(data[sub : sub + 1], labels_bin[sub : sub + 1], transforms, inds_train)\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "                                    pin_memory=True, shuffle=True, drop_last=True)\n",
        "\n",
        "        val_dataset = EmotionDataset_leak(data[sub: sub + 1], labels_bin[sub  : sub + 1], transforms,  inds_test)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "                              pin_memory=True, shuffle=False, drop_last=False)\n",
        "        device  = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = get_model()\n",
        "        model.apply(initialize_weights)\n",
        "        criterion = nn.CrossEntropyLoss(reduction = 'mean')#torch.nn.MSELoss()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=3e-4, momentum = 0.9)#, weight_decay=args.weight_decay)\n",
        "        #optimizer = optim.Adam(model.parameters(), lr=3e-6)#, momentum = 0.9)#, weight_decay=args.weight_decay)\n",
        "        \n",
        "        description = f'cnn2_leak_{sub}_{fold}_subject'\n",
        "        train_loop(description , 0, 3)\n",
        "        model_state  = torch.load(os.path.join(\"/content/drive/MyDrive/MADE/Project/CNN_models/\", f\"val_{description}.tgz\"))\n",
        "        #   #model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device)\n",
        "        model.load_state_dict(model_state['model_state_dict'])\n",
        "        acc, f1 = calculate_predictions(model, val_dataloader, type_emotion)\n",
        "        print(f\"f1 = {f1} acc = {acc}\")\n",
        "        acc_sub.append(acc)\n",
        "        f1_sub.append(f1)\n",
        "        print(acc, f1)\n",
        "        #break\n",
        "    acc_all.append(acc_sub)     \n",
        "    f1_all.append(f1_sub)     \n",
        "    pd.DataFrame(f1_all).to_csv(\"f1_data_val_cnn2_leak_sgd.csv\")\n",
        "    pd.DataFrame(acc_all).to_csv(\"acc_data_val_cnn2_leak_sgd.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKM8bT-OmLW1"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(f1_all).to_csv(\"f1_arousal_cnn2_leak_sgd2.csv\")\n",
        "pd.DataFrame(acc_all).to_csv(\"acc_arousal_cnn2_leak_sgd2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvBCQBeBmWUl",
        "outputId": "407bf89d-eb54-40fc-bd9f-54c75ab2fff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32\n"
          ]
        }
      ],
      "source": [
        "print(len(f1_all))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHLlGuWdQHxD",
        "outputId": "211de1b1-5e89-4833-ac39-7ba533ca921e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*******0*********\n",
            "fold = 0\n",
            "0.5659010653433046\n",
            "0.3619055636227131\n",
            "[[170  10]\n",
            " [ 22 278]]\n",
            "0.9333333333333333 0.9297783629580865\n",
            "0.12273557935106127\n",
            "0.1372770955786109\n",
            "[[171   9]\n",
            " [  6 294]]\n",
            "0.96875 0.9665537856933819\n",
            "0.04006049782037735\n",
            "0.1267004543915391\n",
            "[[172   8]\n",
            " [  9 291]]\n",
            "0.9645833333333333 0.9622639764334834\n",
            "[[171   9]\n",
            " [  6 294]]\n",
            "f1 = 0.9665537856933819 acc = 0.96875\n",
            "0.96875 0.9665537856933819\n",
            "fold = 1\n",
            "0.5886757875743666\n",
            "0.40784429013729095\n",
            "[[168  12]\n",
            " [ 32 268]]\n",
            "0.9083333333333333 0.9041742286751362\n",
            "0.11588066894757121\n",
            "0.1756174210458994\n",
            "[[173   7]\n",
            " [ 14 286]]\n",
            "0.95625 0.9536830690480675\n",
            "0.05403874843920532\n",
            "0.1635468527674675\n",
            "[[175   5]\n",
            " [ 14 286]]\n",
            "0.9604166666666667 0.9581802924628231\n",
            "[[175   5]\n",
            " [ 14 286]]\n",
            "f1 = 0.9581802924628231 acc = 0.9604166666666667\n",
            "0.9604166666666667 0.9581802924628231\n",
            "fold = 2\n",
            "0.5593963500700498\n",
            "0.4174707420170307\n",
            "[[135  45]\n",
            " [ 20 280]]\n",
            "0.8645833333333334 0.8509850746268657\n",
            "0.1184415758440369\n",
            "0.21906737983226776\n",
            "[[161  19]\n",
            " [ 16 284]]\n",
            "0.9270833333333334 0.9219588332845577\n",
            "0.04814498062784735\n",
            "0.19960930198431015\n",
            "[[166  14]\n",
            " [ 14 286]]\n",
            "0.9416666666666667 0.9377777777777778\n",
            "[[166  14]\n",
            " [ 14 286]]\n",
            "f1 = 0.9377777777777778 acc = 0.9416666666666667\n",
            "0.9416666666666667 0.9377777777777778\n",
            "fold = 3\n",
            "0.6193927424518686\n",
            "0.3681361824274063\n",
            "[[173   7]\n",
            " [ 23 277]]\n",
            "0.9375 0.934421451471874\n",
            "0.11829136164956972\n",
            "0.1964781042188406\n",
            "[[168  12]\n",
            " [ 12 288]]\n",
            "0.95 0.9466666666666667\n",
            "0.055818461862049605\n",
            "0.1770666828379035\n",
            "[[170  10]\n",
            " [ 11 289]]\n",
            "0.95625 0.9533849120648912\n",
            "[[170  10]\n",
            " [ 11 289]]\n",
            "f1 = 0.9533849120648912 acc = 0.95625\n",
            "0.95625 0.9533849120648912\n",
            "fold = 4\n",
            "0.5666021696831051\n",
            "0.40059904754161835\n",
            "[[159  21]\n",
            " [ 24 276]]\n",
            "0.90625 0.9003280867145645\n",
            "0.11431630936108138\n",
            "0.19052107445895672\n",
            "[[171   9]\n",
            " [ 14 286]]\n",
            "0.9520833333333333 0.9491654195924946\n",
            "0.048948509177487144\n",
            "0.17928333953022957\n",
            "[[174   6]\n",
            " [ 13 287]]\n",
            "0.9604166666666667 0.9580942053292041\n",
            "[[174   6]\n",
            " [ 13 287]]\n",
            "f1 = 0.9580942053292041 acc = 0.9604166666666667\n",
            "0.9604166666666667 0.9580942053292041\n",
            "*******1*********\n",
            "fold = 0\n",
            "0.70564834538259\n",
            "0.561315268278122\n",
            "[[145  35]\n",
            " [ 57 243]]\n",
            "0.8083333333333333 0.7999963767459556\n",
            "0.35173385394246953\n",
            "0.4643666706979275\n",
            "[[141  39]\n",
            " [ 34 266]]\n",
            "0.8479166666666667 0.8368525200791526\n",
            "0.2288209980255679\n",
            "0.44878189265727997\n",
            "[[157  23]\n",
            " [ 45 255]]\n",
            "0.8583333333333333 0.852171234986141\n",
            "[[157  23]\n",
            " [ 45 255]]\n",
            "f1 = 0.852171234986141 acc = 0.8583333333333333\n",
            "0.8583333333333333 0.852171234986141\n",
            "fold = 1\n",
            "0.6261277277218668\n",
            "0.5764365196228027\n",
            "[[161  19]\n",
            " [ 63 237]]\n",
            "0.8291666666666667 0.824773844290904\n",
            "0.31888952616013977\n",
            "0.393096923828125\n",
            "[[156  24]\n",
            " [ 36 264]]\n",
            "0.875 0.8683344305464121\n",
            "0.2394295672052785\n",
            "0.38220686465501785\n",
            "[[160  20]\n",
            " [ 43 257]]\n",
            "0.86875 0.8631618482200633\n",
            "[[156  24]\n",
            " [ 36 264]]\n",
            "f1 = 0.8683344305464121 acc = 0.875\n",
            "0.875 0.8683344305464121\n",
            "fold = 2\n",
            "0.7188860256420938\n",
            "0.5825231224298477\n",
            "[[142  38]\n",
            " [ 59 241]]\n",
            "0.7979166666666667 0.7889382998109693\n",
            "0.3944674604817441\n",
            "0.5462515354156494\n",
            "[[151  29]\n",
            " [ 57 243]]\n",
            "0.8208333333333333 0.8140004325571336\n",
            "0.2797965164247312\n",
            "0.44322964549064636\n",
            "[[161  19]\n",
            " [ 44 256]]\n",
            "0.86875 0.863399209486166\n",
            "[[161  19]\n",
            " [ 44 256]]\n",
            "f1 = 0.863399209486166 acc = 0.86875\n",
            "0.86875 0.863399209486166\n",
            "fold = 3\n",
            "0.834667759506326\n",
            "0.6546306610107422\n",
            "[[121  59]\n",
            " [ 60 240]]\n",
            "0.7520833333333333 0.7358478350343832\n",
            "0.4812380765613757\n",
            "0.42891543731093407\n",
            "[[150  30]\n",
            " [ 45 255]]\n",
            "0.84375 0.8358974358974359\n",
            "0.28603264062028183\n",
            "0.39082494005560875\n",
            "[[156  24]\n",
            " [ 40 260]]\n",
            "0.8666666666666667 0.8600990964733314\n",
            "[[156  24]\n",
            " [ 40 260]]\n",
            "f1 = 0.8600990964733314 acc = 0.8666666666666667\n",
            "0.8666666666666667 0.8600990964733314\n",
            "fold = 4\n",
            "0.8423729507546676\n",
            "0.5643891990184784\n",
            "[[130  50]\n",
            " [ 44 256]]\n",
            "0.8041666666666667 0.7896738826425015\n",
            "0.41149138855306727\n",
            "0.42777184396982193\n",
            "[[144  36]\n",
            " [ 35 265]]\n",
            "0.8520833333333333 0.8420459864941903\n",
            "0.2365799914849432\n",
            "0.39810770750045776\n",
            "[[154  26]\n",
            " [ 34 266]]\n",
            "0.875 0.8678025851938895\n",
            "[[154  26]\n",
            " [ 34 266]]\n",
            "f1 = 0.8678025851938895 acc = 0.875\n",
            "0.875 0.8678025851938895\n",
            "*******2*********\n",
            "fold = 0\n",
            "0.645549254982095\n",
            "0.5019119530916214\n",
            "[[228  24]\n",
            " [ 51 177]]\n",
            "0.84375 0.8419659436608589\n",
            "0.2598205173486157\n",
            "0.33424343168735504\n",
            "[[228  24]\n",
            " [ 33 195]]\n",
            "0.88125 0.8806860551826995\n",
            "0.1336283111258557\n",
            "0.30083498544991016\n",
            "[[232  20]\n",
            " [ 17 211]]\n",
            "0.9229166666666667 0.9227688414021631\n",
            "[[232  20]\n",
            " [ 17 211]]\n",
            "f1 = 0.9227688414021631 acc = 0.9229166666666667\n",
            "0.9229166666666667 0.9227688414021631\n",
            "fold = 1\n",
            "0.6649349912216789\n",
            "0.4989394545555115\n",
            "[[218  34]\n",
            " [ 33 195]]\n",
            "0.8604166666666667 0.8600954448364517\n",
            "0.27916106895396586\n",
            "0.3312072679400444\n",
            "[[226  26]\n",
            " [ 33 195]]\n",
            "0.8770833333333333 0.8765684996883705\n",
            "0.16752397425864873\n",
            "0.2631617933511734\n",
            "[[237  15]\n",
            " [ 19 209]]\n",
            "0.9291666666666667 0.9289248136018395\n",
            "[[237  15]\n",
            " [ 19 209]]\n",
            "f1 = 0.9289248136018395 acc = 0.9291666666666667\n",
            "0.9291666666666667 0.9289248136018395\n",
            "fold = 2\n",
            "0.6547462548080244\n",
            "0.46399833261966705\n",
            "[[205  47]\n",
            " [ 24 204]]\n",
            "0.8520833333333333 0.8520826913311256\n",
            "0.2441882224459397\n",
            "0.3624465875327587\n",
            "[[225  27]\n",
            " [ 29 199]]\n",
            "0.8833333333333333 0.8829900228099807\n",
            "0.12687215757997414\n",
            "0.3548846207559109\n",
            "[[227  25]\n",
            " [ 25 203]]\n",
            "0.8958333333333334 0.8955722639933166\n",
            "[[227  25]\n",
            " [ 25 203]]\n",
            "f1 = 0.8955722639933166 acc = 0.8958333333333334\n",
            "0.8958333333333334 0.8955722639933166\n",
            "fold = 3\n",
            "0.6583282633831626\n",
            "0.5228735655546188\n",
            "[[180  72]\n",
            " [ 14 214]]\n",
            "0.8208333333333333 0.8199298563975502\n",
            "0.25904420763254166\n",
            "0.3172658681869507\n",
            "[[226  26]\n",
            " [ 17 211]]\n",
            "0.9104166666666667 0.9103290974258716\n",
            "0.1326031269211518\n",
            "0.3008269853889942\n",
            "[[229  23]\n",
            " [ 21 207]]\n",
            "0.9083333333333333 0.9081403643069643\n",
            "[[226  26]\n",
            " [ 17 211]]\n",
            "f1 = 0.9103290974258716 acc = 0.9104166666666667\n",
            "0.9104166666666667 0.9103290974258716\n",
            "fold = 4\n",
            "0.665602633827611\n",
            "0.4869832471013069\n",
            "[[208  44]\n",
            " [ 34 194]]\n",
            "0.8375 0.8373616444544838\n",
            "0.25976992437714025\n",
            "0.37646961584687233\n",
            "[[227  25]\n",
            " [ 34 194]]\n",
            "0.8770833333333333 0.8764996009785836\n",
            "0.13061459911497017\n",
            "0.3311307951807976\n",
            "[[230  22]\n",
            " [ 25 203]]\n",
            "0.9020833333333333 0.9017725354964276\n",
            "[[230  22]\n",
            " [ 25 203]]\n",
            "f1 = 0.9017725354964276 acc = 0.9020833333333333\n",
            "0.9020833333333333 0.9017725354964276\n",
            "*******3*********\n",
            "fold = 0\n",
            "0.5417652232082266\n",
            "0.3748825490474701\n",
            "[[171   9]\n",
            " [ 32 268]]\n",
            "0.9145833333333333 0.9109465996352792\n",
            "0.12977225117777524\n",
            "0.17703291587531567\n",
            "[[172   8]\n",
            " [ 17 283]]\n",
            "0.9479166666666666 0.9449740690300303\n",
            "0.05180465032983767\n",
            "0.16414270550012589\n",
            "[[172   8]\n",
            " [ 14 286]]\n",
            "0.9541666666666667 0.9514268366727383\n",
            "[[172   8]\n",
            " [ 14 286]]\n",
            "f1 = 0.9514268366727383 acc = 0.9541666666666667\n",
            "0.9541666666666667 0.9514268366727383\n",
            "fold = 1\n",
            "0.5419917514449671\n",
            "0.3929729349911213\n",
            "[[157  23]\n",
            " [ 32 268]]\n",
            "0.8854166666666666 0.878942951866067\n",
            "0.11806976403060712\n",
            "0.3012259118258953\n",
            "[[163  17]\n",
            " [ 28 272]]\n",
            "0.90625 0.9011527601718843\n",
            "0.04223902204907254\n",
            "0.32834987342357635\n",
            "[[165  15]\n",
            " [ 23 277]]\n",
            "0.9208333333333333 0.9162749706227966\n",
            "[[165  15]\n",
            " [ 23 277]]\n",
            "f1 = 0.9162749706227966 acc = 0.9208333333333333\n",
            "0.9208333333333333 0.9162749706227966\n",
            "fold = 2\n",
            "0.5711803679403505\n",
            "0.40188413113355637\n",
            "[[172   8]\n",
            " [ 38 262]]\n",
            "0.9041666666666667 0.9006747638326587\n",
            "0.13308317920095042\n",
            "0.20632465556263924\n",
            "[[169  11]\n",
            " [ 20 280]]\n",
            "0.9354166666666667 0.9317678455972378\n",
            "0.05310476076250013\n",
            "0.2018936686217785\n",
            "[[171   9]\n",
            " [ 14 286]]\n",
            "0.9520833333333333 0.9491654195924946\n",
            "[[171   9]\n",
            " [ 14 286]]\n",
            "f1 = 0.9491654195924946 acc = 0.9520833333333333\n",
            "0.9520833333333333 0.9491654195924946\n",
            "fold = 3\n",
            "0.5256411041084089\n",
            "0.4051382914185524\n",
            "[[173   7]\n",
            " [ 42 258]]\n",
            "0.8979166666666667 0.8946118516858967\n",
            "0.10295558593382961\n",
            "0.2621689550578594\n",
            "[[171   9]\n",
            " [ 28 272]]\n",
            "0.9229166666666667 0.919345682768768\n",
            "0.03761485792500408\n",
            "0.27438678219914436\n",
            "[[172   8]\n",
            " [ 24 276]]\n",
            "0.9333333333333333 0.9300495482366657\n",
            "[[172   8]\n",
            " [ 24 276]]\n",
            "f1 = 0.9300495482366657 acc = 0.9333333333333333\n",
            "0.9333333333333333 0.9300495482366657\n",
            "fold = 4\n",
            "0.6423721266420264\n",
            "0.3882961794734001\n",
            "[[166  14]\n",
            " [ 35 265]]\n",
            "0.8979166666666667 0.8933812029972937\n",
            "0.12347136918259294\n",
            "0.2181745208799839\n",
            "[[166  14]\n",
            " [ 18 282]]\n",
            "0.9333333333333333 0.9291983184600635\n",
            "0.044184861704707146\n",
            "0.21480113454163074\n",
            "[[169  11]\n",
            " [ 17 283]]\n",
            "0.9416666666666667 0.9381796103107578\n",
            "[[169  11]\n",
            " [ 17 283]]\n",
            "f1 = 0.9381796103107578 acc = 0.9416666666666667\n",
            "0.9416666666666667 0.9381796103107578\n",
            "*******4*********\n",
            "fold = 0\n",
            "0.6713151774908367\n",
            "0.388394296169281\n",
            "[[101   7]\n",
            " [ 27 345]]\n",
            "0.9291666666666667 0.9044854387114898\n",
            "0.1859285702046595\n",
            "0.24613569676876068\n",
            "[[102   6]\n",
            " [ 25 347]]\n",
            "0.9354166666666667 0.9126632428466617\n",
            "0.09314673668459843\n",
            "0.23715483583509922\n",
            "[[104   4]\n",
            " [ 23 349]]\n",
            "0.94375 0.9239325018341893\n",
            "[[104   4]\n",
            " [ 23 349]]\n",
            "f1 = 0.9239325018341893 acc = 0.94375\n",
            "0.94375 0.9239325018341893\n",
            "fold = 1\n",
            "0.5911845894236314\n",
            "0.48698002845048904\n",
            "[[ 94  14]\n",
            " [ 51 321]]\n",
            "0.8645833333333334 0.8255726193737387\n",
            "0.18953958232151835\n",
            "0.22997799143195152\n",
            "[[100   8]\n",
            " [ 20 352]]\n",
            "0.9416666666666667 0.9194708081679608\n",
            "0.08108096128623736\n",
            "0.23027265258133411\n",
            "[[100   8]\n",
            " [ 22 350]]\n",
            "0.9375 0.9142346634901728\n",
            "[[100   8]\n",
            " [ 20 352]]\n",
            "f1 = 0.9194708081679608 acc = 0.9416666666666667\n",
            "0.9416666666666667 0.9194708081679608\n",
            "fold = 2\n",
            "0.6008161871056807\n",
            "0.41426436975598335\n",
            "[[ 95  13]\n",
            " [ 31 341]]\n",
            "0.9083333333333333 0.8756798756798757\n",
            "0.18651417329123146\n",
            "0.2275831699371338\n",
            "[[101   7]\n",
            " [ 23 349]]\n",
            "0.9375 0.9147404319818113\n",
            "0.08648314513266087\n",
            "0.19548707082867622\n",
            "[[102   6]\n",
            " [ 20 352]]\n",
            "0.9458333333333333 0.925670041691483\n",
            "[[102   6]\n",
            " [ 20 352]]\n",
            "f1 = 0.925670041691483 acc = 0.9458333333333333\n",
            "0.9458333333333333 0.925670041691483\n",
            "fold = 3\n",
            "0.7161809692257329\n",
            "0.49613451212644577\n",
            "[[ 90  18]\n",
            " [ 64 308]]\n",
            "0.8291666666666667 0.7847721953673528\n",
            "0.2157238847330997\n",
            "0.2952352613210678\n",
            "[[ 96  12]\n",
            " [ 31 341]]\n",
            "0.9104166666666667 0.8788554658840793\n",
            "0.08754835307205978\n",
            "0.3062376417219639\n",
            "[[ 98  10]\n",
            " [ 25 347]]\n",
            "0.9270833333333334 0.9002369372739742\n",
            "[[ 98  10]\n",
            " [ 25 347]]\n",
            "f1 = 0.9002369372739742 acc = 0.9270833333333334\n",
            "0.9270833333333334 0.9002369372739742\n",
            "fold = 4\n",
            "0.6595509256187239\n",
            "0.4449922442436218\n",
            "[[ 90  18]\n",
            " [ 32 340]]\n",
            "0.8958333333333334 0.8570577724836212\n",
            "0.18116858738817668\n",
            "0.25725484639406204\n",
            "[[100   8]\n",
            " [ 25 347]]\n",
            "0.93125 0.9064885383520968\n",
            "0.0884234587612905\n",
            "0.2511719074100256\n",
            "[[101   7]\n",
            " [ 25 347]]\n",
            "0.9333333333333333 0.9095853641308187\n",
            "[[101   7]\n",
            " [ 25 347]]\n",
            "f1 = 0.9095853641308187 acc = 0.9333333333333333\n",
            "0.9333333333333333 0.9095853641308187\n",
            "*******5*********\n",
            "fold = 0\n",
            "0.6626514290508471\n",
            "0.6217171922326088\n",
            "[[110  22]\n",
            " [ 76 272]]\n",
            "0.7958333333333333 0.7695879621465938\n",
            "0.2636945388819042\n",
            "0.3288225457072258\n",
            "[[117  15]\n",
            " [ 29 319]]\n",
            "0.9083333333333333 0.888605244836389\n",
            "0.15735151461864771\n",
            "0.28243280574679375\n",
            "[[119  13]\n",
            " [ 30 318]]\n",
            "0.9104166666666667 0.8918233324074025\n",
            "[[119  13]\n",
            " [ 30 318]]\n",
            "f1 = 0.8918233324074025 acc = 0.9104166666666667\n",
            "0.9104166666666667 0.8918233324074025\n",
            "fold = 1\n",
            "0.9340294521105917\n",
            "0.5553815364837646\n",
            "[[101  31]\n",
            " [ 63 285]]\n",
            "0.8041666666666667 0.7704330836860958\n",
            "0.2795380440197493\n",
            "0.3118658885359764\n",
            "[[112  20]\n",
            " [ 30 318]]\n",
            "0.8958333333333334 0.8723159753995446\n",
            "0.15041884662289368\n",
            "0.24106857180595398\n",
            "[[120  12]\n",
            " [ 26 322]]\n",
            "0.9208333333333333 0.903795438722336\n",
            "[[120  12]\n",
            " [ 26 322]]\n",
            "f1 = 0.903795438722336 acc = 0.9208333333333333\n",
            "0.9208333333333333 0.903795438722336\n",
            "fold = 2\n",
            "0.7537728610791659\n",
            "0.5148584693670273\n",
            "[[112  20]\n",
            " [ 44 304]]\n",
            "0.8666666666666667 0.8412698412698413\n",
            "0.2920749516863572\n",
            "0.3177657537162304\n",
            "[[116  16]\n",
            " [ 33 315]]\n",
            "0.8979166666666667 0.8767289136735518\n",
            "0.162947878241539\n",
            "0.2628212757408619\n",
            "[[117  15]\n",
            " [ 28 320]]\n",
            "0.9104166666666667 0.8909039013483728\n",
            "[[117  15]\n",
            " [ 28 320]]\n",
            "f1 = 0.8909039013483728 acc = 0.9104166666666667\n",
            "0.9104166666666667 0.8909039013483728\n",
            "fold = 3\n",
            "0.7816004439404136\n",
            "0.5305815413594246\n",
            "[[100  32]\n",
            " [ 43 305]]\n",
            "0.84375 0.8088918380889184\n",
            "0.24459374499948403\n",
            "0.3647753968834877\n",
            "[[114  18]\n",
            " [ 35 313]]\n",
            "0.8895833333333333 0.8666659678509845\n",
            "0.1306208262318059\n",
            "0.3202350065112114\n",
            "[[117  15]\n",
            " [ 27 321]]\n",
            "0.9125 0.8932112890922961\n",
            "[[117  15]\n",
            " [ 27 321]]\n",
            "f1 = 0.8932112890922961 acc = 0.9125\n",
            "0.9125 0.8932112890922961\n",
            "fold = 4\n",
            "0.9668964053455152\n",
            "0.49901439249515533\n",
            "[[104  28]\n",
            " [ 52 296]]\n",
            "0.8333333333333334 0.8015873015873015\n",
            "0.3185970155816329\n",
            "0.3606248125433922\n",
            "[[108  24]\n",
            " [ 29 319]]\n",
            "0.8895833333333333 0.8631367717708832\n",
            "0.16466761302006871\n",
            "0.3334038518369198\n",
            "[[109  23]\n",
            " [ 25 323]]\n",
            "0.9 0.8751923035253841\n",
            "[[109  23]\n",
            " [ 25 323]]\n",
            "f1 = 0.8751923035253841 acc = 0.9\n",
            "0.9 0.8751923035253841\n",
            "*******6*********\n",
            "fold = 0\n",
            "0.6448206587841636\n",
            "0.4943922534584999\n",
            "[[153  51]\n",
            " [ 19 257]]\n",
            "0.8541666666666666 0.8469833867677061\n",
            "0.2259754487558415\n",
            "0.28228748589754105\n",
            "[[178  26]\n",
            " [ 15 261]]\n",
            "0.9145833333333333 0.9119506422502697\n",
            "0.12496247887611389\n",
            "0.20879174396395683\n",
            "[[185  19]\n",
            " [ 12 264]]\n",
            "0.9354166666666667 0.9336185475488381\n",
            "[[185  19]\n",
            " [ 12 264]]\n",
            "f1 = 0.9336185475488381 acc = 0.9354166666666667\n",
            "0.9354166666666667 0.9336185475488381\n",
            "fold = 1\n",
            "0.6272370642737338\n",
            "0.4941592589020729\n",
            "[[170  34]\n",
            " [ 29 247]]\n",
            "0.86875 0.865283265989816\n",
            "0.23633351373045067\n",
            "0.3083265982568264\n",
            "[[185  19]\n",
            " [ 32 244]]\n",
            "0.89375 0.8921200957169739\n",
            "0.12631596762098765\n",
            "0.21583331376314163\n",
            "[[191  13]\n",
            " [ 21 255]]\n",
            "0.9291666666666667 0.9278846153846154\n",
            "[[191  13]\n",
            " [ 21 255]]\n",
            "f1 = 0.9278846153846154 acc = 0.9291666666666667\n",
            "0.9291666666666667 0.9278846153846154\n",
            "fold = 2\n",
            "0.729024527888549\n",
            "0.47045935690402985\n",
            "[[170  34]\n",
            " [ 22 254]]\n",
            "0.8833333333333333 0.8796475392220073\n",
            "0.2721168932161833\n",
            "0.3317703865468502\n",
            "[[183  21]\n",
            " [ 25 251]]\n",
            "0.9041666666666667 0.9022039543618454\n",
            "0.12993289157748222\n",
            "0.3124040216207504\n",
            "[[187  17]\n",
            " [ 24 252]]\n",
            "0.9145833333333333 0.9129877307394716\n",
            "[[187  17]\n",
            " [ 24 252]]\n",
            "f1 = 0.9129877307394716 acc = 0.9145833333333333\n",
            "0.9145833333333333 0.9129877307394716\n",
            "fold = 3\n",
            "0.6105430479112425\n",
            "0.5090584829449654\n",
            "[[189  15]\n",
            " [ 55 221]]\n",
            "0.8541666666666666 0.853515625\n",
            "0.22098538044251895\n",
            "0.27534809708595276\n",
            "[[188  16]\n",
            " [ 30 246]]\n",
            "0.9041666666666667 0.9027467009637238\n",
            "0.12211369389766141\n",
            "0.27858513966202736\n",
            "[[192  12]\n",
            " [ 31 245]]\n",
            "0.9104166666666667 0.9093110008743757\n",
            "[[192  12]\n",
            " [ 31 245]]\n",
            "f1 = 0.9093110008743757 acc = 0.9104166666666667\n",
            "0.9104166666666667 0.9093110008743757\n",
            "fold = 4\n",
            "0.5804081621922945\n",
            "0.5041044354438782\n",
            "[[173  31]\n",
            " [ 41 235]]\n",
            "0.85 0.8474549338794823\n",
            "0.21627440225136907\n",
            "0.297357976436615\n",
            "[[181  23]\n",
            " [ 23 253]]\n",
            "0.9041666666666667 0.9019607843137254\n",
            "0.11122362335261546\n",
            "0.3106403984129429\n",
            "[[184  20]\n",
            " [ 18 258]]\n",
            "0.9208333333333333 0.9189059415624834\n",
            "[[184  20]\n",
            " [ 18 258]]\n",
            "f1 = 0.9189059415624834 acc = 0.9208333333333333\n",
            "0.9208333333333333 0.9189059415624834\n",
            "*******7*********\n",
            "fold = 0\n",
            "0.7881747703803214\n",
            "0.584288701415062\n",
            "[[213  51]\n",
            " [ 44 172]]\n",
            "0.8020833333333334 0.800628719083242\n",
            "0.38025215189707906\n",
            "0.4659625366330147\n",
            "[[222  42]\n",
            " [ 46 170]]\n",
            "0.8166666666666667 0.8144894947649497\n",
            "0.2557906963323292\n",
            "0.36164670437574387\n",
            "[[234  30]\n",
            " [ 32 184]]\n",
            "0.8708333333333333 0.8694164107064504\n",
            "[[234  30]\n",
            " [ 32 184]]\n",
            "f1 = 0.8694164107064504 acc = 0.8708333333333333\n",
            "0.8708333333333333 0.8694164107064504\n",
            "fold = 1\n",
            "0.7189343916742426\n",
            "0.5843415558338165\n",
            "[[232  32]\n",
            " [ 55 161]]\n",
            "0.81875 0.8146956633637884\n",
            "0.3561685249993676\n",
            "0.4451330527663231\n",
            "[[224  40]\n",
            " [ 36 180]]\n",
            "0.8416666666666667 0.8403249527277821\n",
            "0.19579308087888517\n",
            "0.38498110324144363\n",
            "[[228  36]\n",
            " [ 30 186]]\n",
            "0.8625 0.8614391434419777\n",
            "[[228  36]\n",
            " [ 30 186]]\n",
            "f1 = 0.8614391434419777 acc = 0.8625\n",
            "0.8625 0.8614391434419777\n",
            "fold = 2\n",
            "0.8494589564047361\n",
            "0.631216011941433\n",
            "[[193  71]\n",
            " [ 50 166]]\n",
            "0.7479166666666667 0.7471165275546324\n",
            "0.5190970097717486\n",
            "0.40860651433467865\n",
            "[[223  41]\n",
            " [ 28 188]]\n",
            "0.85625 0.8554816188502237\n",
            "0.2091898028003542\n",
            "0.3355437144637108\n",
            "[[235  29]\n",
            " [ 24 192]]\n",
            "0.8895833333333333 0.8886900516733683\n",
            "[[235  29]\n",
            " [ 24 192]]\n",
            "f1 = 0.8886900516733683 acc = 0.8895833333333333\n",
            "0.8895833333333333 0.8886900516733683\n",
            "fold = 3\n",
            "0.8232030319540125\n",
            "0.6325470954179764\n",
            "[[191  73]\n",
            " [ 49 167]]\n",
            "0.7458333333333333 0.7451963241436925\n",
            "0.4558292141086177\n",
            "0.5788492187857628\n",
            "[[202  62]\n",
            " [ 50 166]]\n",
            "0.7666666666666667 0.7653467420909281\n",
            "0.2436770592865191\n",
            "0.4943960979580879\n",
            "[[216  48]\n",
            " [ 35 181]]\n",
            "0.8270833333333333 0.8261590487618633\n",
            "[[216  48]\n",
            " [ 35 181]]\n",
            "f1 = 0.8261590487618633 acc = 0.8270833333333333\n",
            "0.8270833333333333 0.8261590487618633\n",
            "fold = 4\n",
            "0.7488622085044259\n",
            "0.6173485368490219\n",
            "[[176  88]\n",
            " [ 21 195]]\n",
            "0.7729166666666667 0.7725603049917622\n",
            "0.3952053369660127\n",
            "0.38096143305301666\n",
            "[[228  36]\n",
            " [ 28 188]]\n",
            "0.8666666666666667 0.8657342657342657\n",
            "0.23575469616212344\n",
            "0.2933632917702198\n",
            "[[236  28]\n",
            " [ 18 198]]\n",
            "0.9041666666666667 0.9035622565034329\n",
            "[[236  28]\n",
            " [ 18 198]]\n",
            "f1 = 0.9035622565034329 acc = 0.9041666666666667\n",
            "0.9041666666666667 0.9035622565034329\n",
            "*******8*********\n",
            "fold = 0\n",
            "0.6545630771862833\n",
            "0.3978169485926628\n",
            "[[ 47  13]\n",
            " [ 39 381]]\n",
            "0.8916666666666667 0.789976776278146\n",
            "0.20672985381985964\n",
            "0.2801418714225292\n",
            "[[ 53   7]\n",
            " [ 38 382]]\n",
            "0.90625 0.8231812637628009\n",
            "0.10294867581442783\n",
            "0.28724416345357895\n",
            "[[ 55   5]\n",
            " [ 38 382]]\n",
            "0.9104166666666667 0.8328352406637995\n",
            "[[ 55   5]\n",
            " [ 38 382]]\n",
            "f1 = 0.8328352406637995 acc = 0.9104166666666667\n",
            "0.9104166666666667 0.8328352406637995\n",
            "fold = 1\n",
            "0.703052431344986\n",
            "0.4583148956298828\n",
            "[[ 41  19]\n",
            " [ 41 379]]\n",
            "0.875 0.7520575777402803\n",
            "0.19028225933250628\n",
            "0.2382367141544819\n",
            "[[ 51   9]\n",
            " [ 29 391]]\n",
            "0.9208333333333333 0.8411149825783972\n",
            "0.10029491948846139\n",
            "0.2433999516069889\n",
            "[[ 50  10]\n",
            " [ 31 389]]\n",
            "0.9145833333333333 0.8295794040474892\n",
            "[[ 51   9]\n",
            " [ 29 391]]\n",
            "f1 = 0.8411149825783972 acc = 0.9208333333333333\n",
            "0.9208333333333333 0.8411149825783972\n",
            "fold = 2\n",
            "0.6904718248467696\n",
            "0.415825791656971\n",
            "[[ 48  12]\n",
            " [ 38 382]]\n",
            "0.8958333333333334 0.7980545925751406\n",
            "0.23004567583924845\n",
            "0.31717468425631523\n",
            "[[ 53   7]\n",
            " [ 43 377]]\n",
            "0.8958333333333334 0.8086490623804057\n",
            "0.10682616127949011\n",
            "0.29338557831943035\n",
            "[[ 56   4]\n",
            " [ 40 380]]\n",
            "0.9083333333333333 0.831611174894757\n",
            "[[ 56   4]\n",
            " [ 40 380]]\n",
            "f1 = 0.831611174894757 acc = 0.9083333333333333\n",
            "0.9083333333333333 0.831611174894757\n",
            "fold = 3\n",
            "0.649732558350814\n",
            "0.37988217175006866\n",
            "[[ 55   5]\n",
            " [ 32 388]]\n",
            "0.9229166666666667 0.8513944323116702\n",
            "0.2365774257402671\n",
            "0.2251566331833601\n",
            "[[ 57   3]\n",
            " [ 29 391]]\n",
            "0.9333333333333333 0.8707549392480898\n",
            "0.11319625593329731\n",
            "0.22353743948042393\n",
            "[[ 56   4]\n",
            " [ 33 387]]\n",
            "0.9229166666666667 0.8530275821547679\n",
            "[[ 57   3]\n",
            " [ 29 391]]\n",
            "f1 = 0.8707549392480898 acc = 0.9333333333333333\n",
            "0.9333333333333333 0.8707549392480898\n",
            "fold = 4\n",
            "0.6350584986962771\n",
            "0.548623189330101\n",
            "[[ 54   6]\n",
            " [ 76 344]]\n",
            "0.8291666666666667 0.7309637730690363\n",
            "0.22630552280890315\n",
            "0.3462803401052952\n",
            "[[ 50  10]\n",
            " [ 39 381]]\n",
            "0.8979166666666667 0.8053608520428006\n",
            "0.10078253048030954\n",
            "0.33486249297857285\n",
            "[[ 51   9]\n",
            " [ 40 380]]\n",
            "0.8979166666666667 0.8074640427639388\n",
            "[[ 50  10]\n",
            " [ 39 381]]\n",
            "f1 = 0.8053608520428006 acc = 0.8979166666666667\n",
            "0.8979166666666667 0.8053608520428006\n",
            "*******9*********\n",
            "fold = 0\n",
            "0.6891394320287203\n",
            "0.6021019890904427\n",
            "[[ 51   9]\n",
            " [101 319]]\n",
            "0.7708333333333334 0.6670366259711431\n",
            "0.21893974158324694\n",
            "0.3443134017288685\n",
            "[[ 53   7]\n",
            " [ 48 372]]\n",
            "0.8854166666666666 0.7947745240556907\n",
            "0.09737506234332134\n",
            "0.29012639075517654\n",
            "[[ 54   6]\n",
            " [ 30 390]]\n",
            "0.925 0.8529411764705883\n",
            "[[ 54   6]\n",
            " [ 30 390]]\n",
            "f1 = 0.8529411764705883 acc = 0.925\n",
            "0.925 0.8529411764705883\n",
            "fold = 1\n",
            "0.6149162022691024\n",
            "0.43115512281656265\n",
            "[[ 54   6]\n",
            " [ 38 382]]\n",
            "0.9083333333333333 0.8280354351224597\n",
            "0.18220851452727066\n",
            "0.25205686315894127\n",
            "[[ 56   4]\n",
            " [ 40 380]]\n",
            "0.9083333333333333 0.831611174894757\n",
            "0.08980109424967515\n",
            "0.2579743564128876\n",
            "[[ 57   3]\n",
            " [ 36 384]]\n",
            "0.91875 0.8483854508346089\n",
            "[[ 57   3]\n",
            " [ 36 384]]\n",
            "f1 = 0.8483854508346089 acc = 0.91875\n",
            "0.91875 0.8483854508346089\n",
            "fold = 2\n",
            "0.6773692291033896\n",
            "0.5492639392614365\n",
            "[[ 45  15]\n",
            " [ 81 339]]\n",
            "0.8 0.6799199799949988\n",
            "0.20160325342103055\n",
            "0.321570985019207\n",
            "[[ 55   5]\n",
            " [ 49 371]]\n",
            "0.8875 0.8014462556685868\n",
            "0.09142760755984407\n",
            "0.26544376090168953\n",
            "[[ 57   3]\n",
            " [ 32 388]]\n",
            "0.9270833333333334 0.8609720371734291\n",
            "[[ 57   3]\n",
            " [ 32 388]]\n",
            "f1 = 0.8609720371734291 acc = 0.9270833333333334\n",
            "0.9270833333333334 0.8609720371734291\n",
            "fold = 3\n",
            "0.79283039977676\n",
            "0.3761252872645855\n",
            "[[ 47  13]\n",
            " [ 25 395]]\n",
            "0.9208333333333333 0.8331137461572244\n",
            "0.2162024653271625\n",
            "0.2724780738353729\n",
            "[[ 52   8]\n",
            " [ 35 385]]\n",
            "0.9104166666666667 0.8272962321459949\n",
            "0.09257933948385089\n",
            "0.2025623843073845\n",
            "[[ 54   6]\n",
            " [ 22 398]]\n",
            "0.9416666666666667 0.8800685322672759\n",
            "[[ 54   6]\n",
            " [ 22 398]]\n",
            "f1 = 0.8800685322672759 acc = 0.9416666666666667\n",
            "0.9416666666666667 0.8800685322672759\n",
            "fold = 4\n",
            "0.7607707726327997\n",
            "0.48112694174051285\n",
            "[[ 48  12]\n",
            " [ 55 365]]\n",
            "0.8604166666666667 0.7524459052736104\n",
            "0.21603179997519442\n",
            "0.23120247013866901\n",
            "[[ 55   5]\n",
            " [ 26 394]]\n",
            "0.9354166666666667 0.8711454030602966\n",
            "0.09247390337680515\n",
            "0.1985197220928967\n",
            "[[ 57   3]\n",
            " [ 24 396]]\n",
            "0.94375 0.8877718026654198\n",
            "[[ 57   3]\n",
            " [ 24 396]]\n",
            "f1 = 0.8877718026654198 acc = 0.94375\n",
            "0.94375 0.8877718026654198\n",
            "*******10*********\n",
            "fold = 0\n",
            "0.6444851630612424\n",
            "0.5153869912028313\n",
            "[[141  15]\n",
            " [ 57 267]]\n",
            "0.85 0.8388991441517033\n",
            "0.2647531260001032\n",
            "0.34871142730116844\n",
            "[[142  14]\n",
            " [ 42 282]]\n",
            "0.8833333333333333 0.8724857685009488\n",
            "0.18571323470065468\n",
            "0.3591959737241268\n",
            "[[146  10]\n",
            " [ 43 281]]\n",
            "0.8895833333333333 0.8800989749027925\n",
            "[[146  10]\n",
            " [ 43 281]]\n",
            "f1 = 0.8800989749027925 acc = 0.8895833333333333\n",
            "0.8895833333333333 0.8800989749027925\n",
            "fold = 1\n",
            "0.7027546073261061\n",
            "0.5439162328839302\n",
            "[[128  28]\n",
            " [ 50 274]]\n",
            "0.8375 0.8209332134453139\n",
            "0.28532859369328145\n",
            "0.35913069173693657\n",
            "[[133  23]\n",
            " [ 36 288]]\n",
            "0.8770833333333333 0.8627740763173835\n",
            "0.17488955706357956\n",
            "0.4103395491838455\n",
            "[[135  21]\n",
            " [ 30 294]]\n",
            "0.89375 0.8806546443771665\n",
            "[[135  21]\n",
            " [ 30 294]]\n",
            "f1 = 0.8806546443771665 acc = 0.89375\n",
            "0.89375 0.8806546443771665\n",
            "fold = 2\n",
            "0.8862194434592598\n",
            "0.4643285572528839\n",
            "[[129  27]\n",
            " [ 32 292]]\n",
            "0.8770833333333333 0.8610613694678435\n",
            "0.38327683900531967\n",
            "0.29757800698280334\n",
            "[[140  16]\n",
            " [ 34 290]]\n",
            "0.8958333333333334 0.8845598845598845\n",
            "0.21684091538190842\n",
            "0.29423847422003746\n",
            "[[142  14]\n",
            " [ 36 288]]\n",
            "0.8958333333333334 0.8852135983623807\n",
            "[[140  16]\n",
            " [ 34 290]]\n",
            "f1 = 0.8845598845598845 acc = 0.8958333333333334\n",
            "0.8958333333333334 0.8845598845598845\n",
            "fold = 3\n",
            "0.723026211324491\n",
            "0.4683275446295738\n",
            "[[125  31]\n",
            " [ 27 297]]\n",
            "0.8791666666666667 0.8613656282367939\n",
            "0.3303273524108686\n",
            "0.3233666568994522\n",
            "[[138  18]\n",
            " [ 28 296]]\n",
            "0.9041666666666667 0.8925212718316167\n",
            "0.1927882828994801\n",
            "0.36332161724567413\n",
            "[[141  15]\n",
            " [ 27 297]]\n",
            "0.9125 0.9021663172606569\n",
            "[[141  15]\n",
            " [ 27 297]]\n",
            "f1 = 0.9021663172606569 acc = 0.9125\n",
            "0.9125 0.9021663172606569\n",
            "fold = 4\n",
            "0.7643197461178428\n",
            "0.5467755421996117\n",
            "[[131  25]\n",
            " [ 56 268]]\n",
            "0.83125 0.8162840037612638\n",
            "0.3141757053764243\n",
            "0.42861059680581093\n",
            "[[138  18]\n",
            " [ 49 275]]\n",
            "0.8604166666666667 0.8480373858272181\n",
            "0.18167521216367422\n",
            "0.35958515852689743\n",
            "[[145  11]\n",
            " [ 32 292]]\n",
            "0.9104166666666667 0.901145164303059\n",
            "[[145  11]\n",
            " [ 32 292]]\n",
            "f1 = 0.901145164303059 acc = 0.9104166666666667\n",
            "0.9104166666666667 0.901145164303059\n",
            "*******11*********\n",
            "fold = 0\n",
            "0.557313314393947\n",
            "0.4003036320209503\n",
            "[[185  31]\n",
            " [ 12 252]]\n",
            "0.9104166666666667 0.9086365869745164\n",
            "0.15049561152332708\n",
            "0.1892197635024786\n",
            "[[202  14]\n",
            " [  5 259]]\n",
            "0.9604166666666667 0.9598504959256178\n",
            "0.07069767266511917\n",
            "0.15329376934096217\n",
            "[[204  12]\n",
            " [  3 261]]\n",
            "0.96875 0.9683030230991719\n",
            "[[204  12]\n",
            " [  3 261]]\n",
            "f1 = 0.9683030230991719 acc = 0.96875\n",
            "0.96875 0.9683030230991719\n",
            "fold = 1\n",
            "0.5718249584499159\n",
            "0.4024574011564255\n",
            "[[195  21]\n",
            " [ 27 237]]\n",
            "0.9 0.8992284679578019\n",
            "0.13271348119566315\n",
            "0.19987060502171516\n",
            "[[206  10]\n",
            " [ 22 242]]\n",
            "0.9333333333333333 0.9329562120259794\n",
            "0.06688351164522924\n",
            "0.17645731940865517\n",
            "[[208   8]\n",
            " [ 18 246]]\n",
            "0.9458333333333333 0.9454917101975926\n",
            "[[208   8]\n",
            " [ 18 246]]\n",
            "f1 = 0.9454917101975926 acc = 0.9458333333333333\n",
            "0.9458333333333333 0.9454917101975926\n",
            "fold = 2\n",
            "0.580598162977319\n",
            "0.4149407520890236\n",
            "[[182  34]\n",
            " [ 24 240]]\n",
            "0.8791666666666667 0.8773762751281735\n",
            "0.15993182400339528\n",
            "0.24673696234822273\n",
            "[[198  18]\n",
            " [ 17 247]]\n",
            "0.9270833333333334 0.9263154662959048\n",
            "0.06886921774007772\n",
            "0.22755303978919983\n",
            "[[204  12]\n",
            " [ 16 248]]\n",
            "0.9416666666666667 0.9411723510049723\n",
            "[[204  12]\n",
            " [ 16 248]]\n",
            "f1 = 0.9411723510049723 acc = 0.9416666666666667\n",
            "0.9416666666666667 0.9411723510049723\n",
            "fold = 3\n",
            "0.5752554206471694\n",
            "0.4172139912843704\n",
            "[[187  29]\n",
            " [ 17 247]]\n",
            "0.9041666666666667 0.9026455026455027\n",
            "0.15314831290590136\n",
            "0.20111462101340294\n",
            "[[206  10]\n",
            " [ 24 240]]\n",
            "0.9291666666666667 0.9288094781106593\n",
            "0.057550216485795225\n",
            "0.1971889417618513\n",
            "[[207   9]\n",
            " [ 18 246]]\n",
            "0.94375 0.9433761944083991\n",
            "[[207   9]\n",
            " [ 18 246]]\n",
            "f1 = 0.9433761944083991 acc = 0.94375\n",
            "0.94375 0.9433761944083991\n",
            "fold = 4\n",
            "0.6406908192132649\n",
            "0.4340711459517479\n",
            "[[190  26]\n",
            " [ 27 237]]\n",
            "0.8895833333333333 0.8885144462314465\n",
            "0.17049493287739\n",
            "0.26388853788375854\n",
            "[[197  19]\n",
            " [ 21 243]]\n",
            "0.9166666666666666 0.9158942370030314\n",
            "0.07596884011045883\n",
            "0.19442949071526527\n",
            "[[198  18]\n",
            " [ 15 249]]\n",
            "0.93125 0.930465015210778\n",
            "[[198  18]\n",
            " [ 15 249]]\n",
            "f1 = 0.930465015210778 acc = 0.93125\n",
            "0.93125 0.930465015210778\n",
            "*******12*********\n",
            "fold = 0\n",
            "0.5848448598071149\n",
            "0.35698986053466797\n",
            "[[227  13]\n",
            " [ 26 214]]\n",
            "0.91875 0.9186903588135393\n",
            "0.1670594487927462\n",
            "0.2067260704934597\n",
            "[[228  12]\n",
            " [ 16 224]]\n",
            "0.9416666666666667 0.9416626154594068\n",
            "0.06895326573009554\n",
            "0.2139340415596962\n",
            "[[229  11]\n",
            " [ 17 223]]\n",
            "0.9416666666666667 0.9416575506589571\n",
            "[[228  12]\n",
            " [ 16 224]]\n",
            "f1 = 0.9416626154594068 acc = 0.9416666666666667\n",
            "0.9416666666666667 0.9416626154594068\n",
            "fold = 1\n",
            "0.5556946592895609\n",
            "0.38996969163417816\n",
            "[[219  21]\n",
            " [ 32 208]]\n",
            "0.8895833333333333 0.8895253149440461\n",
            "0.14443965432675263\n",
            "0.2562949135899544\n",
            "[[222  18]\n",
            " [ 21 219]]\n",
            "0.91875 0.9187468260478926\n",
            "0.06298605940843884\n",
            "0.28899015858769417\n",
            "[[227  13]\n",
            " [ 20 220]]\n",
            "0.93125 0.9312353755790077\n",
            "[[227  13]\n",
            " [ 20 220]]\n",
            "f1 = 0.9312353755790077 acc = 0.93125\n",
            "0.93125 0.9312353755790077\n",
            "fold = 2\n",
            "0.5891315121399728\n",
            "0.3365563303232193\n",
            "[[227  13]\n",
            " [ 23 217]]\n",
            "0.925 0.9249674337820235\n",
            "0.15439490993556224\n",
            "0.20827770605683327\n",
            "[[229  11]\n",
            " [ 16 224]]\n",
            "0.94375 0.9437438958220292\n",
            "0.07358529551052734\n",
            "0.18661941215395927\n",
            "[[227  13]\n",
            " [ 13 227]]\n",
            "0.9458333333333333 0.9458333333333333\n",
            "[[227  13]\n",
            " [ 13 227]]\n",
            "f1 = 0.9458333333333333 acc = 0.9458333333333333\n",
            "0.9458333333333333 0.9458333333333333\n",
            "fold = 3\n",
            "0.5150414383725116\n",
            "0.37984901666641235\n",
            "[[217  23]\n",
            " [ 21 219]]\n",
            "0.9083333333333333 0.9083317418705186\n",
            "0.12830872500413343\n",
            "0.2690752297639847\n",
            "[[224  16]\n",
            " [ 16 224]]\n",
            "0.9333333333333333 0.9333333333333333\n",
            "0.051032955709256624\n",
            "0.274401618167758\n",
            "[[225  15]\n",
            " [ 13 227]]\n",
            "0.9416666666666667 0.9416656539176027\n",
            "[[225  15]\n",
            " [ 13 227]]\n",
            "f1 = 0.9416656539176027 acc = 0.9416666666666667\n",
            "0.9416666666666667 0.9416656539176027\n",
            "fold = 4\n",
            "0.569999983436183\n",
            "0.44354503601789474\n",
            "[[179  61]\n",
            " [  8 232]]\n",
            "0.85625 0.8544757921007422\n",
            "0.16815778456236186\n",
            "0.22583234123885632\n",
            "[[216  24]\n",
            " [ 10 230]]\n",
            "0.9291666666666667 0.9291063578391341\n",
            "0.07662981532906231\n",
            "0.1835399717092514\n",
            "[[224  16]\n",
            " [ 10 230]]\n",
            "0.9458333333333333 0.9458248684690316\n",
            "[[224  16]\n",
            " [ 10 230]]\n",
            "f1 = 0.9458248684690316 acc = 0.9458333333333333\n",
            "0.9458333333333333 0.9458248684690316\n",
            "*******13*********\n",
            "fold = 0\n",
            "0.7949096654590807\n",
            "0.6463382616639137\n",
            "[[140  28]\n",
            " [ 82 230]]\n",
            "0.7708333333333334 0.7624831309041836\n",
            "0.4212241125734229\n",
            "0.42030370235443115\n",
            "[[139  29]\n",
            " [ 38 274]]\n",
            "0.8604166666666667 0.8484270060091905\n",
            "0.22480849333499608\n",
            "0.4081917181611061\n",
            "[[145  23]\n",
            " [ 38 274]]\n",
            "0.8729166666666667 0.8630233112991734\n",
            "[[145  23]\n",
            " [ 38 274]]\n",
            "f1 = 0.8630233112991734 acc = 0.8729166666666667\n",
            "0.8729166666666667 0.8630233112991734\n",
            "fold = 1\n",
            "0.7805429163732027\n",
            "0.6021462976932526\n",
            "[[145  23]\n",
            " [ 78 234]]\n",
            "0.7895833333333333 0.7820917929332656\n",
            "0.32086852977150365\n",
            "0.35236000642180443\n",
            "[[144  24]\n",
            " [ 33 279]]\n",
            "0.88125 0.8710498409331919\n",
            "0.22900527401974327\n",
            "0.3181949760764837\n",
            "[[152  16]\n",
            " [ 36 276]]\n",
            "0.8916666666666667 0.8839199345189375\n",
            "[[152  16]\n",
            " [ 36 276]]\n",
            "f1 = 0.8839199345189375 acc = 0.8916666666666667\n",
            "0.8916666666666667 0.8839199345189375\n",
            "fold = 2\n",
            "0.7281938132486845\n",
            "0.5954676494002342\n",
            "[[126  42]\n",
            " [ 49 263]]\n",
            "0.8104166666666667 0.7936030165712964\n",
            "0.31265852404268163\n",
            "0.37066950649023056\n",
            "[[143  25]\n",
            " [ 33 279]]\n",
            "0.8791666666666667 0.8686197523406826\n",
            "0.19532541185617447\n",
            "0.3955099508166313\n",
            "[[138  30]\n",
            " [ 42 270]]\n",
            "0.85 0.8377281947261663\n",
            "[[143  25]\n",
            " [ 33 279]]\n",
            "f1 = 0.8686197523406826 acc = 0.8791666666666667\n",
            "0.8791666666666667 0.8686197523406826\n",
            "fold = 3\n",
            "0.7106636088145407\n",
            "0.5917904153466225\n",
            "[[127  41]\n",
            " [ 55 257]]\n",
            "0.8 0.7841686182669789\n",
            "0.34906029465951416\n",
            "0.38075509667396545\n",
            "[[143  25]\n",
            " [ 40 272]]\n",
            "0.8645833333333334 0.8540412333515782\n",
            "0.20536981326969048\n",
            "0.35697735100984573\n",
            "[[150  18]\n",
            " [ 36 276]]\n",
            "0.8875 0.8791743581137774\n",
            "[[150  18]\n",
            " [ 36 276]]\n",
            "f1 = 0.8791743581137774 acc = 0.8875\n",
            "0.8875 0.8791743581137774\n",
            "fold = 4\n",
            "0.6843810018740202\n",
            "0.6203640550374985\n",
            "[[ 63 105]\n",
            " [ 16 296]]\n",
            "0.7479166666666667 0.6702079938220782\n",
            "0.2983080054584302\n",
            "0.4141346886754036\n",
            "[[134  34]\n",
            " [ 32 280]]\n",
            "0.8625 0.8484819498383425\n",
            "0.2222979037385238\n",
            "0.47429290413856506\n",
            "[[137  31]\n",
            " [ 37 275]]\n",
            "0.8583333333333333 0.845568614091864\n",
            "[[134  34]\n",
            " [ 32 280]]\n",
            "f1 = 0.8484819498383425 acc = 0.8625\n",
            "0.8625 0.8484819498383425\n",
            "*******14*********\n",
            "fold = 0\n",
            "0.6070490197131508\n",
            "0.4886054992675781\n",
            "[[138  18]\n",
            " [ 54 270]]\n",
            "0.85 0.8377281947261663\n",
            "0.23221819063550547\n",
            "0.3084253557026386\n",
            "[[133  23]\n",
            " [ 32 292]]\n",
            "0.8854166666666666 0.8712942243283168\n",
            "0.14640655211712184\n",
            "0.292035112157464\n",
            "[[138  18]\n",
            " [ 29 295]]\n",
            "0.9020833333333333 0.8903529022945209\n",
            "[[138  18]\n",
            " [ 29 295]]\n",
            "f1 = 0.8903529022945209 acc = 0.9020833333333333\n",
            "0.9020833333333333 0.8903529022945209\n",
            "fold = 1\n",
            "0.6022200380500994\n",
            "0.4498758018016815\n",
            "[[124  32]\n",
            " [ 27 297]]\n",
            "0.8770833333333333 0.8587326845279366\n",
            "0.23280321924309982\n",
            "0.35159066691994667\n",
            "[[141  15]\n",
            " [ 39 285]]\n",
            "0.8875 0.8763736263736264\n",
            "0.1424103098872461\n",
            "0.3802580125629902\n",
            "[[139  17]\n",
            " [ 30 294]]\n",
            "0.9020833333333333 0.8906844336765597\n",
            "[[139  17]\n",
            " [ 30 294]]\n",
            "f1 = 0.8906844336765597 acc = 0.9020833333333333\n",
            "0.9020833333333333 0.8906844336765597\n",
            "fold = 2\n",
            "0.6667066122356214\n",
            "0.4370211362838745\n",
            "[[123  33]\n",
            " [ 28 296]]\n",
            "0.8729166666666667 0.8539439619695617\n",
            "0.26488405936642695\n",
            "0.28211890533566475\n",
            "[[141  15]\n",
            " [ 33 291]]\n",
            "0.9 0.8891774891774892\n",
            "0.16602952739125804\n",
            "0.27443137019872665\n",
            "[[145  11]\n",
            " [ 33 291]]\n",
            "0.9083333333333333 0.898987966558895\n",
            "[[145  11]\n",
            " [ 33 291]]\n",
            "f1 = 0.898987966558895 acc = 0.9083333333333333\n",
            "0.9083333333333333 0.898987966558895\n",
            "fold = 3\n",
            "0.7155509104854182\n",
            "0.47832319140434265\n",
            "[[148   8]\n",
            " [ 62 262]]\n",
            "0.8541666666666666 0.8454490257768947\n",
            "0.25313178253801244\n",
            "0.33381839096546173\n",
            "[[143  13]\n",
            " [ 34 290]]\n",
            "0.9020833333333333 0.8919493656335762\n",
            "0.1587815159245541\n",
            "0.33408397808671\n",
            "[[144  12]\n",
            " [ 34 290]]\n",
            "0.9041666666666667 0.8943965104933902\n",
            "[[144  12]\n",
            " [ 34 290]]\n",
            "f1 = 0.8943965104933902 acc = 0.9041666666666667\n",
            "0.9041666666666667 0.8943965104933902\n",
            "fold = 4\n",
            "0.6046019620017001\n",
            "0.44357988238334656\n",
            "[[136  20]\n",
            " [ 35 289]]\n",
            "0.8854166666666666 0.872458222821282\n",
            "0.24933739751577377\n",
            "0.3110678270459175\n",
            "[[140  16]\n",
            " [ 30 294]]\n",
            "0.9041666666666667 0.8931702502370769\n",
            "0.14515632410582743\n",
            "0.35420433804392815\n",
            "[[141  15]\n",
            " [ 32 292]]\n",
            "0.9020833333333333 0.8913289563051845\n",
            "[[140  16]\n",
            " [ 30 294]]\n",
            "f1 = 0.8931702502370769 acc = 0.9041666666666667\n",
            "0.9041666666666667 0.8931702502370769\n",
            "*******15*********\n",
            "fold = 0\n",
            "0.6784612269778001\n",
            "0.44138188660144806\n",
            "[[122  22]\n",
            " [ 29 307]]\n",
            "0.89375 0.8752134573722442\n",
            "0.20684799042187238\n",
            "0.29807181283831596\n",
            "[[131  13]\n",
            " [ 28 308]]\n",
            "0.9145833333333333 0.901140799011408\n",
            "0.10926066731151782\n",
            "0.23507530242204666\n",
            "[[132  12]\n",
            " [ 25 311]]\n",
            "0.9229166666666667 0.9104653683472895\n",
            "[[132  12]\n",
            " [ 25 311]]\n",
            "f1 = 0.9104653683472895 acc = 0.9229166666666667\n",
            "0.9229166666666667 0.9104653683472895\n",
            "fold = 1\n",
            "0.6866424805239627\n",
            "0.46555014699697495\n",
            "[[114  30]\n",
            " [ 38 298]]\n",
            "0.8583333333333333 0.8339303158580267\n",
            "0.23224029493959328\n",
            "0.2523659225553274\n",
            "[[133  11]\n",
            " [ 26 310]]\n",
            "0.9229166666666667 0.910785599107856\n",
            "0.1006428881695396\n",
            "0.21327382698655128\n",
            "[[135   9]\n",
            " [ 21 315]]\n",
            "0.9375 0.9272727272727272\n",
            "[[135   9]\n",
            " [ 21 315]]\n",
            "f1 = 0.9272727272727272 acc = 0.9375\n",
            "0.9375 0.9272727272727272\n",
            "fold = 2\n",
            "0.6859305838220998\n",
            "0.4802943915128708\n",
            "[[ 99  45]\n",
            " [ 21 315]]\n",
            "0.8625 0.8275862068965517\n",
            "0.2025654837489128\n",
            "0.27327628806233406\n",
            "[[125  19]\n",
            " [ 25 311]]\n",
            "0.9083333333333333 0.892137034994178\n",
            "0.10669926514751032\n",
            "0.2469512540847063\n",
            "[[130  14]\n",
            " [ 22 314]]\n",
            "0.925 0.9120807554542494\n",
            "[[130  14]\n",
            " [ 22 314]]\n",
            "f1 = 0.9120807554542494 acc = 0.925\n",
            "0.925 0.9120807554542494\n",
            "fold = 3\n",
            "0.6791975717795523\n",
            "0.48118074983358383\n",
            "[[120  24]\n",
            " [ 43 293]]\n",
            "0.8604166666666667 0.8395777942944367\n",
            "0.22526120708176964\n",
            "0.25488196685910225\n",
            "[[130  14]\n",
            " [ 25 311]]\n",
            "0.91875 0.9052818522660002\n",
            "0.12341461271831863\n",
            "0.22918467968702316\n",
            "[[130  14]\n",
            " [ 21 315]]\n",
            "0.9270833333333334 0.9143621766280107\n",
            "[[130  14]\n",
            " [ 21 315]]\n",
            "f1 = 0.9143621766280107 acc = 0.9270833333333334\n",
            "0.9270833333333334 0.9143621766280107\n",
            "fold = 4\n",
            "0.8075361565539712\n",
            "0.44358788430690765\n",
            "[[122  22]\n",
            " [ 43 293]]\n",
            "0.8645833333333334 0.8448988113880065\n",
            "0.2516174763441086\n",
            "0.26236950047314167\n",
            "[[132  12]\n",
            " [ 30 306]]\n",
            "0.9125 0.8992624572764886\n",
            "0.12017059208531129\n",
            "0.23121432960033417\n",
            "[[136   8]\n",
            " [ 24 312]]\n",
            "0.9333333333333333 0.9229781771501926\n",
            "[[136   8]\n",
            " [ 24 312]]\n",
            "f1 = 0.9229781771501926 acc = 0.9333333333333333\n",
            "0.9333333333333333 0.9229781771501926\n",
            "*******16*********\n",
            "fold = 0\n",
            "0.7316627933790809\n",
            "0.4520326629281044\n",
            "[[ 63   9]\n",
            " [ 58 350]]\n",
            "0.8604166666666667 0.7827482081455911\n",
            "0.20456691400000923\n",
            "0.26472290605306625\n",
            "[[ 68   4]\n",
            " [ 30 378]]\n",
            "0.9291666666666667 0.8784810126582279\n",
            "0.10721921950186554\n",
            "0.2577234450727701\n",
            "[[ 69   3]\n",
            " [ 27 381]]\n",
            "0.9375 0.8917748917748918\n",
            "[[ 69   3]\n",
            " [ 27 381]]\n",
            "f1 = 0.8917748917748918 acc = 0.9375\n",
            "0.9375 0.8917748917748918\n",
            "fold = 1\n",
            "0.6488685043234574\n",
            "0.42505355179309845\n",
            "[[ 51  21]\n",
            " [ 36 372]]\n",
            "0.88125 0.7851741926365627\n",
            "0.19683793716524778\n",
            "0.26988574117422104\n",
            "[[ 64   8]\n",
            " [ 30 378]]\n",
            "0.9208333333333333 0.8616126976419531\n",
            "0.10720740866504218\n",
            "0.244874507188797\n",
            "[[ 65   7]\n",
            " [ 26 382]]\n",
            "0.93125 0.8780703712541664\n",
            "[[ 65   7]\n",
            " [ 26 382]]\n",
            "f1 = 0.8780703712541664 acc = 0.93125\n",
            "0.93125 0.8780703712541664\n",
            "fold = 2\n",
            "0.6614649531088377\n",
            "0.3505481071770191\n",
            "[[ 55  17]\n",
            " [ 17 391]]\n",
            "0.9291666666666667 0.8611111111111112\n",
            "0.23358786380604693\n",
            "0.2538311257958412\n",
            "[[ 62  10]\n",
            " [ 29 379]]\n",
            "0.91875 0.8559013478458329\n",
            "0.11425690568591419\n",
            "0.19003361463546753\n",
            "[[ 68   4]\n",
            " [ 23 385]]\n",
            "0.94375 0.9002393946624998\n",
            "[[ 68   4]\n",
            " [ 23 385]]\n",
            "f1 = 0.9002393946624998 acc = 0.94375\n",
            "0.94375 0.9002393946624998\n",
            "fold = 3\n",
            "0.6254801985464598\n",
            "0.5000842660665512\n",
            "[[ 60  12]\n",
            " [ 59 349]]\n",
            "0.8520833333333333 0.7679722764997038\n",
            "0.18716547363682798\n",
            "0.21639967896044254\n",
            "[[ 69   3]\n",
            " [ 27 381]]\n",
            "0.9375 0.8917748917748918\n",
            "0.08526529018816195\n",
            "0.1858133003115654\n",
            "[[ 70   2]\n",
            " [ 22 386]]\n",
            "0.95 0.9117538914082608\n",
            "[[ 70   2]\n",
            " [ 22 386]]\n",
            "f1 = 0.9117538914082608 acc = 0.95\n",
            "0.95 0.9117538914082608\n",
            "fold = 4\n",
            "0.6564437111741618\n",
            "0.4895562008023262\n",
            "[[ 65   7]\n",
            " [ 60 348]]\n",
            "0.8604166666666667 0.7860436029299253\n",
            "0.16517524146719983\n",
            "0.24018754810094833\n",
            "[[ 68   4]\n",
            " [ 31 377]]\n",
            "0.9270833333333334 0.8754808440619928\n",
            "0.08262373271741365\n",
            "0.2166480701416731\n",
            "[[ 68   4]\n",
            " [ 22 386]]\n",
            "0.9458333333333333 0.9034623596027105\n",
            "[[ 68   4]\n",
            " [ 22 386]]\n",
            "f1 = 0.9034623596027105 acc = 0.9458333333333333\n",
            "0.9458333333333333 0.9034623596027105\n",
            "*******17*********\n",
            "fold = 0\n",
            "0.6291972790893755\n",
            "0.467699833214283\n",
            "[[ 82  14]\n",
            " [ 44 340]]\n",
            "0.8791666666666667 0.8300739764154399\n",
            "0.2522716600643961\n",
            "0.326059240847826\n",
            "[[ 88   8]\n",
            " [ 39 345]]\n",
            "0.9020833333333333 0.8627328096573796\n",
            "0.1418768547867474\n",
            "0.3154183551669121\n",
            "[[ 89   7]\n",
            " [ 35 349]]\n",
            "0.9125 0.8761670761670761\n",
            "[[ 89   7]\n",
            " [ 35 349]]\n",
            "f1 = 0.8761670761670761 acc = 0.9125\n",
            "0.9125 0.8761670761670761\n",
            "fold = 1\n",
            "0.6628865991768084\n",
            "0.4528771862387657\n",
            "[[ 76  20]\n",
            " [ 32 352]]\n",
            "0.8916666666666667 0.8381574852163088\n",
            "0.2582610453429975\n",
            "0.3028177171945572\n",
            "[[ 85  11]\n",
            " [ 38 346]]\n",
            "0.8979166666666667 0.8550644260810086\n",
            "0.1297035848623828\n",
            "0.315657801926136\n",
            "[[ 84  12]\n",
            " [ 41 343]]\n",
            "0.8895833333333333 0.844231228454742\n",
            "[[ 85  11]\n",
            " [ 38 346]]\n",
            "f1 = 0.8550644260810086 acc = 0.8979166666666667\n",
            "0.8979166666666667 0.8550644260810086\n",
            "fold = 2\n",
            "0.68328258865758\n",
            "0.5939573720097542\n",
            "[[ 87   9]\n",
            " [ 88 296]]\n",
            "0.7979166666666667 0.7506413380534387\n",
            "0.25511209705942556\n",
            "0.3709454610943794\n",
            "[[ 84  12]\n",
            " [ 45 339]]\n",
            "0.88125 0.8345578231292516\n",
            "0.12762378783602463\n",
            "0.3118271492421627\n",
            "[[ 90   6]\n",
            " [ 33 351]]\n",
            "0.91875 0.8846431146359048\n",
            "[[ 90   6]\n",
            " [ 33 351]]\n",
            "f1 = 0.8846431146359048 acc = 0.91875\n",
            "0.91875 0.8846431146359048\n",
            "fold = 3\n",
            "0.79359633201047\n",
            "0.5470118671655655\n",
            "[[ 82  14]\n",
            " [ 78 306]]\n",
            "0.8083333333333333 0.7549715909090908\n",
            "0.2564623214696583\n",
            "0.32872970402240753\n",
            "[[ 87   9]\n",
            " [ 39 345]]\n",
            "0.9 0.8593715666886398\n",
            "0.13550401380971858\n",
            "0.3345392346382141\n",
            "[[ 88   8]\n",
            " [ 36 348]]\n",
            "0.9083333333333333 0.8702702702702703\n",
            "[[ 88   8]\n",
            " [ 36 348]]\n",
            "f1 = 0.8702702702702703 acc = 0.9083333333333333\n",
            "0.9083333333333333 0.8702702702702703\n",
            "fold = 4\n",
            "0.7945281439705899\n",
            "0.4029347747564316\n",
            "[[ 81  15]\n",
            " [ 31 353]]\n",
            "0.9041666666666667 0.8588379705400983\n",
            "0.307587552227472\n",
            "0.24961640313267708\n",
            "[[ 88   8]\n",
            " [ 31 353]]\n",
            "0.91875 0.8831278289371001\n",
            "0.16805105734812587\n",
            "0.25217500142753124\n",
            "[[ 86  10]\n",
            " [ 27 357]]\n",
            "0.9229166666666667 0.8868494320172784\n",
            "[[ 86  10]\n",
            " [ 27 357]]\n",
            "f1 = 0.8868494320172784 acc = 0.9229166666666667\n",
            "0.9229166666666667 0.8868494320172784\n",
            "*******18*********\n",
            "fold = 0\n",
            "0.7001180303724188\n",
            "0.4785465598106384\n",
            "[[118  14]\n",
            " [ 55 293]]\n",
            "0.85625 0.8342134901764484\n",
            "0.4142457717343381\n",
            "0.4637451618909836\n",
            "[[108  24]\n",
            " [ 49 299]]\n",
            "0.8479166666666667 0.8193059988964465\n",
            "0.28024221133244664\n",
            "0.4913673475384712\n",
            "[[114  18]\n",
            " [ 51 297]]\n",
            "0.85625 0.8318021847433612\n",
            "[[118  14]\n",
            " [ 55 293]]\n",
            "f1 = 0.8342134901764484 acc = 0.85625\n",
            "0.85625 0.8342134901764484\n",
            "fold = 1\n",
            "0.6461019970868763\n",
            "0.5188049972057343\n",
            "[[120  12]\n",
            " [ 58 290]]\n",
            "0.8541666666666666 0.8332506203473946\n",
            "0.3499207057450947\n",
            "0.34703780710697174\n",
            "[[121  11]\n",
            " [ 30 318]]\n",
            "0.9145833333333333 0.8972811875296857\n",
            "0.2407304632820581\n",
            "0.2937459461390972\n",
            "[[122  10]\n",
            " [ 33 315]]\n",
            "0.9104166666666667 0.8931405998415747\n",
            "[[121  11]\n",
            " [ 30 318]]\n",
            "f1 = 0.8972811875296857 acc = 0.9145833333333333\n",
            "0.9145833333333333 0.8972811875296857\n",
            "fold = 2\n",
            "0.6316208117886594\n",
            "0.49427836388349533\n",
            "[[110  22]\n",
            " [ 54 294]]\n",
            "0.8416666666666667 0.8143927059589711\n",
            "0.4188095950766614\n",
            "0.4004441536962986\n",
            "[[117  15]\n",
            " [ 47 301]]\n",
            "0.8708333333333333 0.8485835232823185\n",
            "0.25362498509256465\n",
            "0.41101424396038055\n",
            "[[122  10]\n",
            " [ 47 301]]\n",
            "0.88125 0.8620682701566351\n",
            "[[122  10]\n",
            " [ 47 301]]\n",
            "f1 = 0.8620682701566351 acc = 0.88125\n",
            "0.88125 0.8620682701566351\n",
            "fold = 3\n",
            "0.6271530044706244\n",
            "0.5172787606716156\n",
            "[[115  17]\n",
            " [ 49 299]]\n",
            "0.8625 0.8388147183327906\n",
            "0.3542341244848151\n",
            "0.4229806363582611\n",
            "[[122  10]\n",
            " [ 52 296]]\n",
            "0.8708333333333333 0.8512921988367212\n",
            "0.25237459807019486\n",
            "0.4284602254629135\n",
            "[[125   7]\n",
            " [ 49 299]]\n",
            "0.8833333333333333 0.8656832763686515\n",
            "[[125   7]\n",
            " [ 49 299]]\n",
            "f1 = 0.8656832763686515 acc = 0.8833333333333333\n",
            "0.8833333333333333 0.8656832763686515\n",
            "fold = 4\n",
            "0.7740160979722676\n",
            "0.49238593876361847\n",
            "[[115  17]\n",
            " [ 59 289]]\n",
            "0.8416666666666667 0.8177130179288841\n",
            "0.48582432458275243\n",
            "0.41991880536079407\n",
            "[[107  25]\n",
            " [ 38 310]]\n",
            "0.86875 0.8401615298824998\n",
            "0.2779909152733652\n",
            "0.386418879032135\n",
            "[[121  11]\n",
            " [ 39 309]]\n",
            "0.8958333333333334 0.8769584119432368\n",
            "[[121  11]\n",
            " [ 39 309]]\n",
            "f1 = 0.8769584119432368 acc = 0.8958333333333334\n",
            "0.8958333333333334 0.8769584119432368\n",
            "*******19*********\n",
            "fold = 0\n",
            "0.4883259377981487\n",
            "0.3123890236020088\n",
            "[[275  13]\n",
            " [  3 189]]\n",
            "0.9666666666666667 0.9655611558537067\n",
            "0.08798588949598764\n",
            "0.07769377995282412\n",
            "[[283   5]\n",
            " [  1 191]]\n",
            "0.9875 0.9870232859923582\n",
            "0.0335249439077942\n",
            "0.06001052865758538\n",
            "[[284   4]\n",
            " [  1 191]]\n",
            "0.9895833333333334 0.9891770499343858\n",
            "[[284   4]\n",
            " [  1 191]]\n",
            "f1 = 0.9891770499343858 acc = 0.9895833333333334\n",
            "0.9895833333333334 0.9891770499343858\n",
            "fold = 1\n",
            "0.49283556326439504\n",
            "0.3907013088464737\n",
            "[[252  36]\n",
            " [  6 186]]\n",
            "0.9125 0.910813823857302\n",
            "0.0879499493656974\n",
            "0.1546401148661971\n",
            "[[279   9]\n",
            " [  9 183]]\n",
            "0.9625 0.9609375\n",
            "0.028969098617763894\n",
            "0.14849676517769694\n",
            "[[280   8]\n",
            " [  8 184]]\n",
            "0.9666666666666667 0.9652777777777778\n",
            "[[280   8]\n",
            " [  8 184]]\n",
            "f1 = 0.9652777777777778 acc = 0.9666666666666667\n",
            "0.9666666666666667 0.9652777777777778\n",
            "fold = 2\n",
            "0.4797852541271009\n",
            "0.3362126909196377\n",
            "[[271  17]\n",
            " [ 16 176]]\n",
            "0.93125 0.9284472049689441\n",
            "0.07187595120386074\n",
            "0.13246718607842922\n",
            "[[275  13]\n",
            " [  9 183]]\n",
            "0.9541666666666667 0.9524187153053133\n",
            "0.03317333657392546\n",
            "0.1338782487437129\n",
            "[[279   9]\n",
            " [ 10 182]]\n",
            "0.9604166666666667 0.9587313510504953\n",
            "[[279   9]\n",
            " [ 10 182]]\n",
            "f1 = 0.9587313510504953 acc = 0.9604166666666667\n",
            "0.9604166666666667 0.9587313510504953\n",
            "fold = 3\n",
            "0.5054335013816231\n",
            "0.39333146810531616\n",
            "[[256  32]\n",
            " [ 12 180]]\n",
            "0.9083333333333333 0.9059762091317045\n",
            "0.06359839841331306\n",
            "0.2226619478315115\n",
            "[[270  18]\n",
            " [ 14 178]]\n",
            "0.9333333333333333 0.9307908586259102\n",
            "0.02436184716459952\n",
            "0.24752573110163212\n",
            "[[269  19]\n",
            " [ 14 178]]\n",
            "0.93125 0.9286868750534624\n",
            "[[270  18]\n",
            " [ 14 178]]\n",
            "f1 = 0.9307908586259102 acc = 0.9333333333333333\n",
            "0.9333333333333333 0.9307908586259102\n",
            "fold = 4\n",
            "0.4650570083605616\n",
            "0.3614417724311352\n",
            "[[264  24]\n",
            " [ 11 181]]\n",
            "0.9270833333333334 0.9248359141160838\n",
            "0.07436340674757957\n",
            "0.1592841763049364\n",
            "[[274  14]\n",
            " [ 11 181]]\n",
            "0.9479166666666666 0.9458852496719294\n",
            "0.02842664262770038\n",
            "0.15615002531558275\n",
            "[[279   9]\n",
            " [  9 183]]\n",
            "0.9625 0.9609375\n",
            "[[279   9]\n",
            " [  9 183]]\n",
            "f1 = 0.9609375 acc = 0.9625\n",
            "0.9625 0.9609375\n",
            "*******20*********\n",
            "fold = 0\n",
            "0.6241325798787569\n",
            "0.5321373045444489\n",
            "[[ 47  13]\n",
            " [ 62 358]]\n",
            "0.84375 0.7306981650072188\n",
            "0.29972386752304275\n",
            "0.31995388492941856\n",
            "[[ 49  11]\n",
            " [ 46 374]]\n",
            "0.88125 0.7807253055499899\n",
            "0.16377972262470344\n",
            "0.1933954916894436\n",
            "[[ 55   5]\n",
            " [ 25 395]]\n",
            "0.9375 0.8745644599303136\n",
            "[[ 55   5]\n",
            " [ 25 395]]\n",
            "f1 = 0.8745644599303136 acc = 0.9375\n",
            "0.9375 0.8745644599303136\n",
            "fold = 1\n",
            "0.7355650898657347\n",
            "0.5389235392212868\n",
            "[[ 54   6]\n",
            " [ 63 357]]\n",
            "0.85625 0.7610234430807196\n",
            "0.3056417436976182\n",
            "0.33047572523355484\n",
            "[[ 55   5]\n",
            " [ 42 378]]\n",
            "0.9020833333333333 0.8210532160449269\n",
            "0.16863448761011424\n",
            "0.29270165227353573\n",
            "[[ 54   6]\n",
            " [ 35 385]]\n",
            "0.9145833333333333 0.8371386721174455\n",
            "[[ 54   6]\n",
            " [ 35 385]]\n",
            "f1 = 0.8371386721174455 acc = 0.9145833333333333\n",
            "0.9145833333333333 0.8371386721174455\n",
            "fold = 2\n",
            "0.8401688133415423\n",
            "0.6326745972037315\n",
            "[[ 52   8]\n",
            " [ 97 323]]\n",
            "0.78125 0.67889703680579\n",
            "0.28339399475800364\n",
            "0.3739196192473173\n",
            "[[ 53   7]\n",
            " [ 58 362]]\n",
            "0.8645833333333334 0.7687501389722722\n",
            "0.19714576280430743\n",
            "0.32915666326880455\n",
            "[[ 53   7]\n",
            " [ 44 376]]\n",
            "0.89375 0.8058237025168358\n",
            "[[ 53   7]\n",
            " [ 44 376]]\n",
            "f1 = 0.8058237025168358 acc = 0.89375\n",
            "0.89375 0.8058237025168358\n",
            "fold = 3\n",
            "0.9443515774450804\n",
            "0.5724113956093788\n",
            "[[ 56   4]\n",
            " [ 86 334]]\n",
            "0.8125 0.7178609681548629\n",
            "0.40829326290833323\n",
            "0.5161280110478401\n",
            "[[ 53   7]\n",
            " [ 84 336]]\n",
            "0.8104166666666667 0.7094025054719881\n",
            "0.23325088777040182\n",
            "0.38200490549206734\n",
            "[[ 51   9]\n",
            " [ 52 368]]\n",
            "0.8729166666666667 0.7746149286819438\n",
            "[[ 51   9]\n",
            " [ 52 368]]\n",
            "f1 = 0.7746149286819438 acc = 0.8729166666666667\n",
            "0.8729166666666667 0.7746149286819438\n",
            "fold = 4\n",
            "0.7587821860062448\n",
            "0.4263777583837509\n",
            "[[ 40  20]\n",
            " [ 27 393]]\n",
            "0.9020833333333333 0.7867493454074543\n",
            "0.36098368544327586\n",
            "0.3238488435745239\n",
            "[[ 51   9]\n",
            " [ 42 378]]\n",
            "0.89375 0.8017348203221809\n",
            "0.17729508876800537\n",
            "0.2643689848482609\n",
            "[[ 52   8]\n",
            " [ 26 394]]\n",
            "0.9291666666666667 0.856130328996086\n",
            "[[ 52   8]\n",
            " [ 26 394]]\n",
            "f1 = 0.856130328996086 acc = 0.9291666666666667\n",
            "0.9291666666666667 0.856130328996086\n",
            "*******21*********\n",
            "fold = 0\n",
            "0.6407413114058343\n",
            "0.5344986245036125\n",
            "[[ 81  27]\n",
            " [ 54 318]]\n",
            "0.83125 0.7768479776847976\n",
            "0.2954394550699937\n",
            "0.30295776575803757\n",
            "[[ 99   9]\n",
            " [ 37 335]]\n",
            "0.9041666666666667 0.8736147998900998\n",
            "0.16120054768888573\n",
            "0.3223176710307598\n",
            "[[ 98  10]\n",
            " [ 38 334]]\n",
            "0.9 0.8681197911896693\n",
            "[[ 99   9]\n",
            " [ 37 335]]\n",
            "f1 = 0.8736147998900998 acc = 0.9041666666666667\n",
            "0.9041666666666667 0.8736147998900998\n",
            "fold = 1\n",
            "0.7069894247933438\n",
            "0.5132000148296356\n",
            "[[ 98  10]\n",
            " [ 63 309]]\n",
            "0.8479166666666667 0.8114902705523486\n",
            "0.31187407280269425\n",
            "0.3022778518497944\n",
            "[[ 95  13]\n",
            " [ 29 343]]\n",
            "0.9125 0.8806366047745358\n",
            "0.1593429783457204\n",
            "0.22925966791808605\n",
            "[[100   8]\n",
            " [ 21 351]]\n",
            "0.9395833333333333 0.9168453813941542\n",
            "[[100   8]\n",
            " [ 21 351]]\n",
            "f1 = 0.9168453813941542 acc = 0.9395833333333333\n",
            "0.9395833333333333 0.9168453813941542\n",
            "fold = 2\n",
            "0.6757402027908125\n",
            "0.465908445417881\n",
            "[[ 79  29]\n",
            " [ 35 337]]\n",
            "0.8666666666666667 0.8124954222515198\n",
            "0.3061090605823617\n",
            "0.3362140469253063\n",
            "[[ 93  15]\n",
            " [ 30 342]]\n",
            "0.90625 0.8717332050665384\n",
            "0.1698099072826536\n",
            "0.3046931717544794\n",
            "[[ 96  12]\n",
            " [ 28 344]]\n",
            "0.9166666666666666 0.8863205759757484\n",
            "[[ 96  12]\n",
            " [ 28 344]]\n",
            "f1 = 0.8863205759757484 acc = 0.9166666666666666\n",
            "0.9166666666666666 0.8863205759757484\n",
            "fold = 3\n",
            "0.6391484862879703\n",
            "0.5752211734652519\n",
            "[[ 97  11]\n",
            " [ 83 289]]\n",
            "0.8041666666666667 0.7668650793650793\n",
            "0.2423631329285471\n",
            "0.37621229887008667\n",
            "[[ 94  14]\n",
            " [ 50 322]]\n",
            "0.8666666666666667 0.8278181329028786\n",
            "0.135931738505238\n",
            "0.32860974967479706\n",
            "[[100   8]\n",
            " [ 44 328]]\n",
            "0.8916666666666667 0.8601022329835889\n",
            "[[100   8]\n",
            " [ 44 328]]\n",
            "f1 = 0.8601022329835889 acc = 0.8916666666666667\n",
            "0.8916666666666667 0.8601022329835889\n",
            "fold = 4\n",
            "0.7410201461691606\n",
            "0.4375937059521675\n",
            "[[ 84  24]\n",
            " [ 37 335]]\n",
            "0.8729166666666667 0.8250885608635654\n",
            "0.3107929998322537\n",
            "0.3310258612036705\n",
            "[[ 87  21]\n",
            " [ 40 332]]\n",
            "0.8729166666666667 0.8281438004402055\n",
            "0.1712999375242936\n",
            "0.2503036856651306\n",
            "[[ 90  18]\n",
            " [ 28 344]]\n",
            "0.9041666666666667 0.866894938631815\n",
            "[[ 90  18]\n",
            " [ 28 344]]\n",
            "f1 = 0.866894938631815 acc = 0.9041666666666667\n",
            "0.9041666666666667 0.866894938631815\n",
            "*******22*********\n",
            "fold = 0\n",
            "0.7564006934040471\n",
            "0.5910463035106659\n",
            "[[179  61]\n",
            " [ 46 194]]\n",
            "0.7770833333333333 0.7768654284783316\n",
            "0.39594149040548426\n",
            "0.39418496936559677\n",
            "[[210  30]\n",
            " [ 37 203]]\n",
            "0.8604166666666667 0.8603869746604096\n",
            "0.2579511639318968\n",
            "0.3794514164328575\n",
            "[[216  24]\n",
            " [ 34 206]]\n",
            "0.8791666666666667 0.8791141988710378\n",
            "[[216  24]\n",
            " [ 34 206]]\n",
            "f1 = 0.8791141988710378 acc = 0.8791666666666667\n",
            "0.8791666666666667 0.8791141988710378\n",
            "fold = 1\n",
            "0.9473842805937717\n",
            "0.5639375448226929\n",
            "[[172  68]\n",
            " [ 28 212]]\n",
            "0.8 0.7986013986013986\n",
            "0.3930784401140715\n",
            "0.5077748373150826\n",
            "[[197  43]\n",
            " [ 42 198]]\n",
            "0.8229166666666666 0.8229158980724742\n",
            "0.2824057207295769\n",
            "0.4486006572842598\n",
            "[[216  24]\n",
            " [ 31 209]]\n",
            "0.8854166666666666 0.8853922926316795\n",
            "[[216  24]\n",
            " [ 31 209]]\n",
            "f1 = 0.8853922926316795 acc = 0.8854166666666666\n",
            "0.8854166666666666 0.8853922926316795\n",
            "fold = 2\n",
            "0.8220239187541761\n",
            "0.5862125009298325\n",
            "[[197  43]\n",
            " [ 58 182]]\n",
            "0.7895833333333333 0.7893776474421637\n",
            "0.4074746778136806\n",
            "0.4489155672490597\n",
            "[[211  29]\n",
            " [ 42 198]]\n",
            "0.8520833333333333 0.8519747557887514\n",
            "0.2756342276146537\n",
            "0.4088639207184315\n",
            "[[213  27]\n",
            " [ 30 210]]\n",
            "0.88125 0.8812453611469198\n",
            "[[213  27]\n",
            " [ 30 210]]\n",
            "f1 = 0.8812453611469198 acc = 0.88125\n",
            "0.88125 0.8812453611469198\n",
            "fold = 3\n",
            "0.8619481121238909\n",
            "0.5810685232281685\n",
            "[[195  45]\n",
            " [ 57 183]]\n",
            "0.7875 0.7873671044402752\n",
            "0.41606238562809794\n",
            "0.41066354885697365\n",
            "[[209  31]\n",
            " [ 30 210]]\n",
            "0.8729166666666667 0.872916115087305\n",
            "0.2464536353945732\n",
            "0.47029129788279533\n",
            "[[208  32]\n",
            " [ 25 215]]\n",
            "0.88125 0.8812247396364679\n",
            "[[208  32]\n",
            " [ 25 215]]\n",
            "f1 = 0.8812247396364679 acc = 0.88125\n",
            "0.88125 0.8812247396364679\n",
            "fold = 4\n",
            "0.8494106123321935\n",
            "0.5634023994207382\n",
            "[[208  32]\n",
            " [ 49 191]]\n",
            "0.83125 0.8310380642385631\n",
            "0.3691730961987847\n",
            "0.4580226391553879\n",
            "[[197  43]\n",
            " [ 38 202]]\n",
            "0.83125 0.8312316874660879\n",
            "0.2821018625246851\n",
            "0.39502495154738426\n",
            "[[209  31]\n",
            " [ 34 206]]\n",
            "0.8645833333333334 0.8645780434131541\n",
            "[[209  31]\n",
            " [ 34 206]]\n",
            "f1 = 0.8645780434131541 acc = 0.8645833333333334\n",
            "0.8645833333333334 0.8645780434131541\n",
            "*******23*********\n",
            "fold = 0\n",
            "0.4598756448218697\n",
            "0.3694663718342781\n",
            "[[134  10]\n",
            " [ 28 308]]\n",
            "0.9208333333333333 0.908856508964442\n",
            "0.1171951669415361\n",
            "0.190448310226202\n",
            "[[133  11]\n",
            " [ 20 316]]\n",
            "0.9354166666666667 0.9244328656093362\n",
            "0.04415630907016365\n",
            "0.1975478045642376\n",
            "[[133  11]\n",
            " [ 17 319]]\n",
            "0.9416666666666667 0.9313599313599313\n",
            "[[133  11]\n",
            " [ 17 319]]\n",
            "f1 = 0.9313599313599313 acc = 0.9416666666666667\n",
            "0.9416666666666667 0.9313599313599313\n",
            "fold = 1\n",
            "0.47643536995900304\n",
            "0.38946864008903503\n",
            "[[130  14]\n",
            " [ 28 308]]\n",
            "0.9125 0.8985486825419191\n",
            "0.10418128996695343\n",
            "0.1954308096319437\n",
            "[[132  12]\n",
            " [ 15 321]]\n",
            "0.94375 0.933428875225371\n",
            "0.039875584801560955\n",
            "0.17337492294609547\n",
            "[[134  10]\n",
            " [ 16 320]]\n",
            "0.9458333333333333 0.9362627934056506\n",
            "[[134  10]\n",
            " [ 16 320]]\n",
            "f1 = 0.9362627934056506 acc = 0.9458333333333333\n",
            "0.9458333333333333 0.9362627934056506\n",
            "fold = 2\n",
            "0.5424074671770397\n",
            "0.3411146476864815\n",
            "[[121  23]\n",
            " [  9 327]]\n",
            "0.9333333333333333 0.9182822242557085\n",
            "0.10733260331969512\n",
            "0.17819090373814106\n",
            "[[134  10]\n",
            " [ 14 322]]\n",
            "0.95 0.9409400377327537\n",
            "0.0380533654242754\n",
            "0.16246909089386463\n",
            "[[135   9]\n",
            " [ 10 326]]\n",
            "0.9604166666666667 0.9529700545072942\n",
            "[[135   9]\n",
            " [ 10 326]]\n",
            "f1 = 0.9529700545072942 acc = 0.9604166666666667\n",
            "0.9604166666666667 0.9529700545072942\n",
            "fold = 3\n",
            "0.4727626733089748\n",
            "0.3615984581410885\n",
            "[[138   6]\n",
            " [ 31 305]]\n",
            "0.9229166666666667 0.9123010601893231\n",
            "0.09143696372446261\n",
            "0.12103172764182091\n",
            "[[139   5]\n",
            " [  8 328]]\n",
            "0.9729166666666667 0.9679472362196231\n",
            "0.03861914888808602\n",
            "0.09035111125558615\n",
            "[[140   4]\n",
            " [  7 329]]\n",
            "0.9770833333333333 0.9728784306473734\n",
            "[[140   4]\n",
            " [  7 329]]\n",
            "f1 = 0.9728784306473734 acc = 0.9770833333333333\n",
            "0.9770833333333333 0.9728784306473734\n",
            "fold = 4\n",
            "0.5218419809090463\n",
            "0.37478017807006836\n",
            "[[132  12]\n",
            " [ 30 306]]\n",
            "0.9125 0.8992624572764886\n",
            "0.10682042041107227\n",
            "0.19875113107264042\n",
            "[[133  11]\n",
            " [ 15 321]]\n",
            "0.9458333333333333 0.9360183742104833\n",
            "0.03752439277932832\n",
            "0.22124159522354603\n",
            "[[134  10]\n",
            " [ 14 322]]\n",
            "0.95 0.9409400377327537\n",
            "[[134  10]\n",
            " [ 14 322]]\n",
            "f1 = 0.9409400377327537 acc = 0.95\n",
            "0.95 0.9409400377327537\n",
            "*******24*********\n",
            "fold = 0\n",
            "0.7173006848285073\n",
            "0.530419260263443\n",
            "[[198  42]\n",
            " [ 51 189]]\n",
            "0.80625 0.8061818608104412\n",
            "0.2880750918074658\n",
            "0.4058978334069252\n",
            "[[206  34]\n",
            " [ 29 211]]\n",
            "0.86875 0.8687357569180685\n",
            "0.15507527754495018\n",
            "0.39866702258586884\n",
            "[[210  30]\n",
            " [ 25 215]]\n",
            "0.8854166666666666 0.8854042322300597\n",
            "[[210  30]\n",
            " [ 25 215]]\n",
            "f1 = 0.8854042322300597 acc = 0.8854166666666666\n",
            "0.8854166666666666 0.8854042322300597\n",
            "fold = 1\n",
            "0.6414595575709092\n",
            "0.4940212219953537\n",
            "[[206  34]\n",
            " [ 32 208]]\n",
            "0.8625 0.862497612805778\n",
            "0.29618423706606817\n",
            "0.2985825091600418\n",
            "[[220  20]\n",
            " [ 19 221]]\n",
            "0.91875 0.9187496473508999\n",
            "0.16176952068742953\n",
            "0.27246296405792236\n",
            "[[218  22]\n",
            " [ 18 222]]\n",
            "0.9166666666666666 0.9166608792277242\n",
            "[[220  20]\n",
            " [ 19 221]]\n",
            "f1 = 0.9187496473508999 acc = 0.91875\n",
            "0.91875 0.9187496473508999\n",
            "fold = 2\n",
            "0.6768184092484022\n",
            "0.5490458458662033\n",
            "[[175  65]\n",
            " [ 25 215]]\n",
            "0.8125 0.8111888111888111\n",
            "0.2971275746822357\n",
            "0.419950507581234\n",
            "[[195  45]\n",
            " [ 27 213]]\n",
            "0.85 0.849788765451416\n",
            "0.1666598014141384\n",
            "0.3267555646598339\n",
            "[[208  32]\n",
            " [ 24 216]]\n",
            "0.8833333333333333 0.8833009169213671\n",
            "[[208  32]\n",
            " [ 24 216]]\n",
            "f1 = 0.8833009169213671 acc = 0.8833333333333333\n",
            "0.8833333333333333 0.8833009169213671\n",
            "fold = 3\n",
            "0.7481848895549774\n",
            "0.5005817487835884\n",
            "[[192  48]\n",
            " [ 29 211]]\n",
            "0.8395833333333333 0.8393315915996853\n",
            "0.2952522227638646\n",
            "0.36483462527394295\n",
            "[[211  29]\n",
            " [ 24 216]]\n",
            "0.8895833333333333 0.8895713510580575\n",
            "0.15181968439566462\n",
            "0.35644248500466347\n",
            "[[210  30]\n",
            " [ 26 214]]\n",
            "0.8833333333333333 0.8833252309188138\n",
            "[[211  29]\n",
            " [ 24 216]]\n",
            "f1 = 0.8895713510580575 acc = 0.8895833333333333\n",
            "0.8895833333333333 0.8895713510580575\n",
            "fold = 4\n",
            "0.7374802545497292\n",
            "0.5015898048877716\n",
            "[[198  42]\n",
            " [ 39 201]]\n",
            "0.83125 0.8312434079456229\n",
            "0.3414548094335355\n",
            "0.38206708803772926\n",
            "[[216  24]\n",
            " [ 28 212]]\n",
            "0.8916666666666667 0.8916591429960414\n",
            "0.1827344094452105\n",
            "0.3125990256667137\n",
            "[[221  19]\n",
            " [ 26 214]]\n",
            "0.90625 0.9062300576077378\n",
            "[[221  19]\n",
            " [ 26 214]]\n",
            "f1 = 0.9062300576077378 acc = 0.90625\n",
            "0.90625 0.9062300576077378\n",
            "*******25*********\n",
            "fold = 0\n",
            "0.5832177039824034\n",
            "0.46096718311309814\n",
            "[[136  20]\n",
            " [ 35 289]]\n",
            "0.8854166666666666 0.872458222821282\n",
            "0.18018065883140816\n",
            "0.2518075332045555\n",
            "[[143  13]\n",
            " [ 25 299]]\n",
            "0.9208333333333333 0.91148381085488\n",
            "0.1065551151374453\n",
            "0.24590739980340004\n",
            "[[147   9]\n",
            " [ 19 305]]\n",
            "0.9416666666666667 0.9345781654627232\n",
            "[[147   9]\n",
            " [ 19 305]]\n",
            "f1 = 0.9345781654627232 acc = 0.9416666666666667\n",
            "0.9416666666666667 0.9345781654627232\n",
            "fold = 1\n",
            "0.606615695514177\n",
            "0.4099917337298393\n",
            "[[130  26]\n",
            " [ 34 290]]\n",
            "0.875 0.859375\n",
            "0.20250975262177617\n",
            "0.26630422472953796\n",
            "[[139  17]\n",
            " [ 30 294]]\n",
            "0.9020833333333333 0.8906844336765597\n",
            "0.10958585103875712\n",
            "0.21395229175686836\n",
            "[[144  12]\n",
            " [ 13 311]]\n",
            "0.9479166666666666 0.9407439595873806\n",
            "[[144  12]\n",
            " [ 13 311]]\n",
            "f1 = 0.9407439595873806 acc = 0.9479166666666666\n",
            "0.9479166666666666 0.9407439595873806\n",
            "fold = 2\n",
            "0.6356008970423749\n",
            "0.4809132292866707\n",
            "[[145  11]\n",
            " [ 59 265]]\n",
            "0.8541666666666666 0.8444444444444446\n",
            "0.18340561656575455\n",
            "0.20260268077254295\n",
            "[[146  10]\n",
            " [ 12 312]]\n",
            "0.9541666666666667 0.9479402890891524\n",
            "0.09947205668217257\n",
            "0.14001487009227276\n",
            "[[150   6]\n",
            " [  9 315]]\n",
            "0.96875 0.9645625692137321\n",
            "[[150   6]\n",
            " [  9 315]]\n",
            "f1 = 0.9645625692137321 acc = 0.96875\n",
            "0.96875 0.9645625692137321\n",
            "fold = 3\n",
            "0.6176165679567739\n",
            "0.410744845867157\n",
            "[[145  11]\n",
            " [ 36 288]]\n",
            "0.9020833333333333 0.8925463560545079\n",
            "0.24962319551329865\n",
            "0.2244581263512373\n",
            "[[146  10]\n",
            " [ 23 301]]\n",
            "0.93125 0.9232465172622653\n",
            "0.12420445033594181\n",
            "0.2146885059773922\n",
            "[[144  12]\n",
            " [ 18 306]]\n",
            "0.9375 0.9294657026979369\n",
            "[[144  12]\n",
            " [ 18 306]]\n",
            "f1 = 0.9294657026979369 acc = 0.9375\n",
            "0.9375 0.9294657026979369\n",
            "fold = 4\n",
            "0.5254308557824084\n",
            "0.4561062902212143\n",
            "[[138  18]\n",
            " [ 36 288]]\n",
            "0.8875 0.8753246753246753\n",
            "0.17842079659825877\n",
            "0.27639585733413696\n",
            "[[142  14]\n",
            " [ 21 303]]\n",
            "0.9270833333333334 0.9178399737870393\n",
            "0.08856050042729628\n",
            "0.2521421778947115\n",
            "[[145  11]\n",
            " [ 16 308]]\n",
            "0.94375 0.9364179148412166\n",
            "[[145  11]\n",
            " [ 16 308]]\n",
            "f1 = 0.9364179148412166 acc = 0.94375\n",
            "0.94375 0.9364179148412166\n",
            "*******26*********\n",
            "fold = 0\n",
            "0.604438633510941\n",
            "0.4483354389667511\n",
            "[[158  22]\n",
            " [ 32 268]]\n",
            "0.8875 0.8812643151626203\n",
            "0.1948743782153255\n",
            "0.267504271119833\n",
            "[[167  13]\n",
            " [ 28 272]]\n",
            "0.9145833333333333 0.9102905982905983\n",
            "0.11090983097490512\n",
            "0.29855041950941086\n",
            "[[168  12]\n",
            " [ 26 274]]\n",
            "0.9208333333333333 0.9167746527714405\n",
            "[[168  12]\n",
            " [ 26 274]]\n",
            "f1 = 0.9167746527714405 acc = 0.9208333333333333\n",
            "0.9208333333333333 0.9167746527714405\n",
            "fold = 1\n",
            "0.5384703404025027\n",
            "0.4692235141992569\n",
            "[[173   7]\n",
            " [ 51 249]]\n",
            "0.8791666666666667 0.8760595484008832\n",
            "0.1729254702988424\n",
            "0.2724435180425644\n",
            "[[164  16]\n",
            " [ 24 276]]\n",
            "0.9166666666666666 0.9118683901292597\n",
            "0.10593637461332898\n",
            "0.24703938513994217\n",
            "[[168  12]\n",
            " [ 21 279]]\n",
            "0.93125 0.9273657711196401\n",
            "[[168  12]\n",
            " [ 21 279]]\n",
            "f1 = 0.9273657711196401 acc = 0.93125\n",
            "0.93125 0.9273657711196401\n",
            "fold = 2\n",
            "0.5322239124461224\n",
            "0.4424251839518547\n",
            "[[171   9]\n",
            " [ 44 256]]\n",
            "0.8895833333333333 0.8860087375378067\n",
            "0.16891600152379588\n",
            "0.22226774506270885\n",
            "[[166  14]\n",
            " [ 16 284]]\n",
            "0.9375 0.9334799238714684\n",
            "0.10201058262272884\n",
            "0.19979647174477577\n",
            "[[167  13]\n",
            " [ 12 288]]\n",
            "0.9479166666666666 0.9443823896106303\n",
            "[[167  13]\n",
            " [ 12 288]]\n",
            "f1 = 0.9443823896106303 acc = 0.9479166666666666\n",
            "0.9479166666666666 0.9443823896106303\n",
            "fold = 3\n",
            "0.5005104259440774\n",
            "0.43225057423114777\n",
            "[[162  18]\n",
            " [ 24 276]]\n",
            "0.9125 0.9072694154661368\n",
            "0.18514067365934975\n",
            "0.25231841392815113\n",
            "[[163  17]\n",
            " [ 26 274]]\n",
            "0.9104166666666667 0.9053553987316523\n",
            "0.11195371162734534\n",
            "0.19864161871373653\n",
            "[[171   9]\n",
            " [ 17 283]]\n",
            "0.9458333333333333 0.9427144535840188\n",
            "[[171   9]\n",
            " [ 17 283]]\n",
            "f1 = 0.9427144535840188 acc = 0.9458333333333333\n",
            "0.9458333333333333 0.9427144535840188\n",
            "fold = 4\n",
            "0.5382814760270872\n",
            "0.43541673570871353\n",
            "[[145  35]\n",
            " [ 34 266]]\n",
            "0.85625 0.8464953953253399\n",
            "0.2020824618245426\n",
            "0.23442933708429337\n",
            "[[172   8]\n",
            " [ 19 281]]\n",
            "0.94375 0.9406916561031307\n",
            "0.11353185919946746\n",
            "0.23432153463363647\n",
            "[[173   7]\n",
            " [ 18 282]]\n",
            "0.9479166666666666 0.9450848667621579\n",
            "[[173   7]\n",
            " [ 18 282]]\n",
            "f1 = 0.9450848667621579 acc = 0.9479166666666666\n",
            "0.9479166666666666 0.9450848667621579\n",
            "*******27*********\n",
            "fold = 0\n",
            "0.649447461492137\n",
            "0.42218395322561264\n",
            "[[200  28]\n",
            " [ 18 234]]\n",
            "0.9041666666666667 0.9036834115614805\n",
            "0.18516046357782265\n",
            "0.2114562913775444\n",
            "[[214  14]\n",
            " [ 14 238]]\n",
            "0.9416666666666667 0.9415204678362573\n",
            "0.09167392198976718\n",
            "0.17822563461959362\n",
            "[[212  16]\n",
            " [  9 243]]\n",
            "0.9479166666666666 0.9476985168171062\n",
            "[[212  16]\n",
            " [  9 243]]\n",
            "f1 = 0.9476985168171062 acc = 0.9479166666666666\n",
            "0.9479166666666666 0.9476985168171062\n",
            "fold = 1\n",
            "0.600204985392721\n",
            "0.4445546790957451\n",
            "[[197  31]\n",
            " [ 19 233]]\n",
            "0.8958333333333334 0.895244081290593\n",
            "0.16957104794288935\n",
            "0.28806838393211365\n",
            "[[206  22]\n",
            " [ 17 235]]\n",
            "0.91875 0.9184523368720023\n",
            "0.08286735552706216\n",
            "0.31166477128863335\n",
            "[[210  18]\n",
            " [ 14 238]]\n",
            "0.9333333333333333 0.9331057069193784\n",
            "[[210  18]\n",
            " [ 14 238]]\n",
            "f1 = 0.9331057069193784 acc = 0.9333333333333333\n",
            "0.9333333333333333 0.9331057069193784\n",
            "fold = 2\n",
            "0.6231086010995665\n",
            "0.48768652230501175\n",
            "[[217  11]\n",
            " [ 50 202]]\n",
            "0.8729166666666667 0.8727924405343759\n",
            "0.1841603862611871\n",
            "0.2578872963786125\n",
            "[[214  14]\n",
            " [ 20 232]]\n",
            "0.9291666666666667 0.9290669170187242\n",
            "0.09363959278715284\n",
            "0.21611495316028595\n",
            "[[218  10]\n",
            " [ 17 235]]\n",
            "0.94375 0.9436793547461878\n",
            "[[218  10]\n",
            " [ 17 235]]\n",
            "f1 = 0.9436793547461878 acc = 0.94375\n",
            "0.94375 0.9436793547461878\n",
            "fold = 3\n",
            "0.637215217477397\n",
            "0.4716430753469467\n",
            "[[193  35]\n",
            " [ 24 228]]\n",
            "0.8770833333333333 0.8764263117704811\n",
            "0.15615243798023776\n",
            "0.28377815335989\n",
            "[[205  23]\n",
            " [ 22 230]]\n",
            "0.90625 0.9059949951039059\n",
            "0.0821947792642995\n",
            "0.2865835279226303\n",
            "[[210  18]\n",
            " [ 22 230]]\n",
            "0.9166666666666666 0.9165217391304348\n",
            "[[210  18]\n",
            " [ 22 230]]\n",
            "f1 = 0.9165217391304348 acc = 0.9166666666666666\n",
            "0.9166666666666666 0.9165217391304348\n",
            "fold = 4\n",
            "0.6294489353895187\n",
            "0.4474133178591728\n",
            "[[206  22]\n",
            " [ 30 222]]\n",
            "0.8916666666666667 0.8915461624026697\n",
            "0.18378983320374237\n",
            "0.2438014168292284\n",
            "[[215  13]\n",
            " [ 18 234]]\n",
            "0.9354166666666667 0.9353153160985745\n",
            "0.08268517275389872\n",
            "0.22332795709371567\n",
            "[[212  16]\n",
            " [ 16 236]]\n",
            "0.9333333333333333 0.9331662489557226\n",
            "[[215  13]\n",
            " [ 18 234]]\n",
            "f1 = 0.9353153160985745 acc = 0.9354166666666667\n",
            "0.9354166666666667 0.9353153160985745\n",
            "*******28*********\n",
            "fold = 0\n",
            "0.7874372460340199\n",
            "0.4769022762775421\n",
            "[[ 85  47]\n",
            " [ 22 326]]\n",
            "0.85625 0.8077983275204708\n",
            "0.34716197613038513\n",
            "0.3163164220750332\n",
            "[[106  26]\n",
            " [ 23 325]]\n",
            "0.8979166666666667 0.8710801966684755\n",
            "0.18430033992779882\n",
            "0.33162694051861763\n",
            "[[116  16]\n",
            " [ 24 324]]\n",
            "0.9166666666666666 0.8974008207934336\n",
            "[[116  16]\n",
            " [ 24 324]]\n",
            "f1 = 0.8974008207934336 acc = 0.9166666666666666\n",
            "0.9166666666666666 0.8974008207934336\n",
            "fold = 1\n",
            "0.5935163686149999\n",
            "0.4707944914698601\n",
            "[[ 88  44]\n",
            " [ 27 321]]\n",
            "0.8520833333333333 0.8064856823253517\n",
            "0.24608140478008672\n",
            "0.29741770029067993\n",
            "[[114  18]\n",
            " [ 24 324]]\n",
            "0.9125 0.8917874396135266\n",
            "0.1561004923362481\n",
            "0.37408365309238434\n",
            "[[106  26]\n",
            " [ 29 319]]\n",
            "0.8854166666666666 0.8573212056358124\n",
            "[[114  18]\n",
            " [ 24 324]]\n",
            "f1 = 0.8917874396135266 acc = 0.9125\n",
            "0.9125 0.8917874396135266\n",
            "fold = 2\n",
            "0.7366939014510104\n",
            "0.5984072908759117\n",
            "[[118  14]\n",
            " [ 99 249]]\n",
            "0.7645833333333333 0.7456375240926848\n",
            "0.3195169089656127\n",
            "0.3840463422238827\n",
            "[[113  19]\n",
            " [ 52 296]]\n",
            "0.8520833333333333 0.8269268857504151\n",
            "0.20461366717752658\n",
            "0.3929930105805397\n",
            "[[117  15]\n",
            " [ 40 308]]\n",
            "0.8854166666666666 0.8638606841000624\n",
            "[[117  15]\n",
            " [ 40 308]]\n",
            "f1 = 0.8638606841000624 acc = 0.8854166666666666\n",
            "0.8854166666666666 0.8638606841000624\n",
            "fold = 3\n",
            "0.7487042703126606\n",
            "0.5777859091758728\n",
            "[[107  25]\n",
            " [ 74 274]]\n",
            "0.79375 0.7653460799660265\n",
            "0.34810313111857366\n",
            "0.2970237173140049\n",
            "[[120  12]\n",
            " [ 33 315]]\n",
            "0.90625 0.8877192982456141\n",
            "0.18979498234234357\n",
            "0.3462706282734871\n",
            "[[121  11]\n",
            " [ 34 314]]\n",
            "0.90625 0.8881703951830433\n",
            "[[120  12]\n",
            " [ 33 315]]\n",
            "f1 = 0.8877192982456141 acc = 0.90625\n",
            "0.90625 0.8877192982456141\n",
            "fold = 4\n",
            "1.050829026259874\n",
            "0.5944063812494278\n",
            "[[110  22]\n",
            " [ 84 264]]\n",
            "0.7791666666666667 0.7538270983723946\n",
            "0.32669363288502945\n",
            "0.47446581721305847\n",
            "[[108  24]\n",
            " [ 45 303]]\n",
            "0.85625 0.8278362573099416\n",
            "0.17777259647846222\n",
            "0.4897109568119049\n",
            "[[114  18]\n",
            " [ 48 300]]\n",
            "0.8625 0.8382055524912668\n",
            "[[114  18]\n",
            " [ 48 300]]\n",
            "f1 = 0.8382055524912668 acc = 0.8625\n",
            "0.8625 0.8382055524912668\n",
            "*******29*********\n",
            "fold = 0\n",
            "0.7108751398168112\n",
            "0.4145977795124054\n",
            "[[324  48]\n",
            " [ 11  97]]\n",
            "0.8770833333333333 0.8416736083546243\n",
            "0.22916834664187932\n",
            "0.278531264513731\n",
            "[[342  30]\n",
            " [  7 101]]\n",
            "0.9229166666666667 0.8969353350472089\n",
            "0.11577314667795834\n",
            "0.2500751558691263\n",
            "[[351  21]\n",
            " [  9  99]]\n",
            "0.9375 0.913718723037101\n",
            "[[351  21]\n",
            " [  9  99]]\n",
            "f1 = 0.913718723037101 acc = 0.9375\n",
            "0.9375 0.913718723037101\n",
            "fold = 1\n",
            "0.6376907919582567\n",
            "0.42136065661907196\n",
            "[[332  40]\n",
            " [  9  99]]\n",
            "0.8979166666666667 0.866447865266792\n",
            "0.2597365716570302\n",
            "0.2559387758374214\n",
            "[[344  28]\n",
            " [  8 100]]\n",
            "0.925 0.8988669351062833\n",
            "0.11637709730941999\n",
            "0.2427763044834137\n",
            "[[343  29]\n",
            " [  9  99]]\n",
            "0.9208333333333333 0.8932484315010769\n",
            "[[344  28]\n",
            " [  8 100]]\n",
            "f1 = 0.8988669351062833 acc = 0.925\n",
            "0.925 0.8988669351062833\n",
            "fold = 2\n",
            "0.6518762574384087\n",
            "0.4254472702741623\n",
            "[[336  36]\n",
            " [ 15  93]]\n",
            "0.89375 0.8571353537475708\n",
            "0.20491497257822439\n",
            "0.2983686104416847\n",
            "[[338  34]\n",
            " [ 10  98]]\n",
            "0.9083333333333333 0.8777777777777778\n",
            "0.11084243380709698\n",
            "0.3025701716542244\n",
            "[[342  30]\n",
            " [ 10  98]]\n",
            "0.9166666666666666 0.8876299278958704\n",
            "[[342  30]\n",
            " [ 10  98]]\n",
            "f1 = 0.8876299278958704 acc = 0.9166666666666666\n",
            "0.9166666666666666 0.8876299278958704\n",
            "fold = 3\n",
            "0.7567291604845148\n",
            "0.41299786418676376\n",
            "[[332  40]\n",
            " [ 12  96]]\n",
            "0.8916666666666667 0.8571297737888085\n",
            "0.21467126788277374\n",
            "0.25120555609464645\n",
            "[[343  29]\n",
            " [  7 101]]\n",
            "0.925 0.899438999976722\n",
            "0.11345513027749564\n",
            "0.28528330847620964\n",
            "[[340  32]\n",
            " [  7 101]]\n",
            "0.91875 0.8919661355386401\n",
            "[[343  29]\n",
            " [  7 101]]\n",
            "f1 = 0.899438999976722 acc = 0.925\n",
            "0.925 0.899438999976722\n",
            "fold = 4\n",
            "0.6623935275956204\n",
            "0.5216568484902382\n",
            "[[293  79]\n",
            " [  9  99]]\n",
            "0.8166666666666667 0.7808719470440539\n",
            "0.25532977498675646\n",
            "0.24098599329590797\n",
            "[[344  28]\n",
            " [  5 103]]\n",
            "0.93125 0.9080774609880513\n",
            "0.12836547097877452\n",
            "0.20571867749094963\n",
            "[[350  22]\n",
            " [  4 104]]\n",
            "0.9458333333333333 0.9265381083562901\n",
            "[[350  22]\n",
            " [  4 104]]\n",
            "f1 = 0.9265381083562901 acc = 0.9458333333333333\n",
            "0.9458333333333333 0.9265381083562901\n",
            "*******30*********\n",
            "fold = 0\n",
            "0.8262579409699691\n",
            "0.5844873413443565\n",
            "[[240  24]\n",
            " [ 70 146]]\n",
            "0.8041666666666667 0.7963568088678666\n",
            "0.3543175686346857\n",
            "0.4309948459267616\n",
            "[[233  31]\n",
            " [ 33 183]]\n",
            "0.8666666666666667 0.8652040368582712\n",
            "0.23201432039863185\n",
            "0.4189843386411667\n",
            "[[231  33]\n",
            " [ 34 182]]\n",
            "0.8604166666666667 0.8589467497664465\n",
            "[[233  31]\n",
            " [ 33 183]]\n",
            "f1 = 0.8652040368582712 acc = 0.8666666666666667\n",
            "0.8666666666666667 0.8652040368582712\n",
            "fold = 1\n",
            "0.7886137601576353\n",
            "0.6183073446154594\n",
            "[[226  38]\n",
            " [ 58 158]]\n",
            "0.8 0.7959039047551556\n",
            "0.4236391351411217\n",
            "0.519654355943203\n",
            "[[213  51]\n",
            " [ 41 175]]\n",
            "0.8083333333333333 0.8071245130068658\n",
            "0.2615119987412503\n",
            "0.42448408901691437\n",
            "[[223  41]\n",
            " [ 21 195]]\n",
            "0.8708333333333333 0.8703923071562957\n",
            "[[223  41]\n",
            " [ 21 195]]\n",
            "f1 = 0.8703923071562957 acc = 0.8708333333333333\n",
            "0.8708333333333333 0.8703923071562957\n",
            "fold = 2\n",
            "0.8624956639189469\n",
            "0.6164399161934853\n",
            "[[223  41]\n",
            " [ 59 157]]\n",
            "0.7916666666666666 0.787651961565005\n",
            "0.42275723971818624\n",
            "0.4681042730808258\n",
            "[[225  39]\n",
            " [ 30 186]]\n",
            "0.85625 0.8552947190436868\n",
            "0.21548165969158473\n",
            "0.43024902045726776\n",
            "[[224  40]\n",
            " [ 30 186]]\n",
            "0.8541666666666666 0.8532469120704416\n",
            "[[225  39]\n",
            " [ 30 186]]\n",
            "f1 = 0.8552947190436868 acc = 0.85625\n",
            "0.85625 0.8552947190436868\n",
            "fold = 3\n",
            "0.9355658041803461\n",
            "0.604010134935379\n",
            "[[197  67]\n",
            " [ 39 177]]\n",
            "0.7791666666666667 0.7787826086956521\n",
            "0.5243137933705982\n",
            "0.48539310693740845\n",
            "[[224  40]\n",
            " [ 46 170]]\n",
            "0.8208333333333333 0.8185366882945614\n",
            "0.2482480626357229\n",
            "0.43797289580106735\n",
            "[[229  35]\n",
            " [ 36 180]]\n",
            "0.8520833333333333 0.850525660200264\n",
            "[[229  35]\n",
            " [ 36 180]]\n",
            "f1 = 0.850525660200264 acc = 0.8520833333333333\n",
            "0.8520833333333333 0.850525660200264\n",
            "fold = 4\n",
            "0.7228583944471259\n",
            "0.5963462367653847\n",
            "[[221  43]\n",
            " [ 45 171]]\n",
            "0.8166666666666667 0.8146555506801227\n",
            "0.3763806890500219\n",
            "0.5019664019346237\n",
            "[[224  40]\n",
            " [ 52 164]]\n",
            "0.8083333333333333 0.8052910052910053\n",
            "0.2769123088372381\n",
            "0.4414958506822586\n",
            "[[226  38]\n",
            " [ 22 194]]\n",
            "0.875 0.8744419642857143\n",
            "[[226  38]\n",
            " [ 22 194]]\n",
            "f1 = 0.8744419642857143 acc = 0.875\n",
            "0.875 0.8744419642857143\n",
            "*******31*********\n",
            "fold = 0\n",
            "0.8417076939030698\n",
            "0.6018284037709236\n",
            "[[119  37]\n",
            " [ 61 263]]\n",
            "0.7958333333333333 0.7756410256410257\n",
            "0.43657153138988897\n",
            "0.517686665058136\n",
            "[[129  27]\n",
            " [ 58 266]]\n",
            "0.8229166666666666 0.8072116088852768\n",
            "0.2660456613490456\n",
            "0.5293526351451874\n",
            "[[129  27]\n",
            " [ 48 276]]\n",
            "0.84375 0.827578774947196\n",
            "[[129  27]\n",
            " [ 48 276]]\n",
            "f1 = 0.827578774947196 acc = 0.84375\n",
            "0.84375 0.827578774947196\n",
            "fold = 1\n",
            "0.788045407910096\n",
            "0.5784781649708748\n",
            "[[105  51]\n",
            " [ 37 287]]\n",
            "0.8166666666666667 0.7858837364910076\n",
            "0.35214673531682866\n",
            "0.42284418642520905\n",
            "[[128  28]\n",
            " [ 48 276]]\n",
            "0.8416666666666667 0.8250326145345714\n",
            "0.22924528545454928\n",
            "0.43966563045978546\n",
            "[[130  26]\n",
            " [ 45 279]]\n",
            "0.8520833333333333 0.8363104529800816\n",
            "[[130  26]\n",
            " [ 45 279]]\n",
            "f1 = 0.8363104529800816 acc = 0.8520833333333333\n",
            "0.8520833333333333 0.8363104529800816\n",
            "fold = 2\n",
            "0.6820792947944841\n",
            "0.5684533342719078\n",
            "[[130  26]\n",
            " [ 60 264]]\n",
            "0.8208333333333333 0.8056899700626988\n",
            "0.416913061549789\n",
            "0.4592365473508835\n",
            "[[124  32]\n",
            " [ 45 279]]\n",
            "0.8395833333333333 0.8209085402786189\n",
            "0.273181004743827\n",
            "0.3282837085425854\n",
            "[[130  26]\n",
            " [ 26 298]]\n",
            "0.8916666666666667 0.8765432098765432\n",
            "[[130  26]\n",
            " [ 26 298]]\n",
            "f1 = 0.8765432098765432 acc = 0.8916666666666667\n",
            "0.8916666666666667 0.8765432098765432\n",
            "fold = 3\n",
            "0.880492993091282\n",
            "0.531211830675602\n",
            "[[130  26]\n",
            " [ 56 268]]\n",
            "0.8291666666666667 0.8137739169931302\n",
            "0.4563884931175332\n",
            "0.5322399809956551\n",
            "[[127  29]\n",
            " [ 54 270]]\n",
            "0.8270833333333333 0.8102414372877481\n",
            "0.2900923898345546\n",
            "0.40262263268232346\n",
            "[[135  21]\n",
            " [ 40 284]]\n",
            "0.8729166666666667 0.859365318757535\n",
            "[[135  21]\n",
            " [ 40 284]]\n",
            "f1 = 0.859365318757535 acc = 0.8729166666666667\n",
            "0.8729166666666667 0.859365318757535\n",
            "fold = 4\n",
            "0.8102002426197654\n",
            "0.5701268687844276\n",
            "[[123  33]\n",
            " [ 70 254]]\n",
            "0.7854166666666667 0.7681474777128012\n",
            "0.39480489178707723\n",
            "0.4563278704881668\n",
            "[[133  23]\n",
            " [ 56 268]]\n",
            "0.8354166666666667 0.8212796041003888\n",
            "0.25929303702555206\n",
            "0.5238557085394859\n",
            "[[128  28]\n",
            " [ 50 274]]\n",
            "0.8375 0.8209332134453139\n",
            "[[128  28]\n",
            " [ 50 274]]\n",
            "f1 = 0.8209332134453139 acc = 0.8375\n",
            "0.8375 0.8209332134453139\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "\n",
        "#def get_mertics_per_subject():\n",
        "k  = 5\n",
        "type_emotion = 1\n",
        "\n",
        "acc_all = []\n",
        "f1_all = []\n",
        "for sub in range(0,32):\n",
        "    print(f\"*******{sub}*********\")\n",
        "\n",
        "    args.batch_size = 100\n",
        "    indexes = np.arange(NVIDEOS * 1 * LEN_RECORD_IN_SECONDS)\n",
        "    n = len(indexes)\n",
        "    #X = np.arange(40)\n",
        "    y = []\n",
        "    for nvideo in range(NVIDEOS):\n",
        "        y.extend(60 * [labels_bin[sub][nvideo, type_emotion]])\n",
        "    \n",
        "\n",
        "    skf = StratifiedKFold(n_splits=k, random_state=None, shuffle=True)\n",
        "    balanced_split = skf.split(indexes, y)\n",
        "    acc_sub = []\n",
        "    f1_sub = []\n",
        "    for fold,  (inds_train, inds_test) in  enumerate(balanced_split):\n",
        "        print(f\"fold = {fold}\")\n",
        "        #print(inds_train, inds_test)\n",
        "        #print(sum(labels_bin[sub][inds_train, type_emotion]))\n",
        "        #print(sum(labels_bin[sub][inds_test, type_emotion]))\n",
        "        args.batch_size = 100\n",
        "        transforms = []\n",
        "        #transforms_random = RandomAugmentation([add_noise, reset_part_in_freq, reset_part_in_time, None], 0.2)\n",
        "        #transforms = [RandomAugmentation([add_noise(), reset_part_in_freq(0.2), reset_part_in_time(0.2), None], 0.2), to_head_matrix(),ToTensor()]   \n",
        "        #transforms = [to_head_matrix(),ToTensor()] \n",
        "        #transforms = [RandomAugmentation([add_noise(), None], 0.5), to_head_matrix(),ToTensor()]   \n",
        "        #transforms = [RandomAugmentation([reset_part_in_time(0.4), None], 0.1), to_head_matrix(),ToTensor()]   \n",
        "\n",
        "        train_dataset = EmotionDataset_leak(data[sub : sub + 1], labels_bin[sub : sub + 1], transforms, inds_train)\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "                                    pin_memory=True, shuffle=True, drop_last=True)\n",
        "\n",
        "        val_dataset = EmotionDataset_leak(data[sub: sub + 1], labels_bin[sub  : sub + 1], transforms,  inds_test)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "                              pin_memory=True, shuffle=False, drop_last=False)\n",
        "        device  = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model = get_model()\n",
        "        model.apply(initialize_weights)\n",
        "        criterion = nn.CrossEntropyLoss(reduction = 'mean')#torch.nn.MSELoss()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=3e-4, momentum = 0.9)#, weight_decay=args.weight_decay)\n",
        "        #optimizer = optim.Adam(model.parameters(), lr=3e-6)#, momentum = 0.9)#, weight_decay=args.weight_decay)\n",
        "        \n",
        "        description = f'cnn2_leak_subject'\n",
        "        train_loop(description , 1, 3)\n",
        "        model_state  = torch.load(os.path.join(\"/content/drive/MyDrive/MADE/Project/CNN_models/\", f\"val_{description}.tgz\"))\n",
        "        #   #model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device)\n",
        "        model.load_state_dict(model_state['model_state_dict'])\n",
        "        acc, f1 = calculate_predictions(model, val_dataloader, type_emotion)\n",
        "        print(f\"f1 = {f1} acc = {acc}\")\n",
        "        acc_sub.append(acc)\n",
        "        f1_sub.append(f1)\n",
        "        print(acc, f1)\n",
        "        #break\n",
        "    acc_all.append(acc_sub)     \n",
        "    f1_all.append(f1_sub)     \n",
        "    pd.DataFrame(f1_all).to_csv(\"f1_arousal_cnn2_leak_sgd.csv\")\n",
        "    pd.DataFrame(acc_all).to_csv(\"acc_arousal_cnn2_leak_sgd.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzDP3i6nRORv",
        "outputId": "f2f74e57-8fc8-4f2a-adda-ee4bb277bea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.4904051172707889, 0.5842217484008528, 0.6439232409381663, 0.5756929637526652, 0.5756929637526652]]\n"
          ]
        }
      ],
      "source": [
        "print(acc_all)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MADE_СNN2_leak_beta1_article.ipynb",
      "provenance": [],
      "mount_file_id": "1143lsjUpaC1HYEZDucaQvAUa1LiJFKRW",
      "authorship_tag": "ABX9TyN8ko0f9OaMCAJZqmrCRSkY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}